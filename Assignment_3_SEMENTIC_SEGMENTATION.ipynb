{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_SEMENTIC SEGMENTATION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85a7ef1f07054e95b517e2f391dd96a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5504ecc540f24516bc5fab8575fb3c03",
              "IPY_MODEL_8e77201f7e4e4c3e9039131f7ce56e57",
              "IPY_MODEL_8603915231ec4e7bad05835fe285477b"
            ],
            "layout": "IPY_MODEL_587a39e36c4b4fa095df73885eca5a21"
          }
        },
        "5504ecc540f24516bc5fab8575fb3c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0bb08564c364859a02886e2676faa06",
            "placeholder": "​",
            "style": "IPY_MODEL_97cc81406951494b9d9d36ae24e2877e",
            "value": "100%"
          }
        },
        "8e77201f7e4e4c3e9039131f7ce56e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2202b1791f3492fbabe42139f0b44a4",
            "max": 168312152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_838cf7f42b57491091470a9cb4771fea",
            "value": 168312152
          }
        },
        "8603915231ec4e7bad05835fe285477b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677625ca3a254ac2b7051c5629008cf5",
            "placeholder": "​",
            "style": "IPY_MODEL_e20f6d54545c4aa6afff7c7d11ef6d69",
            "value": " 161M/161M [00:01&lt;00:00, 82.4MB/s]"
          }
        },
        "587a39e36c4b4fa095df73885eca5a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bb08564c364859a02886e2676faa06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cc81406951494b9d9d36ae24e2877e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2202b1791f3492fbabe42139f0b44a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838cf7f42b57491091470a9cb4771fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "677625ca3a254ac2b7051c5629008cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20f6d54545c4aa6afff7c7d11ef6d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeomSuWoong/SOCAR-AI-BOOT-CAMP/blob/main/Assignment_3_SEMENTIC_SEGMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AB5d_gIqSsE",
        "outputId": "ef5f963a-ea75-4dc0-ab06-9ba7a2172fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "igaH1zwiT6Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"Colab Notebooks\", \"data\")\n",
        "print(root)\n",
        "print(os.path.exists(f'{root}/diabetes.csv'))"
      ],
      "metadata": {
        "id": "wxwAFNI76TdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938a5dfb-6cdb-4838-d4d9-47ae5c2f75fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/data\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SOCAR_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
        "        \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        # load images ad masks\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        mask = np.array(mask)[:,:,0]      # 3차원으로 구성된 mask 를 label 로 쓰기 위해 변환\n",
        "\n",
        "        mask[mask > 0] = 1\n",
        "\n",
        "        # there is only one class\n",
        "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
        "\n",
        "        target = {}\n",
        "        target[\"masks\"] = mask\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "T6HCC1ZG6VOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomHorizontalFlip(object):\n",
        "    def __init__(self, prob):\n",
        "        self.prob = prob\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        if random.random() < self.prob:\n",
        "            height, width = image.shape[-2:]\n",
        "            image = image.flip(-1)\n",
        "            if \"masks\" in target:\n",
        "                target[\"masks\"] = target[\"masks\"].flip(-1)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        return image, target\n",
        "\n",
        "class Resize(object):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.Resize(self.size)(image)\n",
        "        if \"masks\" in target:\n",
        "            target[\"masks\"] = transforms.Resize(self.size)(target[\"masks\"].unsqueeze(dim=0)).squeeze()\n",
        "        return image, target\n",
        "\n",
        "class Normalize(object):\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n",
        "        return image, target\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "pdLF9gX26ZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train):\n",
        "    transforms = [ToTensor(), Resize((300,300)), Normalize()]\n",
        "    if train:\n",
        "        transforms.append(RandomHorizontalFlip(0.5))\n",
        "    return Compose(transforms)"
      ],
      "metadata": {
        "id": "mciftqDM6dvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
        "seg_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "85a7ef1f07054e95b517e2f391dd96a4",
            "5504ecc540f24516bc5fab8575fb3c03",
            "8e77201f7e4e4c3e9039131f7ce56e57",
            "8603915231ec4e7bad05835fe285477b",
            "587a39e36c4b4fa095df73885eca5a21",
            "a0bb08564c364859a02886e2676faa06",
            "97cc81406951494b9d9d36ae24e2877e",
            "c2202b1791f3492fbabe42139f0b44a4",
            "838cf7f42b57491091470a9cb4771fea",
            "677625ca3a254ac2b7051c5629008cf5",
            "e20f6d54545c4aa6afff7c7d11ef6d69"
          ]
        },
        "id": "en4gOxOS6foq",
        "outputId": "3a6c0764-1213-4e5f-d189-7489f0084e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/161M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85a7ef1f07054e95b517e2f391dd96a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLabV3(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): DeepLabHead(\n",
              "    (0): ASPP(\n",
              "      (convs): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (3): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (4): ASPPPooling(\n",
              "          (0): AdaptiveAvgPool2d(output_size=1)\n",
              "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (3): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux_classifier): FCNHead(\n",
              "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seg_model.classifier[4] = nn.Conv2d(256, 2, kernel_size = (1, 1), stride = (1, 1))\n",
        "seg_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn4wx6M2u0JA",
        "outputId": "13112113-dbe4-4a04-85b3-b90f62e35d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLabV3(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): DeepLabHead(\n",
              "    (0): ASPP(\n",
              "      (convs): ModuleList(\n",
              "        (0): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (3): ASPPConv(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (4): ASPPPooling(\n",
              "          (0): AdaptiveAvgPool2d(output_size=1)\n",
              "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (3): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Dropout(p=0.5, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux_classifier): FCNHead(\n",
              "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dent_train = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/train'), get_transform(train=True))\n",
        "dent_valid = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/valid'), get_transform(train=False))\n",
        "dent_test = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test'), get_transform(train=False))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dent_train, batch_size=2, shuffle=True, drop_last=True)\n",
        "valid_loader = DataLoader(dent_valid, batch_size=2, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(dent_test, batch_size=2, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "Dgh1eeI97TJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trainer class 정의\n",
        "\n",
        "class Semantic_Seg_Trainer(nn.Module):\n",
        "    def __init__(self, model,opt=\"adam\", num_class=2, lr=0.001, has_scheduler=False, device=\"cpu\", log_dir=\"logs\", max_epoch=10):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "            model: 사용할 model\n",
        "            opt: optimizer\n",
        "            lr: learning rate\n",
        "            has_scheduler: learning rate scheduler 사용 여부\n",
        "            device: 사용할 device (cpu/cuda)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        weights = torch.FloatTensor([1/5, 4/5])\n",
        "        self.max_epoch = max_epoch\n",
        "        self.model = model                            \n",
        "        self.loss = nn.CrossEntropyLoss(weight = weights)             # loss function 정의\n",
        "        self.num_class = num_class\n",
        "\n",
        "        self._get_optimizer(opt=opt.lower(), lr=lr)   # optimizer 정의\n",
        "        self.has_scheduler = has_scheduler            # scheduler 사용여부 \n",
        "        if self.has_scheduler:\n",
        "            self._get_scheduler()\n",
        "\n",
        "        self.device = device                          # 사용할 device\n",
        "        \n",
        "        self.log_dir = log_dir\n",
        "        if not os.path.exists(f'{root}/{self.log_dir}'): os.makedirs(f'{root}/{self.log_dir}')\n",
        "\n",
        "    def _get_optimizer(self, opt, lr=0.001):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "            opt: optimizer\n",
        "            lr: learning rate\n",
        "        \"\"\"\n",
        "        if opt == \"sgd\":\n",
        "            self.optimizer = torch.optim.SGD(params=self.model.parameters(), lr=lr)\n",
        "        elif opt == \"adam\":\n",
        "            self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=lr)\n",
        "        else:\n",
        "            raise ValueError(f\"optimizer {opt} is not supproted\")\n",
        "\n",
        "    def _get_scheduler(self):\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(optimizer=self.optimizer, step_size=5, gamma=0.5, verbose=True)\n",
        "\n",
        "    def train(self, train_loader, valid_loader, max_epochs=10, disp_epoch=1, visualize=False):\n",
        "        \"\"\"\n",
        "          네트워크를 학습시키는 함수\n",
        "          Args:\n",
        "            train_loader: 학습에 사용할 train dataloader\n",
        "            valid_loader: validation에 사용할 dataloader\n",
        "            max_epochs: 학습을 진행할 총 epoch 수\n",
        "            disp_epochs: 학습 log를 display 할 epoch 주기\n",
        "            visualize: 학습 진행 과정에서 결과 이미지를 visualize \n",
        "        \"\"\"\n",
        "        print(\"===== Train Start =====\")\n",
        "        start_time = time.time()   \n",
        "        history = {\"train_loss\": [], \"valid_loss\": [], \"train_miou\": [], \"valid_miou\": []}\n",
        "        \n",
        "        checkpoint = 1\n",
        "        for e in range(max_epochs):\n",
        "            print(f\"Start Train Epoch {e}\")\n",
        "            train_loss, train_miou = self._train_epoch(train_loader)\n",
        "            print(f\"Start Valid Epoch {e}\")\n",
        "            valid_loss, valid_miou = self._valid_epoch(valid_loader)\n",
        "            \n",
        "            \n",
        "            history[\"train_loss\"].append(train_loss)      # 현재 epoch에서 성능을 history dict에 저장\n",
        "            history[\"valid_loss\"].append(valid_loss)      #\n",
        "            \n",
        "            history[\"train_miou\"].append(train_miou)      # \n",
        "            history[\"valid_miou\"].append(valid_miou)      #\n",
        "\n",
        "            if self.has_scheduler:         # scheduler 사용할 경우 step size 조절\n",
        "                self.scheduler.step()\n",
        "\n",
        "            if e % disp_epoch == 0:        # disp_epoch 마다 결과값 출력 \n",
        "                print(f\"Epoch: {e}, train loss: {train_loss:>6f}, valid loss: {valid_loss:>6f}, train miou: {train_miou:>6f}, valid miou: {valid_miou:>6f}, time: {time.time()-start_time:>3f}\")\n",
        "                \n",
        "                start_time = time.time()   \n",
        "\n",
        "            self.plot_history(history, save_name=f\"{root}/{self.log_dir}/log_epoch_{e}.png\")       # 그래프 출력\n",
        "            #################################################################################################\n",
        "            #                                                                                               #\n",
        "            # TODO : 한 epoch 의 학습이 끝날때 마다 model 을 save 하는 코드를 작성해봅시다.                             #\n",
        "            #        graph 저장 코드를 참고하여 저장되는 model 의 이름에 몇 epoch 인지 나타나게 해봅시다.                  # \n",
        "            #                                                                                               #\n",
        "            #################################################################################################\n",
        "            torch.save({\n",
        "                'model': f\"Deeplabv3-{e}\",\n",
        "                'epoch': e,\n",
        "                'model_state_dict': seg_model.state_dict(),\n",
        "                'desription': f'Model epoch-{checkpoint}',\n",
        "            },\n",
        "            f'{root}/{self.log_dir}/checkpoint-{checkpoint}.pth')\n",
        "            checkpoint += 1\n",
        "\n",
        "    def _train_epoch(self, train_loader, disp_step=10):\n",
        "        \"\"\"\n",
        "          model를 training set 한 epoch 만큼 학습시키는 함수\n",
        "          Args:\n",
        "            train_loader: 학습에 사용할 train dataloader\n",
        "          Returns:\n",
        "            training set 한 epoch의 평균 loss, 평균 accuracy\n",
        "        \"\"\"\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        miou = 0\n",
        "        ious = np.zeros([2])\n",
        "        \n",
        "        self.model.train()                 # self.model을 train 모드로 전환 --> nn.Module의 내장함수\n",
        "        cnt = 0\n",
        "        epoch_start_time = time.time()\n",
        "        start_time = time.time()\n",
        "        for (x, y) in train_loader:        # x: data, y:label\n",
        "            cnt += 1\n",
        "\n",
        "            x = x.to(self.device)\n",
        "            label = y['masks'].to(self.device).type(torch.long)\n",
        "            \n",
        "            out = self.model(x)              # model이 예측한 output\n",
        "            loss = self.loss(out['out'], label)       \n",
        "\n",
        "            self.optimizer.zero_grad()       # backwardpass를 통한 network parameter 업데이트\n",
        "            loss.backward()                  # \n",
        "            self.optimizer.step()            # \n",
        "            \n",
        "            epoch_loss += loss.to(\"cpu\").item()    \n",
        "            \n",
        "            out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)           # meanIoU 계산을 위한 데이터 변형\n",
        "            out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)               #\n",
        "            \n",
        "            ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long)) # ious[0]:background IoU\n",
        "            ious[1] += self.batch_segmentation_iou(out_target, label)                                         # ious[1]:파손 IoU\n",
        "            \n",
        "            if cnt % disp_step == 0:\n",
        "                iou_back = ious[0]/(cnt*x.shape[0])\n",
        "                iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "                miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "                \n",
        "                print(f\"Iter: {cnt}/{len(train_loader)}, train epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n",
        "                start_time = time.time()   \n",
        "\n",
        "        epoch_loss /= len(train_loader)  \n",
        "        \n",
        "        \n",
        "        iou_back = ious[0]/(cnt*x.shape[0])\n",
        "        iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "        print(f\"Train loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n",
        "\n",
        "        return epoch_loss, epoch_miou\n",
        "  \n",
        "    def _valid_epoch(self, valid_loader, disp_step=10):\n",
        "        \"\"\"\n",
        "          현재 model의 성능을 validation set에서 측정하는 함수\n",
        "          Args:\n",
        "            valid_loader: 학습에 사용할 valid dataloader\n",
        "          Returns:\n",
        "            validation set 의 평균 loss, 평균 accuracy\n",
        "        \"\"\"\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        miou = 0\n",
        "        ious = np.zeros([2])\n",
        "                      \n",
        "        self.model.eval()                  # self.model을 eval 모드로 전환 --> nn.Module의 내장함수\n",
        "        cnt = 0\n",
        "        epoch_start_time = time.time()\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():              # model에 loss의 gradient를 계산하지 않음\n",
        "            for (x, y) in valid_loader:\n",
        "                cnt += 1\n",
        "                x = x.to(self.device)\n",
        "                label = y['masks'].to(self.device).type(torch.long)\n",
        "\n",
        "                out = self.model(x) \n",
        "                loss = self.loss(out['out'], label)\n",
        "                      \n",
        "                epoch_loss += loss.to(\"cpu\").item()\n",
        "                \n",
        "                out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)\n",
        "                out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)\n",
        "\n",
        "                ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long))\n",
        "                ious[1] += self.batch_segmentation_iou(out_target, label)\n",
        "                    \n",
        "\n",
        "                \n",
        "                \n",
        "                if cnt % disp_step == 0:\n",
        "                    iou_back = ious[0]/(cnt*x.shape[0])\n",
        "                    iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "                    miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "                    print(f\"Iter: {cnt}/{len(valid_loader)}, valid epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n",
        "                    start_time = time.time()   \n",
        "\n",
        "        epoch_loss /= len(valid_loader)\n",
        "        \n",
        "        iou_back = ious[0]/(cnt*x.shape[0])\n",
        "        iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "        print(f\"Valid loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n",
        "\n",
        "        return epoch_loss, epoch_miou\n",
        "\n",
        "    def plot_history(self, history, save_name=None):\n",
        "        \"\"\"\n",
        "          history에 저장된 model의 성능을 graph로 plot\n",
        "          Args:\n",
        "            history: dictionary with keys {\"train_loss\",\"valid_loss\",  }\n",
        "                     각 item 들은 epoch 단위의 성능 history의 list\n",
        "        \"\"\"\n",
        "        fig = plt.figure(figsize=(16, 8))\n",
        "        \n",
        "        \n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(history[\"train_loss\"], color=\"red\", label=\"train loss\")\n",
        "        ax.plot(history[\"valid_loss\"], color=\"blue\", label=\"valid loss\")\n",
        "        ax.title.set_text(\"Loss\")\n",
        "        ax.legend()\n",
        "        \n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(history[\"train_miou\"], color=\"red\", label=\"train miou\")\n",
        "        ax.plot(history[\"valid_miou\"], color=\"blue\", label=\"valid miou\")\n",
        "        ax.title.set_text(\"miou\")\n",
        "        ax.legend()\n",
        "\n",
        "        plt.show()\n",
        "                      \n",
        "        if not save_name == None:     # graph 저장\n",
        "            plt.savefig(save_name)\n",
        "                      \n",
        "        \n",
        "\n",
        "    def test(self, test_loader):\n",
        "        \"\"\"\n",
        "          현재 model의 성능을 test set에서 측정하는 함수\n",
        "          Args:\n",
        "            test_loader: 학습에 사용할 test dataloader\n",
        "          Returns:\n",
        "            test set 의 평균 loss, 평균 accuracy\n",
        "        \"\"\"\n",
        "        print(\"===== Test Start =====\")\n",
        "        start_time = time.time()\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        miou = 0\n",
        "        ious = np.zeros([2])\n",
        "                      \n",
        "        self.model.eval()                  # self.model을 eval 모드로 전환 --> nn.Module의 내장함수\n",
        "        cnt = 0\n",
        "        epoch_start_time = time.time()\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():              # model에 loss의 gradient를 계산하지 않음\n",
        "            for (x, y) in test_loader:\n",
        "                cnt += 1\n",
        "                x = x.to(self.device)\n",
        "                label = y['masks'].to(self.device).type(torch.long)\n",
        "\n",
        "                out = self.model(x) \n",
        "                loss = self.loss(out['out'], label)\n",
        "\n",
        "                epoch_loss += loss.to(\"cpu\").item()\n",
        "                      \n",
        "                out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)\n",
        "                out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)\n",
        "\n",
        "                ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long))\n",
        "                ious[1] += self.batch_segmentation_iou(out_target, label)\n",
        "                \n",
        "                if cnt % 10 == 0:\n",
        "                    iou_back = ious[0]/(cnt*x.shape[0])\n",
        "                    iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "                    miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "                    print(f\"Iter: {cnt}/{len(valid_loader)}, test epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n",
        "                    start_time = time.time()  \n",
        "\n",
        "        epoch_loss /= len(test_loader)\n",
        "        \n",
        "        \n",
        "        iou_back = ious[0]/(cnt*x.shape[0])\n",
        "        iou_scratch = ious[1]/(cnt*x.shape[0])\n",
        "        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n",
        "        \n",
        "        print(f\"Test loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n",
        "\n",
        "    \n",
        "    def batch_segmentation_iou(self, outputs, labels):\n",
        "        \"\"\"\n",
        "            outputs, labels : (batch, h, w)\n",
        "        \"\"\"\n",
        "        \n",
        "        SMOOTH = 1e-6\n",
        "\n",
        "        intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "        union = (outputs | labels).float().sum((1, 2))         # Will be zero if both are 0\n",
        "\n",
        "        iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "         # TODO\n",
        "        \n",
        "        #################################################################################################\n",
        "        #                                                                                               #\n",
        "        # TODO : 위 코드를 보고 IoU 를 계산하는 코드를 만들어봅시다.                                    #\n",
        "        # hint : 나누기에서 0으로 나누면 error 가 발생하기 때문에 이를 피하기 위해 분자와 분모에        #\n",
        "        #        아주 작은 수인 SMOOTH 를 더해줍시다                                                    #\n",
        "        #        ex) x / y   --->   (x + SMOOTH) / (y + SMOOTH)                                         #\n",
        "        #                                                                                               #\n",
        "        #################################################################################################\n",
        "        \n",
        "        \n",
        "        return torch.sum(iou).to(\"cpu\").numpy()"
      ],
      "metadata": {
        "id": "dwMGcGm_7nsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "4rJDRICKKdKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "trainer = Semantic_Seg_Trainer(model=seg_model, opt=\"adam\", lr=0.00001, has_scheduler=False, device=device).to(device)\n",
        "start_time = time.time()\n",
        "trainer.train(train_loader, valid_loader, max_epochs=10, disp_epoch=1)\n",
        "print(f\"Training time : {time.time()-start_time:>3f}\")"
      ],
      "metadata": {
        "id": "oop5ZL-pBOUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9269f7f-7752-43d2-de98-30106800173f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Train Start =====\n",
            "Start Train Epoch 0\n",
            "Iter: 10/100, train epcoh loss: 0.011624, miou: 0.898294, iou_back : 0.996143, iou_scratch : 0.800445, time: 2.748799\n",
            "Iter: 20/100, train epcoh loss: 0.013012, miou: 0.888505, iou_back : 0.995272, iou_scratch : 0.781738, time: 2.766579\n",
            "Iter: 30/100, train epcoh loss: 0.014676, miou: 0.883041, iou_back : 0.994641, iou_scratch : 0.771441, time: 2.672173\n",
            "Iter: 40/100, train epcoh loss: 0.016428, miou: 0.878715, iou_back : 0.993805, iou_scratch : 0.763625, time: 2.755768\n",
            "Iter: 50/100, train epcoh loss: 0.017113, miou: 0.878441, iou_back : 0.993614, iou_scratch : 0.763268, time: 2.912046\n",
            "Iter: 60/100, train epcoh loss: 0.017766, miou: 0.883671, iou_back : 0.993338, iou_scratch : 0.774003, time: 2.791805\n",
            "Iter: 70/100, train epcoh loss: 0.017514, miou: 0.882558, iou_back : 0.993372, iou_scratch : 0.771744, time: 2.759471\n",
            "Iter: 80/100, train epcoh loss: 0.017602, miou: 0.883777, iou_back : 0.993387, iou_scratch : 0.774167, time: 2.714564\n",
            "Iter: 90/100, train epcoh loss: 0.017709, miou: 0.884456, iou_back : 0.993364, iou_scratch : 0.775548, time: 2.672051\n",
            "Iter: 100/100, train epcoh loss: 0.017747, miou: 0.883664, iou_back : 0.993399, iou_scratch : 0.773930, time: 2.805607\n",
            "Train loss: 0.017747, miou: 0.883664, iou_back : 0.993399, iou_scratch : 0.773930, time: 27.602211\n",
            "Start Valid Epoch 0\n",
            "Iter: 10/133, valid epcoh loss: 0.002857, miou: 0.774536, iou_back : 0.999073, iou_scratch : 0.550000, time: 1.534406\n",
            "Iter: 20/133, valid epcoh loss: 0.004580, miou: 0.699277, iou_back : 0.998554, iou_scratch : 0.400000, time: 1.496437\n",
            "Iter: 30/133, valid epcoh loss: 0.005083, miou: 0.699207, iou_back : 0.998415, iou_scratch : 0.400000, time: 1.476700\n",
            "Iter: 40/133, valid epcoh loss: 0.139938, miou: 0.696792, iou_back : 0.992707, iou_scratch : 0.400878, time: 1.646326\n",
            "Iter: 50/133, valid epcoh loss: 0.202818, miou: 0.686119, iou_back : 0.989631, iou_scratch : 0.382608, time: 1.779646\n",
            "Iter: 60/133, valid epcoh loss: 0.229132, miou: 0.686595, iou_back : 0.988463, iou_scratch : 0.384727, time: 1.838905\n",
            "Iter: 70/133, valid epcoh loss: 0.336140, miou: 0.681049, iou_back : 0.984376, iou_scratch : 0.377721, time: 1.802118\n",
            "Iter: 80/133, valid epcoh loss: 0.348734, miou: 0.680656, iou_back : 0.982807, iou_scratch : 0.378505, time: 1.830137\n",
            "Iter: 90/133, valid epcoh loss: 0.367413, miou: 0.684971, iou_back : 0.981530, iou_scratch : 0.388413, time: 1.765311\n",
            "Iter: 100/133, valid epcoh loss: 0.409991, miou: 0.684590, iou_back : 0.978792, iou_scratch : 0.390388, time: 1.822191\n",
            "Iter: 110/133, valid epcoh loss: 0.435086, miou: 0.685252, iou_back : 0.977264, iou_scratch : 0.393241, time: 1.885251\n",
            "Iter: 120/133, valid epcoh loss: 0.452682, miou: 0.683900, iou_back : 0.976704, iou_scratch : 0.391096, time: 1.879607\n",
            "Iter: 130/133, valid epcoh loss: 0.477747, miou: 0.681922, iou_back : 0.975749, iou_scratch : 0.388094, time: 1.898026\n",
            "Valid loss: 0.472299, miou: 0.683382, iou_back : 0.975901, iou_scratch : 0.390864, time: 23.228007\n",
            "Epoch: 0, train loss: 0.017747, valid loss: 0.472299, train miou: 0.883664, valid miou: 0.683382, time: 50.832392\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 1\n",
            "Iter: 10/100, train epcoh loss: 0.013706, miou: 0.865516, iou_back : 0.995508, iou_scratch : 0.735525, time: 2.746650\n",
            "Iter: 20/100, train epcoh loss: 0.015340, miou: 0.884607, iou_back : 0.994381, iou_scratch : 0.774832, time: 2.756595\n",
            "Iter: 30/100, train epcoh loss: 0.017631, miou: 0.884792, iou_back : 0.993336, iou_scratch : 0.776247, time: 2.687029\n",
            "Iter: 40/100, train epcoh loss: 0.017243, miou: 0.883248, iou_back : 0.993460, iou_scratch : 0.773036, time: 2.931250\n",
            "Iter: 50/100, train epcoh loss: 0.017444, miou: 0.880023, iou_back : 0.993533, iou_scratch : 0.766514, time: 2.878358\n",
            "Iter: 60/100, train epcoh loss: 0.017794, miou: 0.884480, iou_back : 0.993365, iou_scratch : 0.775594, time: 2.816457\n",
            "Iter: 70/100, train epcoh loss: 0.017903, miou: 0.884459, iou_back : 0.993458, iou_scratch : 0.775460, time: 2.742288\n",
            "Iter: 80/100, train epcoh loss: 0.018102, miou: 0.884113, iou_back : 0.993282, iou_scratch : 0.774943, time: 2.763322\n",
            "Iter: 90/100, train epcoh loss: 0.018232, miou: 0.884677, iou_back : 0.993258, iou_scratch : 0.776095, time: 2.805311\n",
            "Iter: 100/100, train epcoh loss: 0.017589, miou: 0.886974, iou_back : 0.993502, iou_scratch : 0.780445, time: 2.772421\n",
            "Train loss: 0.017589, miou: 0.886974, iou_back : 0.993502, iou_scratch : 0.780445, time: 27.902904\n",
            "Start Valid Epoch 1\n",
            "Iter: 10/133, valid epcoh loss: 0.002864, miou: 0.749492, iou_back : 0.998984, iou_scratch : 0.500000, time: 1.536077\n",
            "Iter: 20/133, valid epcoh loss: 0.004497, miou: 0.699258, iou_back : 0.998515, iou_scratch : 0.400000, time: 1.492927\n",
            "Iter: 30/133, valid epcoh loss: 0.004825, miou: 0.690872, iou_back : 0.998410, iou_scratch : 0.383333, time: 1.477127\n",
            "Iter: 40/133, valid epcoh loss: 0.147628, miou: 0.684484, iou_back : 0.992778, iou_scratch : 0.376191, time: 1.661295\n",
            "Iter: 50/133, valid epcoh loss: 0.211628, miou: 0.677128, iou_back : 0.989593, iou_scratch : 0.364663, time: 1.815423\n",
            "Iter: 60/133, valid epcoh loss: 0.233654, miou: 0.680392, iou_back : 0.988502, iou_scratch : 0.372283, time: 1.854254\n",
            "Iter: 70/133, valid epcoh loss: 0.343617, miou: 0.675590, iou_back : 0.984384, iou_scratch : 0.366796, time: 1.811900\n",
            "Iter: 80/133, valid epcoh loss: 0.355112, miou: 0.675675, iou_back : 0.982751, iou_scratch : 0.368599, time: 1.875394\n",
            "Iter: 90/133, valid epcoh loss: 0.373381, miou: 0.680724, iou_back : 0.981469, iou_scratch : 0.379979, time: 1.787671\n",
            "Iter: 100/133, valid epcoh loss: 0.409464, miou: 0.682248, iou_back : 0.979008, iou_scratch : 0.385489, time: 1.892970\n",
            "Iter: 110/133, valid epcoh loss: 0.435526, miou: 0.683170, iou_back : 0.977415, iou_scratch : 0.388926, time: 1.911706\n",
            "Iter: 120/133, valid epcoh loss: 0.452733, miou: 0.682243, iou_back : 0.976872, iou_scratch : 0.387613, time: 1.931587\n",
            "Iter: 130/133, valid epcoh loss: 0.479445, miou: 0.680117, iou_back : 0.975844, iou_scratch : 0.384390, time: 1.930509\n",
            "Valid loss: 0.473939, miou: 0.681678, iou_back : 0.976003, iou_scratch : 0.387354, time: 23.562533\n",
            "Epoch: 1, train loss: 0.017589, valid loss: 0.473939, train miou: 0.886974, valid miou: 0.681678, time: 52.404491\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 2\n",
            "Iter: 10/100, train epcoh loss: 0.022630, miou: 0.896150, iou_back : 0.990883, iou_scratch : 0.801417, time: 2.807322\n",
            "Iter: 20/100, train epcoh loss: 0.020104, miou: 0.901094, iou_back : 0.992153, iou_scratch : 0.810034, time: 2.749273\n",
            "Iter: 30/100, train epcoh loss: 0.018948, miou: 0.898866, iou_back : 0.992644, iou_scratch : 0.805088, time: 2.732068\n",
            "Iter: 40/100, train epcoh loss: 0.018842, miou: 0.892392, iou_back : 0.992529, iou_scratch : 0.792255, time: 2.830730\n",
            "Iter: 50/100, train epcoh loss: 0.018233, miou: 0.887279, iou_back : 0.993034, iou_scratch : 0.781523, time: 2.856873\n",
            "Iter: 60/100, train epcoh loss: 0.017161, miou: 0.885058, iou_back : 0.993510, iou_scratch : 0.776607, time: 2.782382\n",
            "Iter: 70/100, train epcoh loss: 0.017308, miou: 0.881294, iou_back : 0.993525, iou_scratch : 0.769063, time: 2.765802\n",
            "Iter: 80/100, train epcoh loss: 0.017346, miou: 0.884352, iou_back : 0.993481, iou_scratch : 0.775223, time: 2.737516\n",
            "Iter: 90/100, train epcoh loss: 0.017244, miou: 0.885515, iou_back : 0.993564, iou_scratch : 0.777465, time: 2.743160\n",
            "Iter: 100/100, train epcoh loss: 0.017246, miou: 0.884801, iou_back : 0.993516, iou_scratch : 0.776086, time: 2.737803\n",
            "Train loss: 0.017246, miou: 0.884801, iou_back : 0.993516, iou_scratch : 0.776086, time: 27.745224\n",
            "Start Valid Epoch 2\n",
            "Iter: 10/133, valid epcoh loss: 0.002449, miou: 0.799560, iou_back : 0.999120, iou_scratch : 0.600000, time: 1.522816\n",
            "Iter: 20/133, valid epcoh loss: 0.004082, miou: 0.749310, iou_back : 0.998620, iou_scratch : 0.500000, time: 1.509662\n",
            "Iter: 30/133, valid epcoh loss: 0.004699, miou: 0.715869, iou_back : 0.998404, iou_scratch : 0.433333, time: 1.476527\n",
            "Iter: 40/133, valid epcoh loss: 0.143698, miou: 0.709086, iou_back : 0.992731, iou_scratch : 0.425442, time: 1.646884\n",
            "Iter: 50/133, valid epcoh loss: 0.204106, miou: 0.697237, iou_back : 0.989604, iou_scratch : 0.404870, time: 1.782021\n",
            "Iter: 60/133, valid epcoh loss: 0.228882, miou: 0.696847, iou_back : 0.988510, iou_scratch : 0.405184, time: 1.819611\n",
            "Iter: 70/133, valid epcoh loss: 0.334939, miou: 0.689993, iou_back : 0.984452, iou_scratch : 0.395533, time: 1.807735\n",
            "Iter: 80/133, valid epcoh loss: 0.348054, miou: 0.688559, iou_back : 0.982841, iou_scratch : 0.394278, time: 1.836570\n",
            "Iter: 90/133, valid epcoh loss: 0.366189, miou: 0.692449, iou_back : 0.981656, iou_scratch : 0.403242, time: 1.762984\n",
            "Iter: 100/133, valid epcoh loss: 0.406917, miou: 0.692054, iou_back : 0.979012, iou_scratch : 0.405096, time: 1.881541\n",
            "Iter: 110/133, valid epcoh loss: 0.431229, miou: 0.692117, iou_back : 0.977481, iou_scratch : 0.406754, time: 1.906933\n",
            "Iter: 120/133, valid epcoh loss: 0.449746, miou: 0.690522, iou_back : 0.976931, iou_scratch : 0.404114, time: 1.907645\n",
            "Iter: 130/133, valid epcoh loss: 0.475332, miou: 0.688132, iou_back : 0.975942, iou_scratch : 0.400323, time: 1.929060\n",
            "Valid loss: 0.469762, miou: 0.689589, iou_back : 0.976100, iou_scratch : 0.403077, time: 23.386548\n",
            "Epoch: 2, train loss: 0.017246, valid loss: 0.469762, train miou: 0.884801, valid miou: 0.689589, time: 51.969558\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 3\n",
            "Iter: 10/100, train epcoh loss: 0.015507, miou: 0.866165, iou_back : 0.994753, iou_scratch : 0.737577, time: 2.737332\n",
            "Iter: 20/100, train epcoh loss: 0.016630, miou: 0.871028, iou_back : 0.994622, iou_scratch : 0.747434, time: 2.768933\n",
            "Iter: 30/100, train epcoh loss: 0.018218, miou: 0.877591, iou_back : 0.993638, iou_scratch : 0.761544, time: 2.803484\n",
            "Iter: 40/100, train epcoh loss: 0.017490, miou: 0.883405, iou_back : 0.993902, iou_scratch : 0.772908, time: 2.887569\n",
            "Iter: 50/100, train epcoh loss: 0.017371, miou: 0.885576, iou_back : 0.993806, iou_scratch : 0.777346, time: 2.905805\n",
            "Iter: 60/100, train epcoh loss: 0.017358, miou: 0.886785, iou_back : 0.993710, iou_scratch : 0.779859, time: 2.856863\n",
            "Iter: 70/100, train epcoh loss: 0.017064, miou: 0.891175, iou_back : 0.993717, iou_scratch : 0.788633, time: 2.736945\n",
            "Iter: 80/100, train epcoh loss: 0.017099, miou: 0.890188, iou_back : 0.993610, iou_scratch : 0.786766, time: 2.729049\n",
            "Iter: 90/100, train epcoh loss: 0.017194, miou: 0.889392, iou_back : 0.993577, iou_scratch : 0.785206, time: 2.776094\n",
            "Iter: 100/100, train epcoh loss: 0.017123, miou: 0.888873, iou_back : 0.993652, iou_scratch : 0.784094, time: 2.679522\n",
            "Train loss: 0.017123, miou: 0.888873, iou_back : 0.993652, iou_scratch : 0.784094, time: 27.884034\n",
            "Start Valid Epoch 3\n",
            "Iter: 10/133, valid epcoh loss: 0.002846, miou: 0.749527, iou_back : 0.999054, iou_scratch : 0.500000, time: 1.504188\n",
            "Iter: 20/133, valid epcoh loss: 0.004626, miou: 0.724265, iou_back : 0.998529, iou_scratch : 0.450000, time: 1.477947\n",
            "Iter: 30/133, valid epcoh loss: 0.005306, miou: 0.715832, iou_back : 0.998331, iou_scratch : 0.433333, time: 1.480729\n",
            "Iter: 40/133, valid epcoh loss: 0.140800, miou: 0.709360, iou_back : 0.992669, iou_scratch : 0.426051, time: 1.636822\n",
            "Iter: 50/133, valid epcoh loss: 0.201137, miou: 0.696631, iou_back : 0.989549, iou_scratch : 0.403713, time: 1.792238\n",
            "Iter: 60/133, valid epcoh loss: 0.225195, miou: 0.696603, iou_back : 0.988449, iou_scratch : 0.404757, time: 1.823905\n",
            "Iter: 70/133, valid epcoh loss: 0.326071, miou: 0.690033, iou_back : 0.984377, iou_scratch : 0.395688, time: 1.825679\n",
            "Iter: 80/133, valid epcoh loss: 0.339436, miou: 0.688494, iou_back : 0.982715, iou_scratch : 0.394274, time: 1.837678\n",
            "Iter: 90/133, valid epcoh loss: 0.358746, miou: 0.692314, iou_back : 0.981465, iou_scratch : 0.403163, time: 1.780289\n",
            "Iter: 100/133, valid epcoh loss: 0.397921, miou: 0.691611, iou_back : 0.978754, iou_scratch : 0.404467, time: 1.841659\n",
            "Iter: 110/133, valid epcoh loss: 0.420975, miou: 0.692437, iou_back : 0.977280, iou_scratch : 0.407594, time: 1.906266\n",
            "Iter: 120/133, valid epcoh loss: 0.438518, miou: 0.690899, iou_back : 0.976735, iou_scratch : 0.405062, time: 1.903631\n",
            "Iter: 130/133, valid epcoh loss: 0.463539, miou: 0.688678, iou_back : 0.975761, iou_scratch : 0.401596, time: 1.912758\n",
            "Valid loss: 0.458328, miou: 0.690087, iou_back : 0.975926, iou_scratch : 0.404248, time: 23.302268\n",
            "Epoch: 3, train loss: 0.017123, valid loss: 0.458328, train miou: 0.888873, valid miou: 0.690087, time: 52.037010\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 4\n",
            "Iter: 10/100, train epcoh loss: 0.014380, miou: 0.895235, iou_back : 0.994534, iou_scratch : 0.795935, time: 2.763213\n",
            "Iter: 20/100, train epcoh loss: 0.015038, miou: 0.891543, iou_back : 0.994596, iou_scratch : 0.788490, time: 2.815203\n",
            "Iter: 30/100, train epcoh loss: 0.017550, miou: 0.886965, iou_back : 0.993393, iou_scratch : 0.780538, time: 2.746129\n",
            "Iter: 40/100, train epcoh loss: 0.019054, miou: 0.890877, iou_back : 0.992704, iou_scratch : 0.789051, time: 3.310687\n",
            "Iter: 50/100, train epcoh loss: 0.018809, miou: 0.888928, iou_back : 0.992892, iou_scratch : 0.784965, time: 3.327185\n",
            "Iter: 60/100, train epcoh loss: 0.018801, miou: 0.893195, iou_back : 0.992776, iou_scratch : 0.793614, time: 2.769115\n",
            "Iter: 70/100, train epcoh loss: 0.018232, miou: 0.892233, iou_back : 0.993028, iou_scratch : 0.791438, time: 2.712436\n",
            "Iter: 80/100, train epcoh loss: 0.017589, miou: 0.889414, iou_back : 0.993338, iou_scratch : 0.785489, time: 2.725250\n",
            "Iter: 90/100, train epcoh loss: 0.017103, miou: 0.888073, iou_back : 0.993576, iou_scratch : 0.782569, time: 2.749466\n",
            "Iter: 100/100, train epcoh loss: 0.016950, miou: 0.889301, iou_back : 0.993666, iou_scratch : 0.784936, time: 2.773994\n",
            "Train loss: 0.016950, miou: 0.889301, iou_back : 0.993666, iou_scratch : 0.784936, time: 28.696744\n",
            "Start Valid Epoch 4\n",
            "Iter: 10/133, valid epcoh loss: 0.002878, miou: 0.724521, iou_back : 0.999042, iou_scratch : 0.450000, time: 1.525937\n",
            "Iter: 20/133, valid epcoh loss: 0.004635, miou: 0.724261, iou_back : 0.998522, iou_scratch : 0.450000, time: 1.496660\n",
            "Iter: 30/133, valid epcoh loss: 0.005184, miou: 0.707504, iou_back : 0.998341, iou_scratch : 0.416667, time: 1.487326\n",
            "Iter: 40/133, valid epcoh loss: 0.139043, miou: 0.697525, iou_back : 0.992754, iou_scratch : 0.402296, time: 1.665940\n",
            "Iter: 50/133, valid epcoh loss: 0.204429, miou: 0.686881, iou_back : 0.989446, iou_scratch : 0.384317, time: 1.767808\n",
            "Iter: 60/133, valid epcoh loss: 0.228124, miou: 0.688627, iou_back : 0.988368, iou_scratch : 0.388885, time: 1.833302\n",
            "Iter: 70/133, valid epcoh loss: 0.330503, miou: 0.683289, iou_back : 0.984340, iou_scratch : 0.382238, time: 1.792409\n",
            "Iter: 80/133, valid epcoh loss: 0.343149, miou: 0.682411, iou_back : 0.982671, iou_scratch : 0.382152, time: 1.850280\n",
            "Iter: 90/133, valid epcoh loss: 0.362060, miou: 0.687071, iou_back : 0.981416, iou_scratch : 0.392726, time: 1.785581\n",
            "Iter: 100/133, valid epcoh loss: 0.402571, miou: 0.686727, iou_back : 0.978696, iou_scratch : 0.394758, time: 1.878807\n",
            "Iter: 110/133, valid epcoh loss: 0.426320, miou: 0.687576, iou_back : 0.977161, iou_scratch : 0.397990, time: 1.919124\n",
            "Iter: 120/133, valid epcoh loss: 0.444453, miou: 0.686174, iou_back : 0.976565, iou_scratch : 0.395782, time: 1.887226\n",
            "Iter: 130/133, valid epcoh loss: 0.469220, miou: 0.684088, iou_back : 0.975561, iou_scratch : 0.392616, time: 1.930491\n",
            "Valid loss: 0.463999, miou: 0.685607, iou_back : 0.975733, iou_scratch : 0.395481, time: 23.397442\n",
            "Epoch: 4, train loss: 0.016950, valid loss: 0.463999, train miou: 0.889301, valid miou: 0.685607, time: 52.931541\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 5\n",
            "Iter: 10/100, train epcoh loss: 0.018006, miou: 0.899701, iou_back : 0.992873, iou_scratch : 0.806529, time: 2.810185\n",
            "Iter: 20/100, train epcoh loss: 0.019341, miou: 0.886571, iou_back : 0.992321, iou_scratch : 0.780821, time: 2.738747\n",
            "Iter: 30/100, train epcoh loss: 0.019597, miou: 0.892432, iou_back : 0.992213, iou_scratch : 0.792650, time: 2.779270\n",
            "Iter: 40/100, train epcoh loss: 0.019969, miou: 0.889321, iou_back : 0.992132, iou_scratch : 0.786511, time: 3.025176\n",
            "Iter: 50/100, train epcoh loss: 0.018968, miou: 0.887579, iou_back : 0.992606, iou_scratch : 0.782551, time: 2.781668\n",
            "Iter: 60/100, train epcoh loss: 0.018511, miou: 0.883653, iou_back : 0.992818, iou_scratch : 0.774488, time: 2.718730\n",
            "Iter: 70/100, train epcoh loss: 0.018188, miou: 0.884424, iou_back : 0.993106, iou_scratch : 0.775742, time: 2.732192\n",
            "Iter: 80/100, train epcoh loss: 0.017586, miou: 0.885634, iou_back : 0.993373, iou_scratch : 0.777895, time: 2.759876\n",
            "Iter: 90/100, train epcoh loss: 0.016881, miou: 0.889424, iou_back : 0.993668, iou_scratch : 0.785180, time: 2.694552\n",
            "Iter: 100/100, train epcoh loss: 0.016865, miou: 0.890030, iou_back : 0.993682, iou_scratch : 0.786378, time: 2.796897\n",
            "Train loss: 0.016865, miou: 0.890030, iou_back : 0.993682, iou_scratch : 0.786378, time: 27.840284\n",
            "Start Valid Epoch 5\n",
            "Iter: 10/133, valid epcoh loss: 0.002634, miou: 0.749561, iou_back : 0.999122, iou_scratch : 0.500000, time: 1.511021\n",
            "Iter: 20/133, valid epcoh loss: 0.004529, miou: 0.711791, iou_back : 0.998582, iou_scratch : 0.425000, time: 1.492931\n",
            "Iter: 30/133, valid epcoh loss: 0.005123, miou: 0.707533, iou_back : 0.998400, iou_scratch : 0.416667, time: 1.487638\n",
            "Iter: 40/133, valid epcoh loss: 0.142965, miou: 0.704074, iou_back : 0.992798, iou_scratch : 0.415350, time: 1.650674\n",
            "Iter: 50/133, valid epcoh loss: 0.204610, miou: 0.692867, iou_back : 0.989582, iou_scratch : 0.396153, time: 1.810601\n",
            "Iter: 60/133, valid epcoh loss: 0.228177, miou: 0.693824, iou_back : 0.988495, iou_scratch : 0.399154, time: 1.811796\n",
            "Iter: 70/133, valid epcoh loss: 0.332930, miou: 0.688049, iou_back : 0.984451, iou_scratch : 0.391647, time: 1.812312\n",
            "Iter: 80/133, valid epcoh loss: 0.346080, miou: 0.686576, iou_back : 0.982734, iou_scratch : 0.390418, time: 1.843689\n",
            "Iter: 90/133, valid epcoh loss: 0.365432, miou: 0.690456, iou_back : 0.981468, iou_scratch : 0.399443, time: 1.764546\n",
            "Iter: 100/133, valid epcoh loss: 0.401941, miou: 0.690684, iou_back : 0.978881, iou_scratch : 0.402487, time: 1.847299\n",
            "Iter: 110/133, valid epcoh loss: 0.425810, miou: 0.691664, iou_back : 0.977378, iou_scratch : 0.405949, time: 1.910350\n",
            "Iter: 120/133, valid epcoh loss: 0.444945, miou: 0.690046, iou_back : 0.976781, iou_scratch : 0.403312, time: 1.902457\n",
            "Iter: 130/133, valid epcoh loss: 0.471885, miou: 0.687504, iou_back : 0.975743, iou_scratch : 0.399266, time: 1.926082\n",
            "Valid loss: 0.466651, miou: 0.688913, iou_back : 0.975905, iou_scratch : 0.401922, time: 23.351399\n",
            "Epoch: 5, train loss: 0.016865, valid loss: 0.466651, train miou: 0.890030, valid miou: 0.688913, time: 52.030197\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 6\n",
            "Iter: 10/100, train epcoh loss: 0.013704, miou: 0.876563, iou_back : 0.995143, iou_scratch : 0.757984, time: 2.748109\n",
            "Iter: 20/100, train epcoh loss: 0.014454, miou: 0.885812, iou_back : 0.994725, iou_scratch : 0.776900, time: 2.742945\n",
            "Iter: 30/100, train epcoh loss: 0.015787, miou: 0.892848, iou_back : 0.994438, iou_scratch : 0.791257, time: 2.822294\n",
            "Iter: 40/100, train epcoh loss: 0.016397, miou: 0.893571, iou_back : 0.994136, iou_scratch : 0.793006, time: 2.941915\n",
            "Iter: 50/100, train epcoh loss: 0.016131, miou: 0.899080, iou_back : 0.994169, iou_scratch : 0.803991, time: 2.823736\n",
            "Iter: 60/100, train epcoh loss: 0.015893, miou: 0.897523, iou_back : 0.994192, iou_scratch : 0.800854, time: 2.710490\n",
            "Iter: 70/100, train epcoh loss: 0.017017, miou: 0.896205, iou_back : 0.993584, iou_scratch : 0.798825, time: 2.763941\n",
            "Iter: 80/100, train epcoh loss: 0.016728, miou: 0.892453, iou_back : 0.993759, iou_scratch : 0.791148, time: 2.734291\n",
            "Iter: 90/100, train epcoh loss: 0.016734, miou: 0.890593, iou_back : 0.993811, iou_scratch : 0.787374, time: 2.771635\n",
            "Iter: 100/100, train epcoh loss: 0.016836, miou: 0.889520, iou_back : 0.993764, iou_scratch : 0.785275, time: 2.733782\n",
            "Train loss: 0.016836, miou: 0.889520, iou_back : 0.993764, iou_scratch : 0.785275, time: 27.796263\n",
            "Start Valid Epoch 6\n",
            "Iter: 10/133, valid epcoh loss: 0.002440, miou: 0.774588, iou_back : 0.999177, iou_scratch : 0.550000, time: 1.532851\n",
            "Iter: 20/133, valid epcoh loss: 0.004107, miou: 0.736834, iou_back : 0.998668, iou_scratch : 0.475000, time: 1.498173\n",
            "Iter: 30/133, valid epcoh loss: 0.004674, miou: 0.715926, iou_back : 0.998518, iou_scratch : 0.433333, time: 1.492709\n",
            "Iter: 40/133, valid epcoh loss: 0.147194, miou: 0.715623, iou_back : 0.992814, iou_scratch : 0.438431, time: 1.658966\n",
            "Iter: 50/133, valid epcoh loss: 0.212248, miou: 0.700807, iou_back : 0.989642, iou_scratch : 0.411973, time: 1.797897\n",
            "Iter: 60/133, valid epcoh loss: 0.237769, miou: 0.699570, iou_back : 0.988502, iou_scratch : 0.410639, time: 1.802243\n",
            "Iter: 70/133, valid epcoh loss: 0.348086, miou: 0.692214, iou_back : 0.984399, iou_scratch : 0.400028, time: 1.821147\n",
            "Iter: 80/133, valid epcoh loss: 0.360765, miou: 0.690447, iou_back : 0.982797, iou_scratch : 0.398098, time: 1.834451\n",
            "Iter: 90/133, valid epcoh loss: 0.379032, miou: 0.693584, iou_back : 0.981550, iou_scratch : 0.405618, time: 1.776797\n",
            "Iter: 100/133, valid epcoh loss: 0.420541, miou: 0.692500, iou_back : 0.978846, iou_scratch : 0.406153, time: 1.885633\n",
            "Iter: 110/133, valid epcoh loss: 0.443306, miou: 0.692889, iou_back : 0.977329, iou_scratch : 0.408449, time: 1.937774\n",
            "Iter: 120/133, valid epcoh loss: 0.461481, miou: 0.690976, iou_back : 0.976736, iou_scratch : 0.405216, time: 1.964577\n",
            "Iter: 130/133, valid epcoh loss: 0.488322, miou: 0.688289, iou_back : 0.975698, iou_scratch : 0.400879, time: 1.968380\n",
            "Valid loss: 0.482982, miou: 0.689564, iou_back : 0.975854, iou_scratch : 0.403274, time: 23.554414\n",
            "Epoch: 6, train loss: 0.016836, valid loss: 0.482982, train miou: 0.889520, valid miou: 0.689564, time: 52.183594\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 7\n",
            "Iter: 10/100, train epcoh loss: 0.018464, miou: 0.902069, iou_back : 0.993520, iou_scratch : 0.810618, time: 2.776738\n",
            "Iter: 20/100, train epcoh loss: 0.017569, miou: 0.889483, iou_back : 0.993498, iou_scratch : 0.785468, time: 2.740027\n",
            "Iter: 30/100, train epcoh loss: 0.016670, miou: 0.894551, iou_back : 0.993821, iou_scratch : 0.795281, time: 2.688300\n",
            "Iter: 40/100, train epcoh loss: 0.015841, miou: 0.895631, iou_back : 0.994112, iou_scratch : 0.797151, time: 2.903317\n",
            "Iter: 50/100, train epcoh loss: 0.015529, miou: 0.888193, iou_back : 0.994348, iou_scratch : 0.782039, time: 2.804892\n",
            "Iter: 60/100, train epcoh loss: 0.016353, miou: 0.885150, iou_back : 0.993919, iou_scratch : 0.776381, time: 2.759670\n",
            "Iter: 70/100, train epcoh loss: 0.016175, miou: 0.889467, iou_back : 0.994021, iou_scratch : 0.784913, time: 2.800831\n",
            "Iter: 80/100, train epcoh loss: 0.016600, miou: 0.890541, iou_back : 0.993922, iou_scratch : 0.787161, time: 2.742600\n",
            "Iter: 90/100, train epcoh loss: 0.016654, miou: 0.889695, iou_back : 0.993858, iou_scratch : 0.785532, time: 2.768080\n",
            "Iter: 100/100, train epcoh loss: 0.016708, miou: 0.890772, iou_back : 0.993796, iou_scratch : 0.787748, time: 2.777383\n",
            "Train loss: 0.016708, miou: 0.890772, iou_back : 0.993796, iou_scratch : 0.787748, time: 27.763954\n",
            "Start Valid Epoch 7\n",
            "Iter: 10/133, valid epcoh loss: 0.002351, miou: 0.774592, iou_back : 0.999183, iou_scratch : 0.550000, time: 1.528941\n",
            "Iter: 20/133, valid epcoh loss: 0.004111, miou: 0.749314, iou_back : 0.998627, iou_scratch : 0.500000, time: 1.518795\n",
            "Iter: 30/133, valid epcoh loss: 0.004978, miou: 0.724183, iou_back : 0.998366, iou_scratch : 0.450000, time: 1.505284\n",
            "Iter: 40/133, valid epcoh loss: 0.152841, miou: 0.715302, iou_back : 0.992655, iou_scratch : 0.437949, time: 1.656773\n",
            "Iter: 50/133, valid epcoh loss: 0.214979, miou: 0.700846, iou_back : 0.989503, iou_scratch : 0.412189, time: 1.849102\n",
            "Iter: 60/133, valid epcoh loss: 0.239727, miou: 0.699906, iou_back : 0.988403, iou_scratch : 0.411410, time: 1.840576\n",
            "Iter: 70/133, valid epcoh loss: 0.354550, miou: 0.692049, iou_back : 0.984224, iou_scratch : 0.399873, time: 1.840370\n",
            "Iter: 80/133, valid epcoh loss: 0.365178, miou: 0.690386, iou_back : 0.982633, iou_scratch : 0.398139, time: 1.885060\n",
            "Iter: 90/133, valid epcoh loss: 0.381266, miou: 0.693872, iou_back : 0.981456, iou_scratch : 0.406287, time: 1.803952\n",
            "Iter: 100/133, valid epcoh loss: 0.422830, miou: 0.692729, iou_back : 0.978780, iou_scratch : 0.406677, time: 1.867594\n",
            "Iter: 110/133, valid epcoh loss: 0.447602, miou: 0.692738, iou_back : 0.977229, iou_scratch : 0.408246, time: 1.921544\n",
            "Iter: 120/133, valid epcoh loss: 0.466430, miou: 0.691049, iou_back : 0.976672, iou_scratch : 0.405426, time: 1.911550\n",
            "Iter: 130/133, valid epcoh loss: 0.494777, miou: 0.688085, iou_back : 0.975597, iou_scratch : 0.400574, time: 1.923140\n",
            "Valid loss: 0.489313, miou: 0.689390, iou_back : 0.975754, iou_scratch : 0.403026, time: 23.626676\n",
            "Epoch: 7, train loss: 0.016708, valid loss: 0.489313, train miou: 0.890772, valid miou: 0.689390, time: 52.252645\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 8\n",
            "Iter: 10/100, train epcoh loss: 0.013676, miou: 0.878210, iou_back : 0.995323, iou_scratch : 0.761098, time: 2.771028\n",
            "Iter: 20/100, train epcoh loss: 0.016941, miou: 0.876623, iou_back : 0.993774, iou_scratch : 0.759473, time: 2.776915\n",
            "Iter: 30/100, train epcoh loss: 0.017780, miou: 0.888042, iou_back : 0.993468, iou_scratch : 0.782616, time: 2.774261\n",
            "Iter: 40/100, train epcoh loss: 0.017475, miou: 0.893181, iou_back : 0.993786, iou_scratch : 0.792576, time: 2.935415\n",
            "Iter: 50/100, train epcoh loss: 0.016524, miou: 0.893531, iou_back : 0.994030, iou_scratch : 0.793032, time: 2.883524\n",
            "Iter: 60/100, train epcoh loss: 0.016899, miou: 0.885273, iou_back : 0.993762, iou_scratch : 0.776784, time: 2.752100\n",
            "Iter: 70/100, train epcoh loss: 0.017067, miou: 0.883833, iou_back : 0.993651, iou_scratch : 0.774016, time: 2.819359\n",
            "Iter: 80/100, train epcoh loss: 0.016832, miou: 0.885932, iou_back : 0.993739, iou_scratch : 0.778125, time: 2.743408\n",
            "Iter: 90/100, train epcoh loss: 0.016729, miou: 0.889648, iou_back : 0.993761, iou_scratch : 0.785535, time: 2.745429\n",
            "Iter: 100/100, train epcoh loss: 0.016630, miou: 0.891426, iou_back : 0.993791, iou_scratch : 0.789062, time: 2.770501\n",
            "Train loss: 0.016630, miou: 0.891426, iou_back : 0.993791, iou_scratch : 0.789062, time: 27.975326\n",
            "Start Valid Epoch 8\n",
            "Iter: 10/133, valid epcoh loss: 0.002586, miou: 0.799562, iou_back : 0.999124, iou_scratch : 0.600000, time: 1.551205\n",
            "Iter: 20/133, valid epcoh loss: 0.004387, miou: 0.761784, iou_back : 0.998568, iou_scratch : 0.525000, time: 1.520547\n",
            "Iter: 30/133, valid epcoh loss: 0.005313, miou: 0.732473, iou_back : 0.998280, iou_scratch : 0.466667, time: 1.538493\n",
            "Iter: 40/133, valid epcoh loss: 0.148785, miou: 0.721613, iou_back : 0.992623, iou_scratch : 0.450603, time: 1.690530\n",
            "Iter: 50/133, valid epcoh loss: 0.212482, miou: 0.706202, iou_back : 0.989478, iou_scratch : 0.422927, time: 2.411855\n",
            "Iter: 60/133, valid epcoh loss: 0.238080, miou: 0.704646, iou_back : 0.988415, iou_scratch : 0.420877, time: 2.464637\n",
            "Iter: 70/133, valid epcoh loss: 0.347451, miou: 0.696143, iou_back : 0.984283, iou_scratch : 0.408004, time: 1.824360\n",
            "Iter: 80/133, valid epcoh loss: 0.360933, miou: 0.693643, iou_back : 0.982690, iou_scratch : 0.404596, time: 1.879945\n",
            "Iter: 90/133, valid epcoh loss: 0.380713, miou: 0.696854, iou_back : 0.981485, iou_scratch : 0.412223, time: 1.801095\n",
            "Iter: 100/133, valid epcoh loss: 0.422934, miou: 0.695575, iou_back : 0.978842, iou_scratch : 0.412308, time: 1.885263\n",
            "Iter: 110/133, valid epcoh loss: 0.446110, miou: 0.695561, iou_back : 0.977338, iou_scratch : 0.413784, time: 1.942737\n",
            "Iter: 120/133, valid epcoh loss: 0.464996, miou: 0.693435, iou_back : 0.976726, iou_scratch : 0.410145, time: 1.915818\n",
            "Iter: 130/133, valid epcoh loss: 0.493902, miou: 0.690512, iou_back : 0.975686, iou_scratch : 0.405339, time: 1.999887\n",
            "Valid loss: 0.488643, miou: 0.691795, iou_back : 0.975854, iou_scratch : 0.407737, time: 25.022322\n",
            "Epoch: 8, train loss: 0.016630, valid loss: 0.488643, train miou: 0.891426, valid miou: 0.691795, time: 53.943837\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Train Epoch 9\n",
            "Iter: 10/100, train epcoh loss: 0.014600, miou: 0.903922, iou_back : 0.994549, iou_scratch : 0.813295, time: 2.767424\n",
            "Iter: 20/100, train epcoh loss: 0.015327, miou: 0.902668, iou_back : 0.994266, iou_scratch : 0.811071, time: 2.867991\n",
            "Iter: 30/100, train epcoh loss: 0.016184, miou: 0.896010, iou_back : 0.994014, iou_scratch : 0.798006, time: 2.779943\n",
            "Iter: 40/100, train epcoh loss: 0.016642, miou: 0.893927, iou_back : 0.993782, iou_scratch : 0.794072, time: 2.986540\n",
            "Iter: 50/100, train epcoh loss: 0.017331, miou: 0.892874, iou_back : 0.993456, iou_scratch : 0.792293, time: 2.939770\n",
            "Iter: 60/100, train epcoh loss: 0.018137, miou: 0.892382, iou_back : 0.993202, iou_scratch : 0.791562, time: 2.841697\n",
            "Iter: 70/100, train epcoh loss: 0.017809, miou: 0.892511, iou_back : 0.993362, iou_scratch : 0.791661, time: 2.809532\n",
            "Iter: 80/100, train epcoh loss: 0.017232, miou: 0.892402, iou_back : 0.993571, iou_scratch : 0.791233, time: 2.744537\n",
            "Iter: 90/100, train epcoh loss: 0.016595, miou: 0.891885, iou_back : 0.993864, iou_scratch : 0.789907, time: 2.713789\n",
            "Iter: 100/100, train epcoh loss: 0.016606, miou: 0.891244, iou_back : 0.993827, iou_scratch : 0.788661, time: 2.784374\n",
            "Train loss: 0.016606, miou: 0.891244, iou_back : 0.993827, iou_scratch : 0.788661, time: 28.238734\n",
            "Start Valid Epoch 9\n",
            "Iter: 10/133, valid epcoh loss: 0.002312, miou: 0.799602, iou_back : 0.999204, iou_scratch : 0.600000, time: 1.511754\n",
            "Iter: 20/133, valid epcoh loss: 0.003883, miou: 0.774360, iou_back : 0.998720, iou_scratch : 0.550000, time: 1.469032\n",
            "Iter: 30/133, valid epcoh loss: 0.004629, miou: 0.740914, iou_back : 0.998494, iou_scratch : 0.483333, time: 1.462364\n",
            "Iter: 40/133, valid epcoh loss: 0.153873, miou: 0.734037, iou_back : 0.992837, iou_scratch : 0.475236, time: 1.650412\n",
            "Iter: 50/133, valid epcoh loss: 0.216763, miou: 0.715605, iou_back : 0.989768, iou_scratch : 0.441442, time: 1.809142\n",
            "Iter: 60/133, valid epcoh loss: 0.243017, miou: 0.711756, iou_back : 0.988634, iou_scratch : 0.434878, time: 1.836737\n",
            "Iter: 70/133, valid epcoh loss: 0.358872, miou: 0.701977, iou_back : 0.984464, iou_scratch : 0.419491, time: 1.800959\n",
            "Iter: 80/133, valid epcoh loss: 0.372544, miou: 0.698908, iou_back : 0.982919, iou_scratch : 0.414896, time: 1.823923\n",
            "Iter: 90/133, valid epcoh loss: 0.391433, miou: 0.701126, iou_back : 0.981718, iou_scratch : 0.420533, time: 1.802442\n",
            "Iter: 100/133, valid epcoh loss: 0.432642, miou: 0.699621, iou_back : 0.979107, iou_scratch : 0.420135, time: 1.846340\n",
            "Iter: 110/133, valid epcoh loss: 0.457456, miou: 0.698826, iou_back : 0.977576, iou_scratch : 0.420077, time: 1.919321\n",
            "Iter: 120/133, valid epcoh loss: 0.476417, miou: 0.696294, iou_back : 0.976983, iou_scratch : 0.415605, time: 1.912681\n",
            "Iter: 130/133, valid epcoh loss: 0.505257, miou: 0.692807, iou_back : 0.975907, iou_scratch : 0.409707, time: 1.943490\n",
            "Valid loss: 0.499475, miou: 0.694067, iou_back : 0.976074, iou_scratch : 0.412059, time: 23.376031\n",
            "Epoch: 9, train loss: 0.016606, valid loss: 0.499475, train miou: 0.891244, valid miou: 0.694067, time: 52.480543\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time : 523.916588\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(f'{root}/logs/checkpoint-10.pth')\n",
        "seg_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "checkpoint_epoch = checkpoint[\"epoch\"]\n",
        "checkpoint_description = checkpoint[\"desription\"]\n",
        "checkpoint_model_state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "print(checkpoint_description)\n",
        "print(checkpoint_model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQRMMAfLCzfi",
        "outputId": "51b4c9c9-8cea-44ad-bdd7-837a624bcbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0124]],\n",
            "\n",
            "         [[-0.0268]],\n",
            "\n",
            "         [[-0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0060]],\n",
            "\n",
            "         [[ 0.0038]],\n",
            "\n",
            "         [[-0.0130]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158]],\n",
            "\n",
            "         [[-0.0180]],\n",
            "\n",
            "         [[ 0.0106]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[ 0.0106]],\n",
            "\n",
            "         [[-0.0244]]],\n",
            "\n",
            "\n",
            "        [[[-0.0185]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[ 0.0174]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[ 0.0128]]]], device='cuda:0')), ('backbone.layer4.1.bn1.weight', tensor([0.1228, 0.1083, 0.1145, 0.1457, 0.1256, 0.1241, 0.1867, 0.1034, 0.0887,\n",
            "        0.1184, 0.1088, 0.1299, 0.1284, 0.0956, 0.1165, 0.1364, 0.1069, 0.1335,\n",
            "        0.1050, 0.1340, 0.1057, 0.1195, 0.1053, 0.1423, 0.1159, 0.1141, 0.0793,\n",
            "        0.1023, 0.1461, 0.1044, 0.0965, 0.1317, 0.1477, 0.0953, 0.1071, 0.0753,\n",
            "        0.1105, 0.1146, 0.1005, 0.1301, 0.1059, 0.0983, 0.1362, 0.1194, 0.0779,\n",
            "        0.1233, 0.1374, 0.0969, 0.0904, 0.1131, 0.1098, 0.1461, 0.1363, 0.0986,\n",
            "        0.1254, 0.1103, 0.1298, 0.1376, 0.1177, 0.1174, 0.1032, 0.1004, 0.1282,\n",
            "        0.1122, 0.1302, 0.1185, 0.1176, 0.1242, 0.1079, 0.1388, 0.0950, 0.1169,\n",
            "        0.1344, 0.0874, 0.1245, 0.1014, 0.1529, 0.0927, 0.1329, 0.1343, 0.1139,\n",
            "        0.1221, 0.1074, 0.1111, 0.1436, 0.1121, 0.1417, 0.1045, 0.1278, 0.1418,\n",
            "        0.1048, 0.1209, 0.1291, 0.1350, 0.1291, 0.1124, 0.1534, 0.1257, 0.1186,\n",
            "        0.1359, 0.1096, 0.1352, 0.1090, 0.1534, 0.1257, 0.1262, 0.1109, 0.1465,\n",
            "        0.1957, 0.1206, 0.1081, 0.1337, 0.1251, 0.0873, 0.1229, 0.1385, 0.1189,\n",
            "        0.1344, 0.1095, 0.1147, 0.1288, 0.1462, 0.1168, 0.0971, 0.1129, 0.1095,\n",
            "        0.1193, 0.1321, 0.0939, 0.1007, 0.1019, 0.0900, 0.1059, 0.1404, 0.1258,\n",
            "        0.1020, 0.1297, 0.1033, 0.1298, 0.1235, 0.1389, 0.1280, 0.1284, 0.1068,\n",
            "        0.1174, 0.1442, 0.0823, 0.1342, 0.1188, 0.1021, 0.1159, 0.0930, 0.0980,\n",
            "        0.1053, 0.1492, 0.1323, 0.1486, 0.1104, 0.1097, 0.1193, 0.0871, 0.1309,\n",
            "        0.1048, 0.1216, 0.1383, 0.1418, 0.1278, 0.0971, 0.1310, 0.1209, 0.1021,\n",
            "        0.0968, 0.1393, 0.1038, 0.0953, 0.0978, 0.1197, 0.1376, 0.1175, 0.0780,\n",
            "        0.1344, 0.0957, 0.1130, 0.1244, 0.1337, 0.1204, 0.1183, 0.1265, 0.1005,\n",
            "        0.1244, 0.1199, 0.1125, 0.1125, 0.1272, 0.0957, 0.1139, 0.1106, 0.0645,\n",
            "        0.1170, 0.0890, 0.0961, 0.0685, 0.1300, 0.1140, 0.1651, 0.1220, 0.1521,\n",
            "        0.0987, 0.1102, 0.1041, 0.1265, 0.1219, 0.1242, 0.1216, 0.1116, 0.1187,\n",
            "        0.1080, 0.0985, 0.1023, 0.0993, 0.1178, 0.1436, 0.1029, 0.1270, 0.1062,\n",
            "        0.1276, 0.0920, 0.1335, 0.1060, 0.1425, 0.1274, 0.0957, 0.0983, 0.1206,\n",
            "        0.0957, 0.0965, 0.1207, 0.0670, 0.1926, 0.1435, 0.1521, 0.1400, 0.0949,\n",
            "        0.1423, 0.1196, 0.1027, 0.1324, 0.1401, 0.1165, 0.1114, 0.1336, 0.1514,\n",
            "        0.1834, 0.1199, 0.1326, 0.1404, 0.1359, 0.1408, 0.0986, 0.1183, 0.0974,\n",
            "        0.1127, 0.1052, 0.0929, 0.1160, 0.1044, 0.1117, 0.1379, 0.1339, 0.1237,\n",
            "        0.1169, 0.1296, 0.1429, 0.1487, 0.1129, 0.1116, 0.0968, 0.1177, 0.1105,\n",
            "        0.1164, 0.1126, 0.1318, 0.1194, 0.1026, 0.0932, 0.0978, 0.1240, 0.1065,\n",
            "        0.0983, 0.1090, 0.1161, 0.1014, 0.1369, 0.1067, 0.1137, 0.1003, 0.1137,\n",
            "        0.1212, 0.1069, 0.1152, 0.1313, 0.1202, 0.1190, 0.1351, 0.0932, 0.1237,\n",
            "        0.1092, 0.1019, 0.1069, 0.1212, 0.0908, 0.0812, 0.0935, 0.1015, 0.1752,\n",
            "        0.1130, 0.1079, 0.1238, 0.1176, 0.0946, 0.1143, 0.1222, 0.1210, 0.1050,\n",
            "        0.0778, 0.1119, 0.1317, 0.0850, 0.0988, 0.1151, 0.1108, 0.1113, 0.1091,\n",
            "        0.1290, 0.1352, 0.1454, 0.1110, 0.1243, 0.1161, 0.1251, 0.0972, 0.1099,\n",
            "        0.1273, 0.1108, 0.0947, 0.1261, 0.1154, 0.0969, 0.1154, 0.1094, 0.1491,\n",
            "        0.1065, 0.1331, 0.1157, 0.1191, 0.1005, 0.0935, 0.1112, 0.1044, 0.1381,\n",
            "        0.1077, 0.1353, 0.0846, 0.1174, 0.1421, 0.1301, 0.1022, 0.1097, 0.1269,\n",
            "        0.1468, 0.1335, 0.1173, 0.1042, 0.1287, 0.1186, 0.1300, 0.1252, 0.1386,\n",
            "        0.1239, 0.1146, 0.0990, 0.1230, 0.1265, 0.0893, 0.1200, 0.1121, 0.1200,\n",
            "        0.2378, 0.1198, 0.1227, 0.1026, 0.1109, 0.1306, 0.1210, 0.1120, 0.1319,\n",
            "        0.1133, 0.1277, 0.1158, 0.0916, 0.1487, 0.0336, 0.0973, 0.0871, 0.0674,\n",
            "        0.1315, 0.1378, 0.1369, 0.1233, 0.1299, 0.1250, 0.1415, 0.1203, 0.1199,\n",
            "        0.1447, 0.1002, 0.1423, 0.1056, 0.1226, 0.0854, 0.1131, 0.1186, 0.1277,\n",
            "        0.1087, 0.1065, 0.1246, 0.1306, 0.1109, 0.1299, 0.1137, 0.0728, 0.1230,\n",
            "        0.1089, 0.1331, 0.1304, 0.0961, 0.1067, 0.1105, 0.1137, 0.1092, 0.1367,\n",
            "        0.1250, 0.1300, 0.1305, 0.1433, 0.1007, 0.1421, 0.1344, 0.1280, 0.0949,\n",
            "        0.1326, 0.1180, 0.1322, 0.0954, 0.1394, 0.1025, 0.1091, 0.1122, 0.1025,\n",
            "        0.1209, 0.1441, 0.1310, 0.1224, 0.1047, 0.0920, 0.1406, 0.1422, 0.1069,\n",
            "        0.1095, 0.0927, 0.1048, 0.1213, 0.1169, 0.1311, 0.1304, 0.1077, 0.1133,\n",
            "        0.0768, 0.1173, 0.0685, 0.1276, 0.1075, 0.1003, 0.1170, 0.1436, 0.1387,\n",
            "        0.1331, 0.1061, 0.1074, 0.1098, 0.1172, 0.1398, 0.0988, 0.0860, 0.1330,\n",
            "        0.1505, 0.1244, 0.1164, 0.1182, 0.1125, 0.0751, 0.1449, 0.1273, 0.1234,\n",
            "        0.1405, 0.1480, 0.1124, 0.1240, 0.1759, 0.1447, 0.1409, 0.1349],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn1.bias', tensor([-0.0763, -0.0845, -0.0609, -0.1123, -0.1206, -0.0418, -0.0389, -0.0730,\n",
            "        -0.1181, -0.0696, -0.1437, -0.0828, -0.1012, -0.1092, -0.0871, -0.0906,\n",
            "        -0.0814, -0.1127, -0.0490, -0.1119, -0.0864, -0.1321, -0.0547, -0.1007,\n",
            "        -0.1035, -0.1364, -0.1249, -0.0884,  0.0156, -0.0923, -0.0895, -0.1007,\n",
            "        -0.1281, -0.0711, -0.0929, -0.0261, -0.1005, -0.0635, -0.0881, -0.0678,\n",
            "         0.0125, -0.1197, -0.1173, -0.0611, -0.1156, -0.1163, -0.1007, -0.1031,\n",
            "        -0.0681, -0.0842, -0.0403, -0.1249, -0.1032, -0.0538, -0.1260, -0.0922,\n",
            "        -0.0986, -0.0936, -0.1017, -0.0962, -0.0797, -0.1078, -0.0712, -0.0942,\n",
            "        -0.1248, -0.1011, -0.0743, -0.0134, -0.1350, -0.1279, -0.0643, -0.1164,\n",
            "        -0.0958, -0.0736, -0.1141, -0.1093, -0.0910, -0.0759, -0.1165,  0.1252,\n",
            "        -0.1066, -0.1362, -0.0955, -0.0691, -0.0816, -0.1221, -0.1020, -0.0854,\n",
            "        -0.1060, -0.0924, -0.1122, -0.1092, -0.1194, -0.0992, -0.1397, -0.1131,\n",
            "        -0.0802, -0.1019, -0.0692, -0.0578, -0.0708, -0.1007, -0.1179, -0.0302,\n",
            "        -0.1080, -0.1123, -0.0855, -0.0883, -0.1168, -0.0528, -0.0695, -0.0947,\n",
            "        -0.1025, -0.0736, -0.0794, -0.0731, -0.1000, -0.0895, -0.0722, -0.1057,\n",
            "        -0.1234, -0.1050, -0.0444, -0.1074, -0.0962, -0.1122, -0.0837, -0.1333,\n",
            "        -0.1003, -0.1360, -0.0922, -0.0203, -0.0582, -0.1332, -0.0744, -0.0356,\n",
            "        -0.1032, -0.0289, -0.0801, -0.0215, -0.1310, -0.1022, -0.1022, -0.0737,\n",
            "        -0.0563, -0.1405,  0.0314, -0.1039, -0.1262, -0.1027, -0.1115, -0.0284,\n",
            "        -0.0865, -0.0808, -0.0951, -0.1022, -0.0989, -0.0892, -0.0481, -0.1059,\n",
            "        -0.0903, -0.0916, -0.0542, -0.0853, -0.1266, -0.1005, -0.0269, -0.0676,\n",
            "        -0.1152, -0.0821, -0.0935, -0.0580, -0.0620, -0.0940, -0.0615, -0.0712,\n",
            "        -0.0934, -0.0179, -0.0963, -0.1101, -0.0901, -0.0707, -0.0673, -0.0003,\n",
            "        -0.1337, -0.0750, -0.1279, -0.1171, -0.1080, -0.1124, -0.0667, -0.1025,\n",
            "        -0.0958, -0.0891, -0.1040, -0.1347, -0.0711, -0.0421, -0.0890, -0.0631,\n",
            "        -0.1031, -0.0590, -0.1246, -0.0995, -0.1002, -0.0871, -0.1210, -0.0889,\n",
            "        -0.0868, -0.0778, -0.0960, -0.0713, -0.1129, -0.1559, -0.0938, -0.1235,\n",
            "        -0.0233, -0.1161, -0.1202, -0.0655, -0.0971, -0.0896, -0.1023, -0.1076,\n",
            "        -0.0915, -0.0461, -0.0691, -0.1324, -0.1777, -0.1063, -0.1358, -0.1104,\n",
            "        -0.0570, -0.1059, -0.0788, -0.0882, -0.1169, -0.0487, -0.1872, -0.1093,\n",
            "        -0.1212, -0.0512, -0.0342, -0.1079, -0.1223, -0.0861, -0.0822, -0.0553,\n",
            "        -0.0864, -0.0570, -0.0825, -0.0965,  0.1416, -0.0757, -0.0972, -0.1024,\n",
            "        -0.1138, -0.0960, -0.0946, -0.1004, -0.1105, -0.0613, -0.0896, -0.1082,\n",
            "        -0.0915, -0.0542, -0.1049, -0.1126, -0.1193, -0.0908, -0.0636, -0.1016,\n",
            "        -0.0310, -0.0618, -0.1170, -0.1231, -0.0761, -0.0859, -0.0463, -0.0679,\n",
            "        -0.1053, -0.0861, -0.0930, -0.0199, -0.1256, -0.1002, -0.0981, -0.0525,\n",
            "        -0.0545, -0.0807, -0.1053, -0.0859, -0.1151, -0.0885, -0.0903, -0.0805,\n",
            "        -0.0662, -0.0752,  0.0108, -0.1014, -0.1272, -0.0948, -0.0783, -0.1038,\n",
            "        -0.0647, -0.1096, -0.1095, -0.1042, -0.0903, -0.1028, -0.0413, -0.0735,\n",
            "        -0.0659, -0.1073, -0.1300, -0.1181, -0.1136, -0.0948, -0.0529, -0.1160,\n",
            "        -0.0793, -0.1228, -0.0689, -0.1228, -0.1230, -0.0854, -0.0678, -0.0425,\n",
            "        -0.0511, -0.1097, -0.1145, -0.0720, -0.0880, -0.1066, -0.1174, -0.1097,\n",
            "        -0.1180, -0.0579, -0.0793, -0.1327, -0.1144, -0.1217, -0.0958, -0.0879,\n",
            "        -0.0497, -0.1077, -0.0970, -0.1041, -0.0926, -0.1091, -0.0509, -0.0988,\n",
            "        -0.1110, -0.0943, -0.1078, -0.0821, -0.0938, -0.1156, -0.0679, -0.0988,\n",
            "        -0.1042, -0.0859, -0.1132, -0.1145, -0.1003, -0.1257, -0.0626, -0.1058,\n",
            "        -0.0618, -0.1173, -0.1102, -0.0958, -0.0518, -0.0733, -0.1091, -0.0918,\n",
            "        -0.0976, -0.0405, -0.0801, -0.1018, -0.0748, -0.1092, -0.0947, -0.0754,\n",
            "        -0.0750, -0.1387, -0.0433, -0.0100, -0.0844, -0.1153, -0.0865, -0.0659,\n",
            "        -0.0880, -0.1210, -0.0784, -0.0864, -0.0927, -0.1098, -0.0860, -0.0578,\n",
            "        -0.1122,  0.0034, -0.0691, -0.0458, -0.0775, -0.0901, -0.2013, -0.0789,\n",
            "        -0.0856, -0.1073, -0.0690, -0.0711, -0.0865, -0.0915, -0.0900, -0.0961,\n",
            "        -0.1375, -0.0776, -0.0913, -0.0872, -0.0954, -0.0543, -0.0961, -0.0587,\n",
            "        -0.0693, -0.0856, -0.1110, -0.1173, -0.1080, -0.0728, -0.0099, -0.0519,\n",
            "        -0.1318, -0.0680, -0.1214, -0.1063, -0.0894, -0.0814, -0.0893, -0.1330,\n",
            "        -0.0462, -0.1078, -0.1259, -0.1358, -0.1060, -0.1207, -0.1425, -0.0893,\n",
            "        -0.0784, -0.0843, -0.0976, -0.0820, -0.0728, -0.0447, -0.0645, -0.0865,\n",
            "        -0.0881, -0.0360, -0.1002, -0.1059, -0.1064, -0.0960, -0.1152, -0.0899,\n",
            "        -0.1161, -0.0744, -0.0972, -0.0536, -0.0808,  0.0852, -0.1367, -0.1205,\n",
            "        -0.0976, -0.0962, -0.1247, -0.0975, -0.0834, -0.1275, -0.1176, -0.0763,\n",
            "        -0.0958, -0.1132, -0.0690, -0.0708, -0.1413, -0.1114, -0.0678, -0.0480,\n",
            "        -0.0435, -0.1073, -0.0888, -0.1279, -0.0438, -0.0617, -0.1224, -0.0781,\n",
            "        -0.0823, -0.1088, -0.0683, -0.1038, -0.0232, -0.0594, -0.0906, -0.0944,\n",
            "        -0.0962, -0.1323, -0.0963, -0.0566, -0.1743, -0.0954, -0.1598, -0.1304],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn1.running_mean', tensor([-0.2342, -0.3894, -0.2239, -0.0866, -0.0083, -0.2248, -0.0068,  0.0914,\n",
            "        -0.1800, -0.1131, -0.1635, -0.1224, -0.2872, -0.1157, -0.1801, -0.1133,\n",
            "        -0.2443, -0.2058, -0.3231, -0.2031, -0.1992, -0.3977, -0.4058, -0.1366,\n",
            "        -0.0315, -0.0776, -0.4288, -0.2111,  0.3683, -0.1456, -0.2240, -0.3479,\n",
            "        -0.1287, -0.1493, -0.3715, -0.2170, -0.3149, -0.3956,  0.2318, -0.2801,\n",
            "        -0.3786,  0.0308, -0.0807,  0.0894,  0.3761, -0.3388,  0.0263, -0.0620,\n",
            "        -0.4477, -0.6331, -0.0380, -0.2183, -0.0980, -0.0631, -0.0364, -0.3839,\n",
            "        -0.1719, -0.1522,  0.0098,  0.1129, -0.5966, -0.5914, -0.1863, -0.1742,\n",
            "        -0.1342, -0.2871, -0.6859, -0.2357, -0.1902, -0.1748, -0.6361, -0.1922,\n",
            "        -0.0934, -0.4074, -0.4414, -0.2759, -0.0298, -0.3893, -0.3666, -0.4612,\n",
            "        -0.6241, -0.2096, -0.1059, -0.2029, -0.1080, -0.2036, -0.1183, -0.2907,\n",
            "        -0.1093, -0.2025, -0.0222,  0.0472, -0.2691, -0.2946, -0.2580, -0.0564,\n",
            "        -0.2364, -0.2232, -0.3519, -0.3632, -0.2662, -0.1845, -0.1585,  0.2434,\n",
            "         0.0787, -0.0055, -0.1594, -0.2402, -0.3501, -0.1947, -0.4137, -0.2419,\n",
            "         0.1086, -0.5247, -0.0369, -0.1890, -0.2766, -0.1454, -0.2309, -0.3527,\n",
            "         0.0779, -0.0506, -0.1254, -0.2622, -0.3710,  0.0595,  0.0948, -0.1498,\n",
            "        -0.0605,  0.4773, -0.4311, -0.2942, -0.2363,  0.0358,  0.1503, -0.4211,\n",
            "        -0.2814, -0.3824, -0.4141, -0.2436,  0.0581, -0.5744, -0.2134, -0.1880,\n",
            "        -0.0779, -0.5085, -0.2248, -0.1312, -0.2776, -0.1922, -0.1052, -0.1756,\n",
            "        -0.1077, -0.0347, -0.1228, -0.1981, -0.0625, -0.4555, -0.0967, -0.4788,\n",
            "        -0.2410, -0.0954,  0.1175, -0.3662, -0.1299, -0.1314, -0.1918, -0.2269,\n",
            "        -0.3198, -0.1212, -0.4214, -0.1820, -0.0821, -0.2640, -0.1113, -0.1904,\n",
            "        -0.3455, -0.3007, -0.1564, -0.1996, -0.5377, -0.5504, -0.1301, -0.5654,\n",
            "        -0.2018,  0.0972, -0.1807, -0.1821, -0.0862, -0.2195,  0.0901, -0.0041,\n",
            "        -0.1964, -0.5089, -0.2280, -0.1109, -0.2124, -0.5410, -0.2812, -0.3826,\n",
            "        -0.6022, -0.4537,  0.0049, -0.4263, -0.2645, -0.0875, -0.1198, -0.3221,\n",
            "        -0.5490, -0.2218, -0.3036, -0.3722, -0.1357, -0.1603, -0.4566, -0.1879,\n",
            "        -0.2628, -0.1086, -0.0431, -0.0969, -0.1611, -0.2586, -0.2868, -0.2723,\n",
            "        -0.2008, -0.1044, -0.1370, -0.3766,  0.2582, -0.1152, -0.1090, -0.0881,\n",
            "        -0.2376, -0.1927, -0.1507, -0.0819, -0.0538, -0.2907, -0.1012, -0.0758,\n",
            "         0.1703, -0.2485, -0.3660, -0.1486,  0.0734, -0.3303, -0.2135, -0.0136,\n",
            "        -0.2174, -0.1161, -0.2131, -0.2348, -0.1387, -0.3214, -0.5423, -0.0450,\n",
            "        -0.0237, -0.0159, -0.1145, -0.2890, -0.3526, -0.2064, -0.1020, -0.4839,\n",
            "        -0.2697, -0.3727,  0.1139, -0.1906, -0.3676,  0.0398, -0.2852, -0.2968,\n",
            "        -0.4666, -0.1486,  0.0142, -0.3491, -0.0910, -0.1168, -0.1797, -0.3382,\n",
            "        -0.1001, -0.1022, -0.1976, -0.1739, -0.0648, -0.0815, -0.1889, -0.1906,\n",
            "        -0.3756, -0.2667, -0.3019, -0.3394,  0.0737, -0.1420, -0.1242, -0.3041,\n",
            "        -0.2124, -0.3175, -0.4164, -0.4167,  0.0308, -0.1474, -0.1541, -0.1242,\n",
            "        -0.2053, -0.4041, -0.6463, -0.1357, -0.4678, -0.0607, -0.2147, -0.0331,\n",
            "        -0.4015,  0.0845, -0.0416,  0.1380, -0.2181, -0.2993, -0.1056,  0.1432,\n",
            "        -0.2565, -0.2526,  0.1001, -0.1542,  0.1557, -0.1123, -0.3351, -0.2492,\n",
            "        -0.1562, -0.1763, -0.0290, -0.2185,  0.0293, -0.1508, -0.0191, -0.1305,\n",
            "        -0.2286, -0.3009, -0.0830, -0.2810,  0.0094, -0.2510, -0.3377, -0.2153,\n",
            "        -0.0373, -0.2403, -0.1852, -0.2819, -0.2133, -0.2601, -0.2023, -0.2640,\n",
            "        -0.3505, -0.2049, -0.2845, -0.2733, -0.2240, -0.3723, -0.3021, -0.1352,\n",
            "         0.0014, -0.3421, -0.5093, -0.1390, -0.5058, -0.1818, -0.1685, -0.1692,\n",
            "        -0.1478, -0.2395, -0.0686,  0.1072, -0.1654, -0.4904, -0.1035,  0.0756,\n",
            "        -0.1382, -0.3123, -0.3221, -0.0147, -0.0519, -0.1453, -0.4882, -0.2908,\n",
            "        -0.2186,  0.0443, -0.2407,  0.7089, -0.3190, -0.3063, -0.1522, -0.1691,\n",
            "        -0.1881, -0.2573,  0.0177, -0.1526,  0.3127, -0.0831, -0.4662, -0.2119,\n",
            "        -0.0342, -0.2074, -0.4953, -0.2201, -0.4396, -0.0407, -0.2636, -0.3559,\n",
            "        -0.1692, -0.2412, -0.5683,  0.0207, -0.3341, -0.2255, -0.1625, -0.8045,\n",
            "        -0.1728, -0.4935, -0.1760, -0.3081, -0.1067, -0.5822, -0.0617, -0.2063,\n",
            "        -0.1168, -0.2438, -0.4870, -0.2971,  0.1376, -0.1224, -0.1295, -0.1893,\n",
            "         0.3087, -0.0452, -0.1205, -0.1179, -0.2152, -0.2484, -0.5182,  0.1216,\n",
            "         0.0136, -0.0588, -0.1525,  0.4884, -0.1436, -0.1744, -0.1406, -0.0339,\n",
            "        -0.1451, -0.3476, -0.3150, -0.0945, -0.1796, -0.3851, -0.2605, -0.1136,\n",
            "        -0.5805, -0.1898, -0.0325, -0.1486, -0.1578, -0.4466, -0.1075, -0.3299,\n",
            "         0.0899, -0.3712, -0.1459, -0.1415, -0.2532, -0.1434,  0.1930, -0.7204,\n",
            "        -0.3526, -0.2748, -0.3664,  0.0030, -0.1501, -0.0498,  0.2012,  0.0951,\n",
            "        -0.1532, -0.0199, -0.4025, -0.1295, -0.3606, -0.2244, -0.4575, -0.4399,\n",
            "        -0.3067,  0.0286, -0.2617, -0.1968, -0.3103, -0.3462, -0.2462, -0.2857,\n",
            "        -0.1411, -0.3194, -0.0237, -0.2461, -0.3702, -0.2358, -0.3883, -0.4945,\n",
            "        -0.3288, -0.2923, -0.1402, -0.1337, -0.2063, -0.2684, -0.1171, -0.0355],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn1.running_var', tensor([0.0607, 0.1458, 0.0542, 0.0313, 0.0557, 0.0646, 0.0641, 0.0361, 0.0954,\n",
            "        0.0762, 0.0386, 0.0638, 0.0725, 0.0617, 0.0523, 0.0492, 0.0792, 0.0938,\n",
            "        0.0694, 0.2299, 0.0789, 0.1022, 0.1038, 0.0471, 0.0619, 0.0754, 0.1672,\n",
            "        0.1292, 0.0959, 0.0562, 0.0521, 0.0570, 0.0584, 0.0937, 0.0755, 0.0635,\n",
            "        0.0774, 0.1500, 0.0914, 0.0522, 0.0635, 0.0549, 0.0485, 0.0474, 0.0981,\n",
            "        0.0770, 0.0465, 0.0470, 0.1398, 0.2213, 0.0566, 0.0477, 0.0605, 0.1028,\n",
            "        0.0455, 0.0785, 0.0545, 0.1138, 0.0563, 0.0374, 0.1925, 0.1295, 0.0606,\n",
            "        0.0516, 0.0505, 0.1308, 0.1910, 0.0657, 0.0655, 0.0518, 0.1608, 0.0805,\n",
            "        0.0947, 0.0743, 0.1032, 0.0746, 0.0367, 0.1144, 0.0581, 0.1606, 0.1241,\n",
            "        0.0792, 0.0758, 0.1226, 0.0498, 0.0521, 0.0703, 0.0765, 0.0658, 0.0722,\n",
            "        0.0879, 0.0838, 0.0380, 0.0716, 0.1247, 0.0658, 0.0467, 0.0531, 0.1054,\n",
            "        0.1056, 0.0784, 0.0511, 0.0813, 0.0741, 0.1267, 0.0694, 0.0740, 0.0532,\n",
            "        0.1199, 0.0578, 0.0773, 0.0631, 0.0459, 0.1193, 0.0895, 0.0536, 0.0693,\n",
            "        0.0505, 0.1576, 0.0582, 0.0484, 0.0569, 0.0851, 0.0676, 0.1282, 0.0878,\n",
            "        0.0441, 0.1048, 0.0647, 0.0990, 0.1074, 0.1376, 0.0647, 0.0845, 0.1111,\n",
            "        0.0984, 0.1228, 0.0901, 0.1019, 0.0864, 0.0599, 0.1905, 0.0696, 0.0465,\n",
            "        0.0673, 0.0861, 0.0795, 0.0532, 0.0524, 0.1898, 0.0624, 0.1025, 0.0460,\n",
            "        0.0656, 0.0505, 0.0508, 0.0421, 0.0803, 0.0683, 0.1444, 0.1071, 0.0612,\n",
            "        0.0452, 0.1501, 0.0762, 0.0476, 0.0901, 0.0591, 0.0568, 0.0567, 0.1321,\n",
            "        0.0983, 0.0618, 0.0748, 0.0495, 0.0921, 0.0632, 0.0903, 0.0707, 0.0900,\n",
            "        0.1859, 0.1850, 0.0461, 0.1123, 0.0530, 0.0466, 0.0694, 0.0624, 0.0741,\n",
            "        0.1091, 0.0496, 0.0497, 0.0725, 0.1027, 0.0680, 0.0419, 0.1040, 0.0984,\n",
            "        0.0838, 0.1383, 0.1735, 0.1620, 0.0506, 0.0933, 0.0488, 0.0618, 0.0572,\n",
            "        0.0641, 0.1331, 0.0432, 0.1077, 0.0795, 0.0573, 0.0576, 0.1256, 0.0632,\n",
            "        0.0923, 0.0928, 0.0528, 0.0334, 0.0463, 0.1066, 0.0886, 0.0722, 0.0871,\n",
            "        0.0507, 0.0894, 0.1149, 0.0551, 0.0489, 0.0605, 0.0638, 0.0690, 0.0695,\n",
            "        0.2054, 0.0540, 0.0629, 0.1157, 0.0480, 0.0843, 0.0542, 0.0564, 0.0984,\n",
            "        0.0478, 0.0850, 0.0504, 0.0529, 0.0506, 0.0819, 0.0782, 0.1442, 0.0672,\n",
            "        0.1243, 0.0732, 0.1506, 0.0572, 0.0475, 0.0400, 0.0690, 0.0623, 0.0580,\n",
            "        0.0656, 0.0813, 0.1525, 0.0977, 0.2137, 0.0759, 0.0495, 0.0800, 0.0584,\n",
            "        0.0898, 0.0484, 0.1836, 0.0605, 0.0518, 0.1007, 0.0725, 0.0529, 0.0713,\n",
            "        0.1542, 0.1172, 0.0575, 0.2102, 0.1190, 0.1261, 0.0914, 0.0874, 0.0443,\n",
            "        0.0750, 0.0971, 0.0640, 0.0624, 0.0633, 0.0836, 0.1205, 0.0823, 0.0524,\n",
            "        0.0724, 0.1360, 0.1063, 0.0629, 0.0499, 0.0423, 0.0443, 0.0427, 0.0506,\n",
            "        0.1704, 0.0840, 0.1365, 0.0780, 0.1084, 0.0936, 0.0933, 0.0601, 0.0563,\n",
            "        0.0464, 0.0658, 0.1450, 0.0611, 0.0587, 0.0866, 0.0756, 0.0494, 0.0613,\n",
            "        0.2226, 0.0647, 0.0985, 0.1707, 0.2401, 0.0597, 0.0374, 0.0737, 0.0381,\n",
            "        0.0462, 0.0463, 0.0590, 0.1388, 0.1158, 0.0515, 0.0739, 0.0531, 0.0579,\n",
            "        0.0725, 0.0696, 0.0647, 0.0355, 0.1228, 0.0602, 0.0622, 0.0870, 0.0840,\n",
            "        0.1092, 0.0759, 0.0798, 0.0626, 0.0549, 0.1219, 0.1208, 0.0449, 0.0552,\n",
            "        0.0355, 0.0795, 0.1230, 0.0602, 0.1116, 0.0521, 0.0813, 0.0926, 0.0463,\n",
            "        0.0651, 0.0360, 0.0542, 0.0430, 0.1090, 0.0407, 0.0508, 0.0486, 0.0788,\n",
            "        0.0468, 0.1142, 0.0838, 0.0472, 0.0998, 0.1154, 0.0776, 0.0678, 0.0807,\n",
            "        0.2336, 0.1082, 0.0501, 0.0543, 0.0584, 0.1316, 0.0583, 0.0410, 0.0662,\n",
            "        0.1411, 0.0575, 0.2412, 0.0772, 0.0511, 0.1002, 0.0769, 0.1378, 0.0876,\n",
            "        0.0417, 0.0721, 0.0855, 0.0681, 0.0710, 0.1276, 0.0967, 0.0870, 0.0920,\n",
            "        0.0502, 0.1337, 0.0598, 0.0966, 0.0616, 0.1250, 0.0523, 0.1731, 0.0718,\n",
            "        0.1054, 0.0566, 0.0567, 0.0755, 0.0754, 0.0437, 0.0520, 0.0750, 0.0664,\n",
            "        0.0967, 0.0559, 0.0838, 0.1006, 0.0590, 0.0506, 0.1258, 0.0522, 0.0578,\n",
            "        0.0440, 0.0546, 0.1028, 0.0585, 0.0775, 0.0777, 0.0473, 0.0391, 0.1350,\n",
            "        0.0825, 0.0728, 0.0703, 0.1252, 0.0783, 0.0432, 0.1394, 0.0693, 0.0618,\n",
            "        0.1429, 0.0574, 0.1319, 0.0782, 0.0659, 0.1107, 0.1200, 0.0519, 0.0600,\n",
            "        0.1156, 0.0699, 0.0881, 0.1943, 0.0724, 0.1183, 0.0690, 0.0813, 0.0432,\n",
            "        0.1905, 0.0643, 0.0787, 0.0751, 0.0553, 0.0772, 0.0403, 0.0532, 0.0403,\n",
            "        0.1032, 0.1034, 0.0917, 0.0554, 0.0657, 0.0561, 0.1194, 0.0770, 0.0916,\n",
            "        0.0467, 0.0582, 0.0802, 0.0550, 0.0835, 0.1195, 0.1073, 0.0793, 0.1536,\n",
            "        0.0632, 0.0493, 0.1044, 0.0586, 0.0869, 0.0629, 0.0704, 0.0660],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn1.num_batches_tracked', tensor(99698, device='cuda:0')), ('backbone.layer4.1.conv2.weight', tensor([[[[-0.0128, -0.0057,  0.0141],\n",
            "          [-0.0199, -0.0214, -0.0073],\n",
            "          [-0.0027, -0.0118, -0.0018]],\n",
            "\n",
            "         [[ 0.0114,  0.0146,  0.0024],\n",
            "          [ 0.0076,  0.0027,  0.0213],\n",
            "          [-0.0049,  0.0160, -0.0005]],\n",
            "\n",
            "         [[ 0.0383,  0.0156,  0.0085],\n",
            "          [ 0.0226,  0.0112,  0.0091],\n",
            "          [ 0.0127, -0.0200,  0.0123]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0024, -0.0112,  0.0030],\n",
            "          [-0.0006,  0.0069,  0.0077],\n",
            "          [ 0.0089,  0.0286,  0.0076]],\n",
            "\n",
            "         [[-0.0109,  0.0140,  0.0046],\n",
            "          [-0.0074, -0.0147,  0.0166],\n",
            "          [-0.0225, -0.0101, -0.0047]],\n",
            "\n",
            "         [[-0.0006, -0.0054,  0.0137],\n",
            "          [-0.0054,  0.0009,  0.0128],\n",
            "          [ 0.0060,  0.0195,  0.0170]]],\n",
            "\n",
            "\n",
            "        [[[-0.0006, -0.0211, -0.0008],\n",
            "          [-0.0006,  0.0031,  0.0008],\n",
            "          [ 0.0108, -0.0069, -0.0022]],\n",
            "\n",
            "         [[ 0.0030, -0.0082, -0.0260],\n",
            "          [-0.0089,  0.0079, -0.0059],\n",
            "          [ 0.0047, -0.0014, -0.0035]],\n",
            "\n",
            "         [[-0.0009,  0.0235,  0.0167],\n",
            "          [ 0.0119,  0.0095,  0.0118],\n",
            "          [ 0.0360,  0.0124,  0.0081]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0228, -0.0172,  0.0087],\n",
            "          [-0.0034, -0.0099,  0.0032],\n",
            "          [-0.0022,  0.0093,  0.0051]],\n",
            "\n",
            "         [[ 0.0109, -0.0001,  0.0036],\n",
            "          [ 0.0221, -0.0032,  0.0125],\n",
            "          [-0.0051,  0.0023,  0.0025]],\n",
            "\n",
            "         [[-0.0193, -0.0190,  0.0018],\n",
            "          [ 0.0127,  0.0033,  0.0168],\n",
            "          [ 0.0008,  0.0029, -0.0129]]],\n",
            "\n",
            "\n",
            "        [[[-0.0061, -0.0008, -0.0051],\n",
            "          [-0.0025, -0.0179,  0.0070],\n",
            "          [-0.0296,  0.0169, -0.0285]],\n",
            "\n",
            "         [[-0.0206,  0.0135,  0.0060],\n",
            "          [-0.0005, -0.0059,  0.0086],\n",
            "          [-0.0063,  0.0108,  0.0010]],\n",
            "\n",
            "         [[-0.0093, -0.0270, -0.0052],\n",
            "          [-0.0035, -0.0252, -0.0173],\n",
            "          [-0.0125, -0.0033, -0.0014]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0149, -0.0084, -0.0232],\n",
            "          [ 0.0058, -0.0035,  0.0022],\n",
            "          [-0.0093,  0.0359,  0.0048]],\n",
            "\n",
            "         [[-0.0261, -0.0154,  0.0062],\n",
            "          [-0.0309, -0.0063, -0.0014],\n",
            "          [-0.0068, -0.0118, -0.0074]],\n",
            "\n",
            "         [[-0.0074,  0.0160, -0.0060],\n",
            "          [ 0.0190,  0.0003,  0.0209],\n",
            "          [-0.0232,  0.0040, -0.0097]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0060,  0.0068,  0.0076],\n",
            "          [-0.0030,  0.0232,  0.0015],\n",
            "          [-0.0090, -0.0092, -0.0155]],\n",
            "\n",
            "         [[-0.0044,  0.0167,  0.0086],\n",
            "          [ 0.0028, -0.0015,  0.0010],\n",
            "          [-0.0031, -0.0072,  0.0002]],\n",
            "\n",
            "         [[ 0.0194, -0.0132, -0.0081],\n",
            "          [ 0.0033, -0.0125, -0.0270],\n",
            "          [-0.0029, -0.0006, -0.0123]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0203, -0.0304, -0.0130],\n",
            "          [-0.0008, -0.0081, -0.0201],\n",
            "          [-0.0176, -0.0111, -0.0150]],\n",
            "\n",
            "         [[-0.0024,  0.0057,  0.0035],\n",
            "          [ 0.0098,  0.0019,  0.0078],\n",
            "          [-0.0011, -0.0141,  0.0089]],\n",
            "\n",
            "         [[-0.0220, -0.0099, -0.0039],\n",
            "          [ 0.0032,  0.0149,  0.0045],\n",
            "          [-0.0193, -0.0079, -0.0173]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0092,  0.0026, -0.0056],\n",
            "          [ 0.0108, -0.0085,  0.0145],\n",
            "          [ 0.0117,  0.0167,  0.0153]],\n",
            "\n",
            "         [[-0.0117, -0.0092, -0.0071],\n",
            "          [-0.0289,  0.0097, -0.0133],\n",
            "          [ 0.0011, -0.0060, -0.0189]],\n",
            "\n",
            "         [[-0.0030, -0.0040,  0.0044],\n",
            "          [ 0.0124, -0.0152,  0.0072],\n",
            "          [ 0.0224,  0.0042,  0.0270]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0122,  0.0047,  0.0025],\n",
            "          [ 0.0029, -0.0036,  0.0043],\n",
            "          [-0.0023,  0.0076, -0.0027]],\n",
            "\n",
            "         [[ 0.0018, -0.0163,  0.0043],\n",
            "          [-0.0089,  0.0100, -0.0071],\n",
            "          [-0.0172,  0.0141, -0.0135]],\n",
            "\n",
            "         [[-0.0031, -0.0003, -0.0039],\n",
            "          [-0.0115, -0.0044, -0.0048],\n",
            "          [-0.0163,  0.0021, -0.0105]]],\n",
            "\n",
            "\n",
            "        [[[-0.0027, -0.0192, -0.0246],\n",
            "          [-0.0338, -0.0133, -0.0177],\n",
            "          [-0.0030, -0.0042,  0.0031]],\n",
            "\n",
            "         [[-0.0040, -0.0034,  0.0046],\n",
            "          [ 0.0125, -0.0036, -0.0060],\n",
            "          [ 0.0139,  0.0055,  0.0291]],\n",
            "\n",
            "         [[-0.0144, -0.0045, -0.0056],\n",
            "          [ 0.0111, -0.0050, -0.0015],\n",
            "          [-0.0192, -0.0195, -0.0296]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0153,  0.0137,  0.0125],\n",
            "          [ 0.0066,  0.0058,  0.0016],\n",
            "          [ 0.0099,  0.0268,  0.0249]],\n",
            "\n",
            "         [[-0.0070,  0.0008,  0.0064],\n",
            "          [ 0.0136,  0.0118, -0.0011],\n",
            "          [ 0.0102, -0.0068,  0.0136]],\n",
            "\n",
            "         [[-0.0045, -0.0111, -0.0130],\n",
            "          [ 0.0013, -0.0088,  0.0022],\n",
            "          [ 0.0077,  0.0316,  0.0096]]]], device='cuda:0')), ('backbone.layer4.1.bn2.weight', tensor([0.1350, 0.1021, 0.0944, 0.1158, 0.1086, 0.0834, 0.1083, 0.1154, 0.1058,\n",
            "        0.1053, 0.0937, 0.1346, 0.1016, 0.0991, 0.1178, 0.1245, 0.1162, 0.1297,\n",
            "        0.1087, 0.1067, 0.1025, 0.1172, 0.1258, 0.1014, 0.1178, 0.1082, 0.1345,\n",
            "        0.1060, 0.0947, 0.1313, 0.0969, 0.1201, 0.1335, 0.0946, 0.1237, 0.0841,\n",
            "        0.1093, 0.0977, 0.0973, 0.1632, 0.1259, 0.0817, 0.1085, 0.0932, 0.1126,\n",
            "        0.0889, 0.1544, 0.1136, 0.1004, 0.1264, 0.1261, 0.0772, 0.1238, 0.1111,\n",
            "        0.1384, 0.1359, 0.1099, 0.1291, 0.1038, 0.1244, 0.1374, 0.1510, 0.1040,\n",
            "        0.1068, 0.0720, 0.1211, 0.1152, 0.1102, 0.1253, 0.1046, 0.0910, 0.0839,\n",
            "        0.1388, 0.0989, 0.0855, 0.1318, 0.1026, 0.0895, 0.1232, 0.1071, 0.1592,\n",
            "        0.1530, 0.1285, 0.1131, 0.1058, 0.1220, 0.1084, 0.1326, 0.1266, 0.1164,\n",
            "        0.0935, 0.1251, 0.1345, 0.1507, 0.1385, 0.0979, 0.1005, 0.1131, 0.1720,\n",
            "        0.1332, 0.0875, 0.1073, 0.1139, 0.1192, 0.0937, 0.0833, 0.1091, 0.1344,\n",
            "        0.1479, 0.0938, 0.1496, 0.1171, 0.1633, 0.1263, 0.1622, 0.1278, 0.1324,\n",
            "        0.1109, 0.1207, 0.0780, 0.1253, 0.1142, 0.1524, 0.1061, 0.1129, 0.1141,\n",
            "        0.1112, 0.0978, 0.0892, 0.1144, 0.1291, 0.1092, 0.1112, 0.0886, 0.1163,\n",
            "        0.2005, 0.0924, 0.1034, 0.0861, 0.1487, 0.1055, 0.1394, 0.1141, 0.1264,\n",
            "        0.1222, 0.0922, 0.1145, 0.1224, 0.1223, 0.1483, 0.1557, 0.1004, 0.1164,\n",
            "        0.1137, 0.0849, 0.1224, 0.1331, 0.0888, 0.1236, 0.1078, 0.0868, 0.1630,\n",
            "        0.1018, 0.1315, 0.1295, 0.1075, 0.1223, 0.1678, 0.1344, 0.0986, 0.0974,\n",
            "        0.0774, 0.1149, 0.1028, 0.1085, 0.1215, 0.1056, 0.1003, 0.1499, 0.0921,\n",
            "        0.0688, 0.1047, 0.0983, 0.1047, 0.0847, 0.1226, 0.1141, 0.0855, 0.1242,\n",
            "        0.1127, 0.1396, 0.0892, 0.1120, 0.1057, 0.1333, 0.0933, 0.1308, 0.1229,\n",
            "        0.1508, 0.1705, 0.1324, 0.0833, 0.0699, 0.1066, 0.1214, 0.1406, 0.1060,\n",
            "        0.0909, 0.1076, 0.1229, 0.1271, 0.1215, 0.1213, 0.1324, 0.1077, 0.1195,\n",
            "        0.1173, 0.1124, 0.0994, 0.1239, 0.0928, 0.0903, 0.1181, 0.1071, 0.1386,\n",
            "        0.0904, 0.0807, 0.1206, 0.1142, 0.1218, 0.1391, 0.1286, 0.0738, 0.0708,\n",
            "        0.1865, 0.0889, 0.1097, 0.1013, 0.1090, 0.1030, 0.0994, 0.1077, 0.1072,\n",
            "        0.1566, 0.0898, 0.1221, 0.1503, 0.0958, 0.1743, 0.0993, 0.1056, 0.1254,\n",
            "        0.1839, 0.0936, 0.0829, 0.1022, 0.0822, 0.1156, 0.1144, 0.0986, 0.1180,\n",
            "        0.0803, 0.1141, 0.1248, 0.0968, 0.1245, 0.0957, 0.1302, 0.1138, 0.1168,\n",
            "        0.1266, 0.2030, 0.1137, 0.1377, 0.1137, 0.1481, 0.1755, 0.0896, 0.1093,\n",
            "        0.1073, 0.1535, 0.1197, 0.1332, 0.0998, 0.1315, 0.1054, 0.1147, 0.1255,\n",
            "        0.0958, 0.1060, 0.1194, 0.1788, 0.1280, 0.0850, 0.1497, 0.1515, 0.1022,\n",
            "        0.1003, 0.1410, 0.1408, 0.1148, 0.1263, 0.0914, 0.0974, 0.0894, 0.1456,\n",
            "        0.1018, 0.0768, 0.0946, 0.1079, 0.1168, 0.1449, 0.1211, 0.1077, 0.1573,\n",
            "        0.1243, 0.1547, 0.1302, 0.1008, 0.0926, 0.1317, 0.1499, 0.1014, 0.0965,\n",
            "        0.0833, 0.1179, 0.1190, 0.1141, 0.1140, 0.0713, 0.1289, 0.1260, 0.1065,\n",
            "        0.0966, 0.1042, 0.0931, 0.1150, 0.1073, 0.1212, 0.1092, 0.1012, 0.1465,\n",
            "        0.1142, 0.1023, 0.0849, 0.0738, 0.1193, 0.0811, 0.1105, 0.1072, 0.1043,\n",
            "        0.0653, 0.1196, 0.1277, 0.1302, 0.1188, 0.0784, 0.1332, 0.1255, 0.1217,\n",
            "        0.1070, 0.1131, 0.1005, 0.1270, 0.1024, 0.1685, 0.0896, 0.1539, 0.1561,\n",
            "        0.1377, 0.1077, 0.0994, 0.1989, 0.0972, 0.0847, 0.1102, 0.1123, 0.1574,\n",
            "        0.1196, 0.1061, 0.1236, 0.1024, 0.1033, 0.1192, 0.1212, 0.1289, 0.1134,\n",
            "        0.1056, 0.0765, 0.1304, 0.0931, 0.1071, 0.1250, 0.0903, 0.0839, 0.1184,\n",
            "        0.1080, 0.1293, 0.2008, 0.1348, 0.1082, 0.1264, 0.1358, 0.1019, 0.1166,\n",
            "        0.1127, 0.1189, 0.1140, 0.1435, 0.1631, 0.1786, 0.0941, 0.1040, 0.1293,\n",
            "        0.1220, 0.1134, 0.1251, 0.1240, 0.1467, 0.0897, 0.1449, 0.0873, 0.1342,\n",
            "        0.1087, 0.1123, 0.1304, 0.1157, 0.1254, 0.0952, 0.1046, 0.1024, 0.0918,\n",
            "        0.1154, 0.1104, 0.0968, 0.1249, 0.1000, 0.0930, 0.1416, 0.1121, 0.1581,\n",
            "        0.1099, 0.1046, 0.0723, 0.0898, 0.1172, 0.1231, 0.0955, 0.0970, 0.1216,\n",
            "        0.0941, 0.1078, 0.1167, 0.1240, 0.0959, 0.1136, 0.1408, 0.1236, 0.1124,\n",
            "        0.1269, 0.1324, 0.0948, 0.1172, 0.1463, 0.1135, 0.1155, 0.0960, 0.0923,\n",
            "        0.0902, 0.1971, 0.1119, 0.0820, 0.0992, 0.0629, 0.0851, 0.1194, 0.1228,\n",
            "        0.1024, 0.1211, 0.0921, 0.1032, 0.1044, 0.1241, 0.1630, 0.1087, 0.1068,\n",
            "        0.0919, 0.1253, 0.1275, 0.1007, 0.1090, 0.0869, 0.1340, 0.1111, 0.1064,\n",
            "        0.1167, 0.1343, 0.1100, 0.1118, 0.1073, 0.1495, 0.1191, 0.0961, 0.1236,\n",
            "        0.0869, 0.1188, 0.1502, 0.1083, 0.1076, 0.1071, 0.0732, 0.0936],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn2.bias', tensor([-0.1082, -0.1136, -0.1079, -0.1177, -0.1265, -0.1063, -0.0839, -0.0970,\n",
            "        -0.1216, -0.0750, -0.1020, -0.0978, -0.1357, -0.1022, -0.0950, -0.0903,\n",
            "        -0.1156, -0.0819, -0.0818, -0.0938, -0.1107, -0.1019, -0.0921, -0.1088,\n",
            "        -0.1117, -0.0917, -0.0603, -0.0742, -0.0700, -0.1036, -0.0824, -0.1033,\n",
            "        -0.1159, -0.0305, -0.0832, -0.1008, -0.0742, -0.0888, -0.0595, -0.1052,\n",
            "        -0.1075, -0.0772, -0.0755, -0.0969, -0.0610, -0.0794, -0.0634, -0.0837,\n",
            "        -0.0619, -0.0884, -0.0910, -0.0431, -0.1380, -0.1036, -0.1487, -0.1331,\n",
            "        -0.0903, -0.1086, -0.0941, -0.1336, -0.0850, -0.0882, -0.0897, -0.1120,\n",
            "        -0.0569, -0.1055, -0.1137, -0.1230, -0.0834, -0.0720, -0.1016, -0.1062,\n",
            "        -0.1114, -0.0762, -0.0427, -0.1234, -0.0860, -0.0738, -0.1250, -0.0737,\n",
            "        -0.1272, -0.1487, -0.0871, -0.0947, -0.0435, -0.0882, -0.0900, -0.1389,\n",
            "        -0.1115, -0.0867, -0.0976, -0.0904, -0.1573, -0.0958, -0.1042, -0.1019,\n",
            "        -0.0756, -0.1009, -0.1308, -0.1127, -0.0565, -0.0737, -0.0700, -0.0944,\n",
            "        -0.1029, -0.0581, -0.1111, -0.1034, -0.1169, -0.0780, -0.1304, -0.0871,\n",
            "        -0.1223, -0.0949, -0.0896, -0.0798, -0.1122, -0.1072, -0.1078, -0.0977,\n",
            "        -0.1279, -0.0771, -0.1106, -0.0861, -0.1135, -0.0863, -0.0996, -0.0844,\n",
            "        -0.0821, -0.0965, -0.0763, -0.1164, -0.1069, -0.0598, -0.0904, -0.1663,\n",
            "        -0.0733, -0.0769, -0.0656, -0.0751, -0.1017, -0.1229, -0.0866, -0.1382,\n",
            "        -0.1219, -0.0881, -0.1033, -0.0912, -0.0959, -0.0673, -0.1375, -0.0252,\n",
            "        -0.1167, -0.0915, -0.0903, -0.1282, -0.1132, -0.0687, -0.0996, -0.0573,\n",
            "        -0.0634, -0.1246, -0.0583, -0.1402, -0.1882, -0.0888, -0.0977, -0.1166,\n",
            "        -0.1179, -0.1239, -0.1028, -0.0612, -0.1087, -0.0893, -0.0911, -0.0888,\n",
            "        -0.1009, -0.0735, -0.1639, -0.0958, -0.0697, -0.0554, -0.1089, -0.1376,\n",
            "        -0.1016, -0.1057, -0.0987, -0.0972, -0.1147, -0.0786, -0.1507, -0.0572,\n",
            "        -0.0804, -0.1204, -0.1352, -0.0734, -0.0964, -0.1076, -0.1322, -0.1329,\n",
            "        -0.0955, -0.0924, -0.0874, -0.0851, -0.1072, -0.1232, -0.0610, -0.1024,\n",
            "        -0.0629, -0.1576, -0.1547, -0.1105, -0.0576, -0.1042, -0.1602, -0.1287,\n",
            "        -0.0952, -0.0634, -0.1149, -0.0947, -0.1019, -0.0588, -0.0840, -0.1276,\n",
            "        -0.1227, -0.0891, -0.0442, -0.1218, -0.1008, -0.1343, -0.0626, -0.1004,\n",
            "        -0.0758, -0.0584, -0.1184, -0.0889, -0.0992, -0.0471, -0.0957, -0.1247,\n",
            "        -0.0793, -0.0773, -0.1049, -0.1276, -0.0552, -0.0851, -0.1179, -0.0762,\n",
            "        -0.0934, -0.1012, -0.0705, -0.0845, -0.1075, -0.0864, -0.0435, -0.0720,\n",
            "        -0.0483, -0.0826, -0.0871, -0.0799, -0.0614, -0.0815, -0.0667, -0.0962,\n",
            "        -0.0538, -0.1222, -0.0476, -0.1112, -0.1539, -0.1150, -0.1252, -0.0105,\n",
            "        -0.0926, -0.1211, -0.1435, -0.1151, -0.1150, -0.0483, -0.0983, -0.0109,\n",
            "        -0.1097, -0.0745, -0.1033, -0.0984, -0.0707, -0.1021, -0.1075, -0.1066,\n",
            "        -0.0977, -0.1257, -0.0860, -0.1764, -0.0874, -0.0936, -0.1067, -0.1275,\n",
            "        -0.0907, -0.0682, -0.1336, -0.1266, -0.1033, -0.1205, -0.0752, -0.0951,\n",
            "        -0.0931, -0.1103, -0.0878, -0.0557, -0.1038, -0.1197, -0.0793, -0.1072,\n",
            "        -0.0858, -0.0938, -0.0982,  0.0720, -0.1079, -0.1129, -0.1066, -0.1119,\n",
            "        -0.1072, -0.0999, -0.1153, -0.0799, -0.0888, -0.0962, -0.1408, -0.1165,\n",
            "        -0.0921, -0.0477, -0.0910, -0.1026, -0.1186, -0.1047, -0.1165, -0.0492,\n",
            "        -0.0641, -0.1021, -0.0554, -0.0366, -0.0922, -0.0825, -0.0845, -0.0711,\n",
            "        -0.0749, -0.0906, -0.1372, -0.0875, -0.1038, -0.0963, -0.0928, -0.0800,\n",
            "        -0.0848, -0.1143, -0.1026, -0.0869, -0.1268, -0.0921, -0.0915, -0.1070,\n",
            "        -0.1052, -0.1077, -0.0929, -0.1106, -0.0735, -0.1218, -0.0712, -0.0911,\n",
            "        -0.1319, -0.1034, -0.1027, -0.0925, -0.1971, -0.1275, -0.0995, -0.1030,\n",
            "        -0.0507, -0.0911, -0.1783, -0.0730, -0.1062, -0.1158, -0.1200, -0.1020,\n",
            "        -0.1328, -0.1032, -0.0921, -0.0650, -0.1024, -0.1238, -0.0778, -0.1210,\n",
            "        -0.1130, -0.1390, -0.0882, -0.0995, -0.1285, -0.1055, -0.2202, -0.1179,\n",
            "        -0.0813, -0.0943, -0.0866, -0.1062, -0.1252, -0.1061, -0.1129, -0.0713,\n",
            "        -0.0757, -0.1340, -0.1085, -0.0750, -0.1009, -0.1335, -0.1049, -0.0880,\n",
            "        -0.1083, -0.0854, -0.1070, -0.0932, -0.1276, -0.0495, -0.1139, -0.0805,\n",
            "        -0.1002, -0.1283, -0.0906, -0.1294, -0.0999, -0.0738, -0.0555, -0.0921,\n",
            "        -0.0977, -0.1012, -0.1011, -0.1048, -0.0699, -0.0828, -0.1107, -0.0963,\n",
            "        -0.1286, -0.1113, -0.0866, -0.1052, -0.0979, -0.1143, -0.0791, -0.0677,\n",
            "        -0.0928, -0.0945, -0.0733, -0.1013, -0.1158, -0.1051, -0.0857, -0.1208,\n",
            "        -0.1459, -0.1545, -0.1040, -0.1223, -0.1247, -0.0604, -0.0813, -0.1276,\n",
            "        -0.0861, -0.0891, -0.0903, -0.0685, -0.0750, -0.1458, -0.1151, -0.0925,\n",
            "        -0.0785, -0.0672, -0.0824, -0.0834, -0.0815, -0.1221, -0.1315, -0.0768,\n",
            "        -0.1342, -0.1263, -0.0808, -0.1053, -0.0874, -0.0924, -0.0686, -0.1121,\n",
            "        -0.0987, -0.1233, -0.1256, -0.0555, -0.1077, -0.0854, -0.0694, -0.0862,\n",
            "        -0.1139, -0.1106, -0.0987, -0.0896, -0.1008, -0.1077, -0.0864, -0.0820,\n",
            "        -0.0602, -0.1290, -0.1396, -0.0637, -0.0856, -0.0653, -0.0713, -0.0554],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn2.running_mean', tensor([ 7.4301e-02,  1.3399e-01, -9.3112e-02, -1.8236e-01, -3.2570e-02,\n",
            "        -1.0017e-01, -2.8417e-02, -3.1373e-02, -2.6152e-02, -6.8018e-02,\n",
            "         5.2056e-02, -1.7101e-02,  8.3259e-02, -2.0262e-01, -2.1335e-02,\n",
            "        -3.2173e-02,  6.8057e-02, -7.6951e-02,  3.1494e-03, -1.0051e-01,\n",
            "        -9.9659e-03, -3.6355e-02, -1.1747e-01,  6.0834e-02,  2.0218e-01,\n",
            "        -2.0763e-01,  1.5259e-01, -9.5354e-03, -8.3272e-02, -1.9367e-01,\n",
            "         1.1112e-01, -2.3919e-01, -2.2631e-01, -4.1024e-02, -3.3852e-01,\n",
            "        -8.6324e-02, -5.8875e-02, -2.8445e-02, -2.2829e-02, -1.0418e-01,\n",
            "        -8.9516e-02,  8.3120e-02,  5.7084e-02, -7.4626e-03, -2.6663e-02,\n",
            "        -1.0566e-01,  7.3568e-02,  1.0548e-01, -7.0392e-02, -6.6376e-02,\n",
            "        -1.9485e-01,  5.5387e-03,  9.4233e-03,  5.7241e-02, -6.0513e-02,\n",
            "        -8.1013e-02, -1.2955e-01,  1.9874e-02,  6.2407e-02, -1.8265e-01,\n",
            "        -1.9912e-01,  7.8473e-02,  2.8235e-02, -5.2116e-02,  4.9478e-02,\n",
            "        -4.7856e-02,  4.5494e-02,  6.1174e-02, -1.2333e-01,  3.3590e-02,\n",
            "         6.5517e-02, -8.9333e-03, -9.7182e-02, -2.7151e-01, -1.7171e-02,\n",
            "         6.1729e-02, -6.8395e-02, -1.8760e-02,  1.4556e-01, -2.6269e-03,\n",
            "        -4.7070e-02, -9.7146e-02,  5.3944e-02, -7.0074e-02, -2.2747e-02,\n",
            "        -1.0408e-01, -1.2168e-01, -1.1354e-01, -2.3367e-02,  3.1477e-02,\n",
            "        -1.2107e-01,  9.0939e-02,  7.6741e-02,  8.1733e-02, -1.4289e-01,\n",
            "        -5.7948e-02, -7.3134e-02, -1.2421e-01, -1.7921e-01, -1.2712e-03,\n",
            "        -7.0126e-02, -2.3211e-01, -4.9358e-02, -3.9966e-03,  1.6212e-01,\n",
            "         5.1690e-02, -5.7146e-02, -9.2393e-02, -9.0631e-02, -2.3927e-04,\n",
            "        -6.3971e-02, -1.4508e-01, -2.0662e-01, -1.6935e-01, -4.4431e-02,\n",
            "         2.3457e-02, -4.8052e-02,  3.9861e-02, -2.0289e-01, -5.7336e-02,\n",
            "         1.1463e-01, -8.3415e-02, -1.1392e-01,  1.7358e-02,  2.3870e-02,\n",
            "        -7.7205e-02,  1.9384e-01, -6.0109e-02, -8.0348e-02,  6.3622e-03,\n",
            "         2.2071e-02, -1.4807e-01,  9.4260e-02, -1.8966e-02, -1.1843e-01,\n",
            "        -1.8839e-01,  4.8229e-02, -2.1645e-01,  1.5555e-02, -7.1714e-02,\n",
            "        -7.4867e-02, -9.7800e-02, -5.6531e-02,  1.1791e-02, -8.5315e-02,\n",
            "         2.3655e-02, -6.6929e-02, -1.2360e-01, -1.3982e-01,  4.1087e-02,\n",
            "        -1.4357e-01, -1.3025e-01,  7.1820e-05,  6.4465e-02,  1.4513e-02,\n",
            "        -2.4125e-01,  7.8441e-02,  5.6243e-03, -1.5197e-01, -1.6763e-01,\n",
            "        -1.1027e-01, -1.8546e-01, -1.2137e-01, -6.2040e-02, -4.2701e-02,\n",
            "        -1.6849e-01,  6.4859e-02, -2.0185e-01, -5.3572e-02,  1.1990e-01,\n",
            "        -2.0701e-01,  8.4660e-03, -1.1822e-01,  8.9234e-02,  6.0429e-02,\n",
            "        -4.3726e-02, -2.4309e-01, -1.0576e-01, -1.3588e-01, -2.6230e-01,\n",
            "        -1.2003e-01, -6.7276e-02,  9.5167e-02,  3.7329e-02,  1.2246e-01,\n",
            "         5.8710e-02,  1.0617e-01, -1.1199e-02, -1.5324e-01, -1.6642e-01,\n",
            "        -1.1457e-01, -1.6955e-01, -1.5570e-01, -3.9616e-02,  4.3530e-03,\n",
            "        -7.8119e-02, -7.2474e-02, -1.5881e-03, -6.7152e-02, -1.2348e-01,\n",
            "        -1.4571e-01,  5.1951e-02, -1.9737e-02,  1.1339e-02, -1.1546e-01,\n",
            "        -3.7844e-02, -9.3142e-02,  4.4509e-03, -1.5864e-01,  1.5162e-02,\n",
            "        -2.2943e-02, -1.2413e-01, -5.4853e-02,  9.8716e-04,  5.8170e-02,\n",
            "        -6.9921e-02, -9.2392e-02, -1.2034e-01, -2.5384e-02, -1.4981e-01,\n",
            "        -1.6345e-01,  4.1379e-02, -2.5065e-02, -4.5134e-02,  1.1103e-01,\n",
            "        -2.0449e-01,  7.4239e-02, -1.7623e-01, -1.2672e-02, -7.3482e-02,\n",
            "        -7.6493e-03, -4.8756e-02,  3.1346e-02, -1.9063e-01, -1.4670e-01,\n",
            "         6.8660e-02, -3.2050e-02,  8.6994e-02, -7.2551e-02, -1.1405e-02,\n",
            "        -1.1323e-01, -1.2284e-01, -9.0317e-02,  1.1124e-01,  9.0795e-02,\n",
            "        -1.2958e-01,  7.8656e-02, -5.6529e-02,  1.8288e-01, -6.8364e-02,\n",
            "        -9.8506e-02, -1.7327e-01,  5.8734e-02, -4.0936e-02,  2.8284e-02,\n",
            "        -2.8819e-02,  3.6276e-02, -1.6130e-01,  3.1916e-02, -1.8055e-01,\n",
            "         2.6640e-02, -7.4611e-03, -3.7382e-03, -5.0189e-02, -2.1574e-02,\n",
            "         8.4066e-02, -1.3264e-01, -2.5572e-02,  7.1738e-02, -1.0173e-01,\n",
            "        -3.4832e-03, -3.4919e-02, -1.1932e-02, -1.7026e-01,  9.7172e-03,\n",
            "        -5.2837e-02,  9.0508e-02,  3.7652e-03,  1.4264e-01, -3.2954e-02,\n",
            "         5.0194e-02, -1.5886e-01, -1.3068e-01,  6.8017e-03,  5.3112e-02,\n",
            "        -4.9578e-02,  8.3730e-02, -2.4541e-02, -1.1459e-01, -8.8445e-02,\n",
            "        -2.2515e-01,  2.3352e-02, -1.5673e-01,  1.7835e-02, -5.1900e-02,\n",
            "         8.8312e-02, -4.7973e-02,  2.1934e-02, -1.0449e-01, -1.7507e-01,\n",
            "         2.0055e-02,  3.8708e-02, -7.3508e-02, -2.8541e-01,  1.8353e-01,\n",
            "        -1.8419e-01, -7.7914e-02, -1.9631e-01, -4.7553e-02, -1.4478e-01,\n",
            "         1.3996e-01,  5.4863e-02, -3.8370e-02,  3.2356e-02, -5.0832e-02,\n",
            "        -6.4524e-02,  3.7583e-02,  2.4071e-02, -4.2587e-02,  1.4610e-01,\n",
            "         1.6152e-02, -1.3460e-01, -1.8945e-01, -6.6729e-02, -1.0291e-02,\n",
            "        -6.3985e-02, -2.6520e-02, -1.4178e-01, -8.3607e-02, -1.4587e-02,\n",
            "        -1.9105e-01, -2.4460e-01, -3.3166e-02, -1.7899e-01, -6.2314e-03,\n",
            "        -6.0743e-02, -1.7551e-02,  1.1769e-01,  7.0743e-03, -2.6140e-03,\n",
            "         7.6926e-02, -3.1528e-02,  1.3509e-01,  1.6818e-01, -5.3944e-02,\n",
            "        -5.6202e-02,  1.7663e-02,  1.6338e-02,  1.3676e-01, -8.4305e-02,\n",
            "         2.6169e-02, -1.7770e-01, -9.1210e-02, -1.0939e-01, -1.7213e-01,\n",
            "        -1.7293e-01, -4.6205e-02, -5.2909e-02, -1.5155e-01, -2.2149e-01,\n",
            "         5.2557e-02, -4.0612e-02, -3.8967e-02, -1.3432e-01, -4.8065e-02,\n",
            "        -1.9025e-01, -1.1401e-01,  5.3727e-02,  6.3470e-02, -2.4838e-02,\n",
            "        -1.1687e-01, -2.4526e-02,  3.1717e-02,  3.5324e-02, -5.5016e-02,\n",
            "        -4.5403e-02, -9.6086e-02, -1.4085e-01,  2.8962e-02, -1.5708e-01,\n",
            "        -1.1369e-01,  1.3154e-01,  4.1303e-02,  4.4948e-02, -2.0289e-02,\n",
            "        -4.9035e-02, -2.4650e-02, -2.0868e-03, -1.8879e-01, -1.3349e-01,\n",
            "        -1.5235e-01,  1.8242e-01, -9.4470e-02,  5.8776e-02, -1.0701e-01,\n",
            "         1.1094e-01, -1.0255e-02, -1.9906e-01, -1.0114e-01, -1.3814e-01,\n",
            "        -5.3957e-02, -1.7072e-01, -4.8655e-02, -4.5645e-03,  8.9409e-02,\n",
            "        -1.3376e-01, -3.8532e-02, -4.5433e-02, -1.5180e-01, -9.8382e-02,\n",
            "        -6.8353e-02,  6.1776e-02, -1.2601e-01,  1.1613e-01, -1.6821e-01,\n",
            "         3.1156e-02,  7.7676e-02, -2.1659e-02, -6.3090e-02,  1.1967e-01,\n",
            "         2.2730e-01, -5.5901e-02,  1.8668e-01, -1.9245e-01, -1.4376e-01,\n",
            "        -2.3258e-01, -4.1737e-02,  8.4527e-02, -2.1492e-02,  1.5385e-01,\n",
            "         1.3093e-02,  1.4017e-01, -1.0130e-01, -2.0747e-01,  7.6452e-02,\n",
            "         8.8425e-02, -1.8068e-01,  2.0501e-02, -1.4542e-01, -8.6315e-03,\n",
            "        -1.7571e-01, -1.4899e-01, -5.9771e-02,  1.2275e-01, -2.6396e-02,\n",
            "        -1.0106e-01,  5.6655e-02, -1.1283e-01, -1.9319e-02, -1.1131e-01,\n",
            "        -1.6268e-01, -3.6234e-02, -5.7962e-02, -1.5607e-02, -4.3901e-02,\n",
            "         1.5842e-01, -4.5226e-02,  6.7501e-02, -1.2656e-01, -2.4695e-01,\n",
            "        -1.6263e-01,  6.2798e-02, -3.9506e-02, -1.9209e-01, -4.3492e-02,\n",
            "        -9.6039e-02,  1.6003e-01, -7.1029e-02, -3.3606e-01,  6.6881e-02,\n",
            "        -1.7961e-01,  5.7102e-03, -1.1763e-02, -1.3836e-01, -2.2886e-02,\n",
            "        -6.3433e-02, -9.2061e-02,  3.6999e-02,  1.6031e-01, -7.5564e-02,\n",
            "         5.8065e-02, -1.0040e-02, -1.1419e-01,  1.1001e-01,  1.5761e-02,\n",
            "         1.5118e-02, -1.2827e-01, -2.1515e-02,  1.6385e-01,  1.0580e-01,\n",
            "         9.4837e-02, -7.2992e-02, -1.0301e-01, -9.6814e-02, -3.7413e-04,\n",
            "        -1.4715e-01, -6.2823e-02, -1.6856e-01,  1.4271e-01, -1.3387e-01,\n",
            "         8.7775e-02, -7.8171e-02, -1.9753e-01, -1.4073e-01,  2.4105e-02,\n",
            "        -1.8899e-01,  1.3860e-01, -8.9122e-02, -1.1047e-01, -1.2049e-01,\n",
            "        -1.9743e-01,  1.1942e-01], device='cuda:0')), ('backbone.layer4.1.bn2.running_var', tensor([0.0188, 0.0216, 0.0136, 0.0269, 0.0250, 0.0136, 0.0118, 0.0104, 0.0156,\n",
            "        0.0107, 0.0077, 0.0095, 0.0148, 0.0158, 0.0094, 0.0113, 0.0084, 0.0084,\n",
            "        0.0124, 0.0137, 0.0225, 0.0114, 0.0117, 0.0111, 0.0193, 0.0184, 0.0240,\n",
            "        0.0135, 0.0151, 0.0170, 0.0136, 0.0168, 0.0187, 0.0086, 0.0250, 0.0188,\n",
            "        0.0079, 0.0156, 0.0218, 0.0083, 0.0146, 0.0137, 0.0092, 0.0146, 0.0126,\n",
            "        0.0260, 0.0178, 0.0173, 0.0124, 0.0115, 0.0156, 0.0079, 0.0121, 0.0155,\n",
            "        0.0096, 0.0213, 0.0098, 0.0068, 0.0138, 0.0275, 0.0221, 0.0164, 0.0126,\n",
            "        0.0100, 0.0138, 0.0114, 0.0161, 0.0145, 0.0114, 0.0145, 0.0115, 0.0143,\n",
            "        0.0130, 0.0187, 0.0069, 0.0153, 0.0172, 0.0138, 0.0118, 0.0103, 0.0161,\n",
            "        0.0160, 0.0188, 0.0086, 0.0140, 0.0127, 0.0151, 0.0100, 0.0122, 0.0079,\n",
            "        0.0178, 0.0142, 0.0151, 0.0152, 0.0086, 0.0126, 0.0194, 0.0081, 0.0122,\n",
            "        0.0099, 0.0134, 0.0225, 0.0146, 0.0120, 0.0254, 0.0130, 0.0152, 0.0130,\n",
            "        0.0156, 0.0100, 0.0113, 0.0152, 0.0157, 0.0129, 0.0135, 0.0149, 0.0138,\n",
            "        0.0083, 0.0155, 0.0151, 0.0137, 0.0101, 0.0091, 0.0145, 0.0128, 0.0076,\n",
            "        0.0206, 0.0125, 0.0190, 0.0197, 0.0121, 0.0153, 0.0120, 0.0129, 0.0113,\n",
            "        0.0266, 0.0208, 0.0171, 0.0088, 0.0175, 0.0115, 0.0122, 0.0153, 0.0120,\n",
            "        0.0163, 0.0128, 0.0074, 0.0202, 0.0202, 0.0227, 0.0180, 0.0172, 0.0189,\n",
            "        0.0088, 0.0109, 0.0116, 0.0128, 0.0124, 0.0279, 0.0126, 0.0138, 0.0152,\n",
            "        0.0106, 0.0097, 0.0234, 0.0150, 0.0201, 0.0119, 0.0082, 0.0209, 0.0171,\n",
            "        0.0126, 0.0133, 0.0144, 0.0176, 0.0097, 0.0209, 0.0104, 0.0150, 0.0258,\n",
            "        0.0203, 0.0191, 0.0116, 0.0174, 0.0200, 0.0103, 0.0177, 0.0113, 0.0225,\n",
            "        0.0146, 0.0158, 0.0130, 0.0148, 0.0132, 0.0104, 0.0188, 0.0193, 0.0094,\n",
            "        0.0114, 0.0216, 0.0211, 0.0168, 0.0093, 0.0231, 0.0123, 0.0123, 0.0174,\n",
            "        0.0066, 0.0154, 0.0135, 0.0166, 0.0145, 0.0154, 0.0156, 0.0109, 0.0070,\n",
            "        0.0147, 0.0222, 0.0111, 0.0147, 0.0101, 0.0107, 0.0157, 0.0075, 0.0193,\n",
            "        0.0182, 0.0317, 0.0109, 0.0137, 0.0172, 0.0162, 0.0098, 0.0117, 0.0183,\n",
            "        0.0161, 0.0081, 0.0230, 0.0181, 0.0157, 0.0169, 0.0238, 0.0155, 0.0096,\n",
            "        0.0163, 0.0083, 0.0196, 0.0155, 0.0117, 0.0269, 0.0095, 0.0108, 0.0177,\n",
            "        0.0159, 0.0136, 0.0094, 0.0116, 0.0120, 0.0225, 0.0089, 0.0158, 0.0093,\n",
            "        0.0118, 0.0116, 0.0146, 0.0140, 0.0177, 0.0103, 0.0118, 0.0144, 0.0231,\n",
            "        0.0106, 0.0207, 0.0230, 0.0152, 0.0142, 0.0151, 0.0251, 0.0193, 0.0231,\n",
            "        0.0155, 0.0157, 0.0122, 0.0164, 0.0187, 0.0162, 0.0174, 0.0130, 0.0189,\n",
            "        0.0132, 0.0120, 0.0201, 0.0138, 0.0187, 0.0203, 0.0152, 0.0199, 0.0095,\n",
            "        0.0098, 0.0109, 0.0238, 0.0135, 0.0190, 0.0202, 0.0196, 0.0151, 0.0181,\n",
            "        0.0140, 0.0135, 0.0135, 0.0176, 0.0185, 0.0100, 0.0109, 0.0197, 0.0096,\n",
            "        0.0187, 0.0156, 0.0224, 0.0142, 0.0172, 0.0108, 0.0212, 0.0172, 0.0111,\n",
            "        0.0251, 0.0194, 0.0139, 0.0184, 0.0092, 0.0093, 0.0146, 0.0204, 0.0150,\n",
            "        0.0195, 0.0096, 0.0100, 0.0114, 0.0144, 0.0198, 0.0190, 0.0073, 0.0108,\n",
            "        0.0191, 0.0146, 0.0165, 0.0107, 0.0127, 0.0142, 0.0158, 0.0125, 0.0095,\n",
            "        0.0143, 0.0121, 0.0181, 0.0222, 0.0134, 0.0203, 0.0147, 0.0130, 0.0216,\n",
            "        0.0185, 0.0153, 0.0132, 0.0270, 0.0129, 0.0129, 0.0127, 0.0157, 0.0237,\n",
            "        0.0145, 0.0144, 0.0120, 0.0166, 0.0139, 0.0184, 0.0090, 0.0152, 0.0143,\n",
            "        0.0187, 0.0144, 0.0086, 0.0182, 0.0100, 0.0091, 0.0153, 0.0120, 0.0115,\n",
            "        0.0148, 0.0180, 0.0143, 0.0121, 0.0107, 0.0188, 0.0135, 0.0166, 0.0135,\n",
            "        0.0081, 0.0110, 0.0190, 0.0153, 0.0126, 0.0113, 0.0160, 0.0153, 0.0124,\n",
            "        0.0164, 0.0076, 0.0202, 0.0132, 0.0127, 0.0162, 0.0108, 0.0152, 0.0172,\n",
            "        0.0190, 0.0095, 0.0118, 0.0060, 0.0119, 0.0125, 0.0212, 0.0115, 0.0122,\n",
            "        0.0159, 0.0190, 0.0186, 0.0114, 0.0136, 0.0068, 0.0139, 0.0234, 0.0093,\n",
            "        0.0119, 0.0180, 0.0186, 0.0145, 0.0182, 0.0116, 0.0196, 0.0222, 0.0109,\n",
            "        0.0156, 0.0151, 0.0116, 0.0176, 0.0118, 0.0109, 0.0180, 0.0199, 0.0127,\n",
            "        0.0176, 0.0223, 0.0083, 0.0130, 0.0096, 0.0193, 0.0113, 0.0132, 0.0153,\n",
            "        0.0163, 0.0147, 0.0182, 0.0094, 0.0165, 0.0132, 0.0127, 0.0151, 0.0125,\n",
            "        0.0307, 0.0190, 0.0111, 0.0095, 0.0184, 0.0181, 0.0094, 0.0142, 0.0194,\n",
            "        0.0295, 0.0219, 0.0163, 0.0233, 0.0112, 0.0105, 0.0242, 0.0170, 0.0138,\n",
            "        0.0156, 0.0110, 0.0177, 0.0123, 0.0151, 0.0096, 0.0137, 0.0154, 0.0140,\n",
            "        0.0137, 0.0143, 0.0142, 0.0135, 0.0158, 0.0226, 0.0222, 0.0199, 0.0182,\n",
            "        0.0142, 0.0133, 0.0140, 0.0104, 0.0175, 0.0186, 0.0159, 0.0118],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn2.num_batches_tracked', tensor(99698, device='cuda:0')), ('backbone.layer4.1.conv3.weight', tensor([[[[-2.0759e-02]],\n",
            "\n",
            "         [[-6.8084e-03]],\n",
            "\n",
            "         [[-4.4784e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.2378e-03]],\n",
            "\n",
            "         [[-3.6292e-03]],\n",
            "\n",
            "         [[-7.9682e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2561e-04]],\n",
            "\n",
            "         [[-2.7304e-02]],\n",
            "\n",
            "         [[ 2.8506e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.2836e-03]],\n",
            "\n",
            "         [[ 1.0541e-03]],\n",
            "\n",
            "         [[-1.2224e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.2648e-03]],\n",
            "\n",
            "         [[ 6.7294e-05]],\n",
            "\n",
            "         [[-9.3284e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3309e-03]],\n",
            "\n",
            "         [[-5.3446e-03]],\n",
            "\n",
            "         [[ 1.1601e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5187e-02]],\n",
            "\n",
            "         [[-8.2907e-03]],\n",
            "\n",
            "         [[-1.8946e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2688e-03]],\n",
            "\n",
            "         [[ 1.9546e-02]],\n",
            "\n",
            "         [[ 4.3955e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8704e-03]],\n",
            "\n",
            "         [[ 2.8581e-02]],\n",
            "\n",
            "         [[-2.6576e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4324e-02]],\n",
            "\n",
            "         [[-3.0883e-02]],\n",
            "\n",
            "         [[-8.2428e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7272e-04]],\n",
            "\n",
            "         [[-4.9268e-03]],\n",
            "\n",
            "         [[-7.1346e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0289e-02]],\n",
            "\n",
            "         [[-6.8390e-03]],\n",
            "\n",
            "         [[ 1.0871e-03]]]], device='cuda:0')), ('backbone.layer4.1.bn3.weight', tensor([0.1028, 0.1736, 0.1222,  ..., 0.0889, 0.1198, 0.0887], device='cuda:0')), ('backbone.layer4.1.bn3.bias', tensor([-0.0581, -0.0652, -0.0605,  ..., -0.0456, -0.0589, -0.0347],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn3.running_mean', tensor([-0.0289,  0.0070,  0.0133,  ..., -0.0253, -0.0100, -0.0150],\n",
            "       device='cuda:0')), ('backbone.layer4.1.bn3.running_var', tensor([0.0018, 0.0024, 0.0004,  ..., 0.0010, 0.0006, 0.0014], device='cuda:0')), ('backbone.layer4.1.bn3.num_batches_tracked', tensor(99698, device='cuda:0')), ('backbone.layer4.2.conv1.weight', tensor([[[[ 0.0047]],\n",
            "\n",
            "         [[-0.0051]],\n",
            "\n",
            "         [[ 0.0099]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[-0.0003]],\n",
            "\n",
            "         [[ 0.0165]]],\n",
            "\n",
            "\n",
            "        [[[-0.0354]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         [[-0.0148]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0196]],\n",
            "\n",
            "         [[-0.0150]],\n",
            "\n",
            "         [[ 0.0150]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0029]],\n",
            "\n",
            "         [[ 0.0052]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0132]],\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         [[ 0.0139]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0004]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         [[-0.0244]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0070]],\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         [[-0.0211]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0094]],\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         [[-0.0074]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0007]],\n",
            "\n",
            "         [[ 0.0108]],\n",
            "\n",
            "         [[ 0.0228]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0170]],\n",
            "\n",
            "         [[ 0.0053]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         [[ 0.0171]]]], device='cuda:0')), ('backbone.layer4.2.bn1.weight', tensor([0.1526, 0.1536, 0.1103, 0.1260, 0.1100, 0.1150, 0.1069, 0.1114, 0.1196,\n",
            "        0.1330, 0.1267, 0.1150, 0.1336, 0.1156, 0.1177, 0.1255, 0.1427, 0.1185,\n",
            "        0.1351, 0.1203, 0.1028, 0.1343, 0.0942, 0.1206, 0.1361, 0.1060, 0.1141,\n",
            "        0.1066, 0.1051, 0.1187, 0.1408, 0.1285, 0.1171, 0.1475, 0.1215, 0.1082,\n",
            "        0.1494, 0.0822, 0.1275, 0.1244, 0.1456, 0.1717, 0.1160, 0.1123, 0.1188,\n",
            "        0.1352, 0.1114, 0.1288, 0.1014, 0.1513, 0.1433, 0.1039, 0.1255, 0.1567,\n",
            "        0.1409, 0.0996, 0.1405, 0.1220, 0.1102, 0.1234, 0.1352, 0.1191, 0.1246,\n",
            "        0.0850, 0.1208, 0.1108, 0.1793, 0.1027, 0.1215, 0.1569, 0.1309, 0.1224,\n",
            "        0.1166, 0.1274, 0.1058, 0.1268, 0.0868, 0.1197, 0.1563, 0.1167, 0.1089,\n",
            "        0.1213, 0.1008, 0.0915, 0.1157, 0.1147, 0.1322, 0.1283, 0.1334, 0.1081,\n",
            "        0.1205, 0.1521, 0.1144, 0.1082, 0.1232, 0.1129, 0.1214, 0.1328, 0.1135,\n",
            "        0.1189, 0.1258, 0.1365, 0.1451, 0.1484, 0.0930, 0.1388, 0.1362, 0.1083,\n",
            "        0.1031, 0.1352, 0.1332, 0.1202, 0.1110, 0.1272, 0.1202, 0.1238, 0.0985,\n",
            "        0.1125, 0.1401, 0.1160, 0.1007, 0.1188, 0.1353, 0.1139, 0.0974, 0.1265,\n",
            "        0.1312, 0.1210, 0.1215, 0.1210, 0.1420, 0.1170, 0.1433, 0.1165, 0.1001,\n",
            "        0.1541, 0.1580, 0.1308, 0.1263, 0.1176, 0.1162, 0.1323, 0.1005, 0.1017,\n",
            "        0.0934, 0.1529, 0.1247, 0.1074, 0.1023, 0.1311, 0.1372, 0.1008, 0.1269,\n",
            "        0.1160, 0.1329, 0.1124, 0.1106, 0.1519, 0.0825, 0.1395, 0.1016, 0.0604,\n",
            "        0.1493, 0.1261, 0.1428, 0.1321, 0.1224, 0.1433, 0.1212, 0.1398, 0.1124,\n",
            "        0.1304, 0.1026, 0.0971, 0.1156, 0.1205, 0.0947, 0.1403, 0.1230, 0.1597,\n",
            "        0.1127, 0.1154, 0.1339, 0.1516, 0.1060, 0.1239, 0.1422, 0.1188, 0.1342,\n",
            "        0.1253, 0.1227, 0.1275, 0.0663, 0.1506, 0.1082, 0.1224, 0.1212, 0.1300,\n",
            "        0.1575, 0.1382, 0.1267, 0.1193, 0.1326, 0.1049, 0.1056, 0.1214, 0.1288,\n",
            "        0.1194, 0.1249, 0.1472, 0.1177, 0.0949, 0.1061, 0.1191, 0.1319, 0.1512,\n",
            "        0.1232, 0.1260, 0.1378, 0.1062, 0.1118, 0.1061, 0.1387, 0.0813, 0.1667,\n",
            "        0.1278, 0.0884, 0.1144, 0.1386, 0.1334, 0.1173, 0.1613, 0.1171, 0.1323,\n",
            "        0.1241, 0.1498, 0.1005, 0.1238, 0.1087, 0.1146, 0.1404, 0.1200, 0.1316,\n",
            "        0.1268, 0.1209, 0.1056, 0.1616, 0.1073, 0.1052, 0.1411, 0.1308, 0.1600,\n",
            "        0.1540, 0.1074, 0.1138, 0.1317, 0.1074, 0.0971, 0.1149, 0.0888, 0.1242,\n",
            "        0.1279, 0.1506, 0.1357, 0.1223, 0.1352, 0.1079, 0.1525, 0.1033, 0.1308,\n",
            "        0.1081, 0.1521, 0.1196, 0.1168, 0.1266, 0.0859, 0.1779, 0.0857, 0.1180,\n",
            "        0.0996, 0.1208, 0.1207, 0.1240, 0.1128, 0.1582, 0.1042, 0.1055, 0.1458,\n",
            "        0.1205, 0.1096, 0.1195, 0.1116, 0.1107, 0.1280, 0.1337, 0.1315, 0.1114,\n",
            "        0.1157, 0.1150, 0.1167, 0.1059, 0.1010, 0.0432, 0.1251, 0.1086, 0.1741,\n",
            "        0.1531, 0.1001, 0.0862, 0.1164, 0.0644, 0.1278, 0.0405, 0.1316, 0.1189,\n",
            "        0.1384, 0.1477, 0.1127, 0.0811, 0.0977, 0.1195, 0.1349, 0.1603, 0.1316,\n",
            "        0.0844, 0.1340, 0.1071, 0.1299, 0.1256, 0.1294, 0.1450, 0.1463, 0.1130,\n",
            "        0.1033, 0.1138, 0.1301, 0.1269, 0.1101, 0.1092, 0.1107, 0.1394, 0.1096,\n",
            "        0.1409, 0.1136, 0.1245, 0.1563, 0.0978, 0.1332, 0.1306, 0.1251, 0.1053,\n",
            "        0.0893, 0.1315, 0.1543, 0.1404, 0.1168, 0.1150, 0.1199, 0.1315, 0.1299,\n",
            "        0.1214, 0.1534, 0.1311, 0.1314, 0.1447, 0.1121, 0.1858, 0.1249, 0.1324,\n",
            "        0.1421, 0.3037, 0.1091, 0.1268, 0.1194, 0.1413, 0.1073, 0.1445, 0.1089,\n",
            "        0.1172, 0.1049, 0.1084, 0.1059, 0.1151, 0.1312, 0.1009, 0.1118, 0.1013,\n",
            "        0.1071, 0.0874, 0.1138, 0.1175, 0.1413, 0.1320, 0.1031, 0.1241, 0.1133,\n",
            "        0.1316, 0.0924, 0.1087, 0.1358, 0.1302, 0.1157, 0.1386, 0.1895, 0.1023,\n",
            "        0.1313, 0.1002, 0.1025, 0.1304, 0.1162, 0.1175, 0.0967, 0.1160, 0.1062,\n",
            "        0.1312, 0.1298, 0.0692, 0.1209, 0.1242, 0.1167, 0.1046, 0.1244, 0.1404,\n",
            "        0.1274, 0.1189, 0.1192, 0.1236, 0.0936, 0.1338, 0.1317, 0.1303, 0.1187,\n",
            "        0.1325, 0.0982, 0.1431, 0.1091, 0.1123, 0.1245, 0.1304, 0.1164, 0.1175,\n",
            "        0.1307, 0.1194, 0.1173, 0.1304, 0.1167, 0.1276, 0.1185, 0.1529, 0.1046,\n",
            "        0.1051, 0.1314, 0.0824, 0.1396, 0.0920, 0.1121, 0.0997, 0.1423, 0.0878,\n",
            "        0.1215, 0.1188, 0.1327, 0.1119, 0.1013, 0.1257, 0.1131, 0.1370, 0.1120,\n",
            "        0.1131, 0.1151, 0.1234, 0.1040, 0.0918, 0.1609, 0.1542, 0.1277, 0.1123,\n",
            "        0.1309, 0.1222, 0.1399, 0.1284, 0.1079, 0.1151, 0.1528, 0.1255, 0.1571,\n",
            "        0.1329, 0.1711, 0.1149, 0.1210, 0.1180, 0.1353, 0.0900, 0.1218, 0.1311,\n",
            "        0.0856, 0.1039, 0.1156, 0.1160, 0.1057, 0.1191, 0.1037, 0.1100, 0.1313,\n",
            "        0.1836, 0.1017, 0.1151, 0.1224, 0.1351, 0.1169, 0.1201, 0.1339],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn1.bias', tensor([-0.0812, -0.1227, -0.1292, -0.1444, -0.0869, -0.1354, -0.1678, -0.1375,\n",
            "        -0.0879, -0.1106, -0.1312, -0.1236, -0.1000, -0.1266, -0.1070, -0.1389,\n",
            "        -0.0392, -0.1332, -0.1027, -0.1144, -0.0944, -0.1197, -0.0778, -0.1012,\n",
            "        -0.1296, -0.1175, -0.1276, -0.1101, -0.1348, -0.0965, -0.1094, -0.1254,\n",
            "        -0.1716, -0.0928, -0.1283, -0.1227, -0.0906, -0.1211, -0.0719, -0.0811,\n",
            "        -0.1056, -0.1357, -0.1190, -0.1013, -0.1003, -0.0879, -0.1664, -0.1313,\n",
            "        -0.1293, -0.1561, -0.1011, -0.1082, -0.0998, -0.1319, -0.1222, -0.1161,\n",
            "        -0.1290, -0.1326, -0.1275, -0.1066, -0.1132, -0.1054, -0.0947, -0.0763,\n",
            "        -0.0964, -0.0963, -0.0735, -0.0832, -0.0739, -0.1858, -0.1426, -0.1176,\n",
            "        -0.0458, -0.0950, -0.0567, -0.1373, -0.1202, -0.1279, -0.1505, -0.1218,\n",
            "        -0.0801, -0.1277, -0.0682, -0.0527, -0.1006, -0.1129, -0.1002, -0.1450,\n",
            "        -0.1223, -0.1728, -0.0428, -0.1289, -0.1221, -0.1343, -0.1187, -0.1378,\n",
            "        -0.1285, -0.1363, -0.1457, -0.1408, -0.1317, -0.0935, -0.1376, -0.1346,\n",
            "        -0.0929, -0.1083, -0.1357, -0.1289, -0.0259, -0.1544, -0.1570, -0.1128,\n",
            "        -0.1096, -0.1171, -0.0960, -0.1020, -0.1090, -0.1233, -0.1019, -0.1306,\n",
            "        -0.1164, -0.1079, -0.1033, -0.0741, -0.0571, -0.0955, -0.1534, -0.0905,\n",
            "        -0.1105, -0.0952, -0.1102, -0.1360, -0.1493, -0.1384, -0.1185, -0.1253,\n",
            "        -0.1388, -0.0933, -0.1230, -0.0955, -0.1353, -0.1286, -0.1334, -0.0851,\n",
            "        -0.1383, -0.0822, -0.0881, -0.1436, -0.0849, -0.1422, -0.0997, -0.1415,\n",
            "        -0.1263, -0.1154, -0.0793, -0.1240, -0.1297, -0.1562, -0.0762, -0.1632,\n",
            "        -0.1269,  0.0114, -0.1159, -0.1116, -0.1582, -0.1132, -0.0924, -0.1231,\n",
            "        -0.1227, -0.1338, -0.1116, -0.1471, -0.0896, -0.1181, -0.1530, -0.1111,\n",
            "        -0.0928, -0.1277, -0.0818, -0.0929, -0.1133, -0.1140, -0.1268, -0.1596,\n",
            "        -0.0954, -0.0935, -0.1264, -0.1214, -0.1294, -0.1335, -0.0730, -0.1732,\n",
            "        -0.0196, -0.1299, -0.0970, -0.1067, -0.1144, -0.1449, -0.1398, -0.1407,\n",
            "        -0.1251, -0.0895, -0.0749, -0.1348, -0.0967, -0.1917, -0.1162, -0.0848,\n",
            "        -0.0909, -0.1330, -0.0759, -0.0850, -0.1539, -0.0863, -0.1293, -0.1118,\n",
            "        -0.0937, -0.1356, -0.1398, -0.1167, -0.1326, -0.1301, -0.0106, -0.0598,\n",
            "        -0.1356, -0.1341, -0.0757, -0.1015, -0.1281, -0.1082, -0.0846, -0.0991,\n",
            "        -0.1398, -0.1126, -0.1058, -0.1407, -0.1213, -0.1324, -0.1456, -0.1360,\n",
            "        -0.1351, -0.1053, -0.1238, -0.0740, -0.1104, -0.1225, -0.1268, -0.1265,\n",
            "        -0.0869, -0.1555, -0.0926, -0.1684, -0.0899, -0.1571, -0.1144, -0.1264,\n",
            "        -0.1121, -0.1239, -0.1398, -0.1316, -0.1149, -0.1374, -0.1444, -0.0772,\n",
            "        -0.1308, -0.1549, -0.1202, -0.1648, -0.1079, -0.1367, -0.1189, -0.1378,\n",
            "        -0.0994, -0.1155, -0.1283, -0.0997, -0.1001, -0.0693, -0.1172, -0.1250,\n",
            "        -0.1209, -0.1041, -0.0746, -0.0347, -0.1472, -0.1087, -0.1072, -0.1105,\n",
            "        -0.1153, -0.1331, -0.1363, -0.1363, -0.0861, -0.1710, -0.1300, -0.0776,\n",
            "        -0.1373, -0.1191, -0.0742, -0.0924, -0.0702, -0.0942,  0.0228, -0.1168,\n",
            "        -0.1347, -0.1177, -0.1036, -0.1134, -0.0727, -0.1386,  0.0159, -0.0974,\n",
            "         0.0440, -0.1048, -0.1064, -0.1123, -0.0897, -0.1141, -0.0943, -0.0920,\n",
            "        -0.1662, -0.1099, -0.1754, -0.0985, -0.1199, -0.1248, -0.0955, -0.1145,\n",
            "        -0.1284, -0.1535, -0.1292, -0.1376, -0.1325, -0.1460, -0.1345, -0.1495,\n",
            "        -0.1368, -0.1087, -0.1457,  0.0314, -0.1188, -0.0876, -0.1324, -0.0882,\n",
            "        -0.1505, -0.1426, -0.0533, -0.1369, -0.1023, -0.1005, -0.1104, -0.0929,\n",
            "        -0.1144, -0.0936, -0.1396, -0.1208, -0.1376, -0.1234, -0.1657, -0.1158,\n",
            "        -0.1089, -0.1270, -0.1182, -0.0525, -0.1670, -0.1098, -0.1692, -0.1172,\n",
            "        -0.1009, -0.1275, -0.2463, -0.1381, -0.0724, -0.1130, -0.1442, -0.1150,\n",
            "        -0.1742, -0.0963, -0.0847, -0.0884, -0.1344, -0.0780, -0.1562, -0.0980,\n",
            "        -0.1064,  0.0386, -0.1302, -0.1238, -0.1153, -0.0846, -0.1379, -0.1547,\n",
            "        -0.1147, -0.0614, -0.1380, -0.0988, -0.1335, -0.1342, -0.1336, -0.1201,\n",
            "        -0.0948, -0.1563, -0.1102, -0.1243, -0.1452, -0.1063, -0.1378, -0.1561,\n",
            "        -0.1149, -0.1332, -0.1152, -0.1324, -0.0738, -0.1064, -0.1096, -0.1471,\n",
            "        -0.0279, -0.1093, -0.0872, -0.1266, -0.0759, -0.1021, -0.1112, -0.1080,\n",
            "        -0.0941, -0.0719, -0.1305, -0.1200, -0.1755, -0.0621, -0.1103, -0.0791,\n",
            "        -0.0801, -0.1355, -0.1373, -0.1493, -0.1013, -0.0812, -0.1232, -0.0788,\n",
            "        -0.1213, -0.1048, -0.1003, -0.1782, -0.0972, -0.1182, -0.1266, -0.1457,\n",
            "        -0.1190, -0.0922, -0.0839, -0.1088,  0.0178, -0.1737, -0.1152, -0.1061,\n",
            "        -0.1327, -0.1296, -0.1197, -0.1348, -0.1330, -0.1438, -0.1100, -0.1220,\n",
            "        -0.1314, -0.1075, -0.1719, -0.0844, -0.1045, -0.0858, -0.1182, -0.1273,\n",
            "        -0.1017, -0.0966, -0.1304, -0.1147, -0.1010, -0.1272, -0.1328, -0.1302,\n",
            "        -0.0995, -0.1096, -0.1141, -0.1630, -0.1473, -0.1555, -0.1090, -0.0533,\n",
            "        -0.0941, -0.1205, -0.1271, -0.1011, -0.1195, -0.1142, -0.1538,  0.0143,\n",
            "        -0.1616, -0.1339, -0.1547, -0.1186, -0.1068, -0.1406, -0.0852, -0.1022,\n",
            "        -0.2359, -0.1545, -0.1199, -0.1294, -0.1233, -0.1312, -0.1314, -0.1686],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn1.running_mean', tensor([ 3.4828e-01, -1.8890e-01,  3.5555e-01, -2.7652e-01, -1.6724e-01,\n",
            "        -3.2803e-01, -3.5272e-01,  6.2912e-01,  1.9584e-01, -1.2622e-01,\n",
            "        -3.5542e-01, -3.4683e-01,  7.1927e-02, -3.8385e-01, -1.1811e-01,\n",
            "         6.5330e-02,  4.0737e-01,  6.3253e-01, -1.8199e-01, -1.3606e-01,\n",
            "        -2.4626e-01, -3.2065e-01, -3.4156e-01, -2.9770e-01, -9.0998e-02,\n",
            "        -1.8540e-01, -3.0828e-02, -1.7997e-01,  5.0336e-01, -1.3512e-01,\n",
            "        -2.7743e-01, -1.1877e-01,  6.7302e-01, -2.5225e-01, -4.5452e-02,\n",
            "        -6.1537e-02, -2.0578e-01, -1.5859e-01,  1.9977e-01, -2.3605e-01,\n",
            "         1.2040e-01, -2.5628e-01, -1.3753e-01, -3.0125e-01, -3.2868e-01,\n",
            "        -4.2686e-01,  4.9980e-01, -8.2022e-02, -3.8903e-01,  4.7969e-02,\n",
            "        -3.2001e-01,  5.0123e-01, -1.7186e-01, -3.5590e-01, -4.5395e-01,\n",
            "        -2.8028e-01,  2.4468e-01, -1.7567e-01, -1.7376e-01, -1.2215e-01,\n",
            "        -7.5291e-01, -4.6552e-01, -2.3712e-01,  3.2932e-01, -9.8865e-02,\n",
            "        -3.0558e-01, -5.3512e-01,  4.5338e-01, -2.8069e-01, -5.4588e-01,\n",
            "         5.8840e-01, -3.7604e-01, -2.9296e-01, -4.3396e-01,  3.2322e-01,\n",
            "        -1.4497e-01, -1.7015e-01, -1.4051e-01, -5.5182e-01,  2.0380e-04,\n",
            "        -4.3250e-01, -3.5330e-01, -3.8372e-01, -1.3297e-01,  4.5335e-02,\n",
            "        -1.4575e-01,  7.9489e-02, -1.2968e-01, -2.2451e-01, -1.9216e-01,\n",
            "        -3.9369e-01, -3.2977e-01,  5.7739e-01,  5.4874e-01, -1.8604e-01,\n",
            "        -3.9645e-01, -4.1761e-01, -3.7431e-01, -2.8766e-01, -4.5291e-01,\n",
            "         1.3186e-03, -3.3254e-01, -3.5480e-01, -2.8979e-01, -2.5540e-01,\n",
            "        -3.2295e-01, -3.9116e-01,  2.9729e-01, -4.1162e-01, -9.3927e-02,\n",
            "        -8.7424e-02, -3.7022e-01,  7.5181e-03, -3.9342e-01, -3.5486e-01,\n",
            "        -5.3483e-01, -1.5146e-01, -3.3255e-01,  3.0152e-01, -2.4170e-01,\n",
            "        -4.8473e-02, -2.1533e-01, -5.4765e-01, -2.4682e-02, -3.8492e-01,\n",
            "        -1.9239e-01, -2.3817e-01, -2.4004e-01, -1.6160e-01, -5.1260e-02,\n",
            "        -5.3050e-02, -1.9519e-01,  6.1332e-01, -3.7460e-01,  2.8110e-01,\n",
            "        -3.4815e-01,  9.7934e-03, -3.4791e-01, -4.3292e-01, -1.9332e-01,\n",
            "        -4.6567e-02,  6.2175e-01,  1.6883e-01, -7.3500e-02,  1.5508e-01,\n",
            "        -3.1258e-01, -3.5961e-01,  5.9935e-01,  8.0626e-02, -2.2794e-01,\n",
            "        -2.7688e-01, -2.9706e-01, -1.6463e-01, -1.7503e-01, -4.1774e-01,\n",
            "        -4.0879e-01, -4.7388e-02, -2.3064e-01, -2.4453e-01,  5.8821e-01,\n",
            "        -2.7451e-01, -4.2223e-01,  4.5790e-02, -2.3438e-01, -3.6030e-01,\n",
            "         3.4510e-02,  1.4877e-01, -1.2014e-01, -2.2901e-01, -1.5515e-01,\n",
            "        -3.9195e-01,  4.1218e-01, -2.5330e-01, -4.2871e-01, -3.9963e-01,\n",
            "        -1.2032e-01, -4.4380e-01, -5.4388e-01, -4.1694e-01, -2.6125e-01,\n",
            "         1.2439e-01, -3.3446e-01, -2.5431e-01, -3.9517e-01, -3.7764e-01,\n",
            "        -2.0617e-01, -4.0936e-01, -1.3203e-01, -2.2676e-01, -1.8793e-01,\n",
            "        -2.0289e-01, -3.4939e-01,  1.5273e-01, -3.6324e-01, -1.2805e-01,\n",
            "        -3.3971e-01, -3.7198e-01, -4.2011e-01, -1.2898e-01,  2.3592e-01,\n",
            "        -3.3415e-01, -2.4246e-01, -1.8788e-02, -1.4141e-01, -2.9911e-01,\n",
            "        -3.2038e-01, -3.3726e-01, -1.6131e-01, -2.0196e-01, -2.0643e-01,\n",
            "        -2.5820e-01, -3.3491e-01, -2.3743e-03, -2.8146e-01, -4.2208e-02,\n",
            "         1.4121e-01, -1.4045e-01,  2.7690e-01,  6.5586e-02,  4.7567e-01,\n",
            "         3.3175e-01, -2.7979e-01, -2.1009e-01, -3.3104e-01, -4.4250e-02,\n",
            "        -3.4371e-01,  1.3565e-01, -9.4801e-02, -2.1959e-01, -3.7119e-01,\n",
            "        -1.8577e-01, -3.4893e-01,  5.3019e-01, -3.6810e-01, -4.0288e-01,\n",
            "        -2.5101e-01,  4.9932e-03, -4.0310e-01, -3.2279e-01,  6.9586e-01,\n",
            "        -3.3298e-01, -2.2931e-01, -2.9477e-01, -4.7892e-01, -2.8171e-01,\n",
            "         6.2018e-01, -1.8439e-01, -2.5793e-01, -9.5704e-02, -3.2049e-01,\n",
            "        -4.0234e-01, -1.5848e-02, -7.9392e-02, -1.7903e-01,  5.7449e-01,\n",
            "        -3.4888e-01, -2.4836e-01, -3.5062e-01, -2.0521e-01, -2.3173e-01,\n",
            "        -3.6536e-01,  6.1217e-01, -8.6021e-02, -4.2240e-01, -1.1904e-01,\n",
            "        -4.7696e-02,  4.8241e-01, -3.0841e-02, -2.5770e-01,  2.2056e-01,\n",
            "         5.2709e-01,  2.9375e-01, -1.8576e-01,  4.1462e-01, -1.6133e-01,\n",
            "        -3.3843e-01,  2.6054e-01,  1.1380e-01, -3.6069e-01, -5.8577e-02,\n",
            "        -2.0828e-01, -2.3707e-02, -1.7126e-01, -5.3505e-02, -2.6649e-01,\n",
            "        -3.1055e-01, -2.1610e-01, -1.2931e-01, -2.5754e-01, -3.4244e-01,\n",
            "         2.5269e-01,  3.8118e-01, -4.1999e-02, -2.6059e-01, -2.5023e-01,\n",
            "        -1.3033e-01,  1.2452e-01,  7.2404e-01, -2.5558e-01, -2.1320e-01,\n",
            "        -2.3595e-01, -1.4479e-02,  3.4671e-01, -4.8744e-01,  4.0414e-01,\n",
            "        -3.8763e-01, -3.0531e-01, -3.1543e-01, -1.0663e-01, -2.1142e-01,\n",
            "         1.2862e-01, -2.9991e-01, -7.3877e-02, -2.6126e-01, -2.5771e-01,\n",
            "        -9.8563e-02, -4.0085e-01, -1.6155e-01, -6.1021e-02, -1.8509e-01,\n",
            "        -1.4797e-01, -2.4486e-01, -8.1139e-02, -7.7878e-02,  1.5638e-02,\n",
            "        -2.6056e-01, -3.8252e-01, -2.6804e-01, -3.6909e-01, -4.3035e-01,\n",
            "        -4.2221e-02,  3.1375e-02, -4.8529e-01, -3.6103e-01,  2.0220e-01,\n",
            "        -4.3640e-01,  3.8854e-02, -1.5548e-01, -5.2864e-03,  5.0914e-01,\n",
            "         1.9321e-01,  1.1917e-02, -2.2516e-01, -8.8239e-02,  6.9544e-01,\n",
            "        -3.6647e-01, -2.9457e-01, -3.4709e-02,  2.9651e-01,  7.1417e-02,\n",
            "        -1.2621e-02, -2.6403e-01, -1.1329e-01, -3.3159e-01, -3.5711e-01,\n",
            "         1.0408e-02,  6.9404e-01, -3.9968e-01,  9.5831e-02, -1.9395e-02,\n",
            "        -1.5416e-01, -1.5673e-01, -4.3145e-01, -3.2039e-01, -4.1902e-01,\n",
            "        -1.6383e-01, -2.8706e-01,  4.6153e-02, -2.3667e-01, -7.1908e-02,\n",
            "         4.6695e-01, -3.8569e-01, -1.1841e-01,  5.0168e-01, -2.8561e-01,\n",
            "         4.2481e-02, -4.0073e-01,  4.0406e-01, -2.1780e-01, -3.6197e-01,\n",
            "        -3.4895e-01, -5.0854e-01, -3.8411e-01, -2.7760e-01,  4.6853e-01,\n",
            "         8.7956e-03,  3.2048e-01, -2.9839e-01, -1.8187e-01, -1.4180e-01,\n",
            "        -6.1232e-01, -3.9145e-01, -3.8359e-01,  5.9579e-02,  6.7931e-01,\n",
            "        -2.8651e-01,  3.7786e-01, -1.3954e-01, -3.5315e-01,  4.1978e-01,\n",
            "        -2.5389e-01, -1.2190e-01, -2.1436e-01, -2.5119e-01, -4.0154e-01,\n",
            "        -3.2265e-01,  2.2716e-01,  2.5276e-01, -1.3340e-01,  7.0330e-01,\n",
            "        -3.6538e-01, -1.1460e-01, -3.6577e-01,  1.5149e-01,  9.8216e-03,\n",
            "         4.6658e-01, -2.6362e-02, -4.0349e-01, -1.3000e-01,  3.2180e-01,\n",
            "        -2.0932e-01, -1.3256e-01, -2.7197e-01, -3.5966e-01, -1.2452e-01,\n",
            "        -2.7880e-02, -3.0008e-01, -1.4916e-01, -5.4924e-02, -4.5540e-01,\n",
            "        -1.9251e-02, -3.7580e-01, -3.5968e-01,  1.4339e-01, -1.6085e-01,\n",
            "        -1.5367e-01, -2.5959e-01, -1.0068e-01,  2.6950e-01, -4.0730e-01,\n",
            "        -1.6861e-01,  5.8920e-01, -1.5761e-01,  5.2415e-01, -4.2421e-01,\n",
            "        -4.7342e-01, -1.8446e-01, -3.3473e-01, -2.6609e-01, -2.9002e-01,\n",
            "        -2.7613e-01, -4.4354e-01,  6.8555e-02,  6.7058e-02, -2.9234e-01,\n",
            "         2.4694e-01, -5.5034e-02, -2.4288e-01, -2.2885e-01, -4.2295e-02,\n",
            "        -2.6945e-02,  4.8240e-01, -1.8890e-01, -4.6041e-01, -2.9491e-01,\n",
            "         3.5019e-01,  8.7065e-02, -2.2541e-01, -3.0731e-01, -2.2107e-01,\n",
            "        -2.7637e-01, -3.7634e-02, -2.6019e-01, -4.5270e-01, -3.3817e-01,\n",
            "        -4.4346e-01, -1.4073e-01, -1.6159e-01, -9.1337e-02, -4.0359e-01,\n",
            "        -2.6815e-01, -2.9894e-01, -3.6173e-01,  4.0744e-02,  4.7852e-01,\n",
            "         1.9891e-02, -1.9286e-01, -1.6419e-03, -2.6309e-01, -5.0618e-02,\n",
            "        -3.8350e-01, -5.0037e-01, -1.7820e-01,  1.0407e-01, -3.5100e-01,\n",
            "        -3.4209e-01,  5.8727e-01,  5.3501e-01,  5.0204e-01,  2.0748e-01,\n",
            "        -3.1728e-01,  8.0549e-02, -8.1174e-02, -3.0706e-01, -1.8661e-01,\n",
            "        -3.4780e-01,  2.3974e-01, -2.8465e-01, -1.6761e-01, -3.4673e-01,\n",
            "        -2.9072e-01,  6.5648e-01], device='cuda:0')), ('backbone.layer4.2.bn1.running_var', tensor([0.0963, 0.0594, 0.1883, 0.1221, 0.1128, 0.0873, 0.1748, 0.2250, 0.1285,\n",
            "        0.0826, 0.1268, 0.2560, 0.1253, 0.2413, 0.1138, 0.0842, 0.2116, 0.1972,\n",
            "        0.1212, 0.0526, 0.1321, 0.0904, 0.1472, 0.0646, 0.3024, 0.1449, 0.1174,\n",
            "        0.0600, 0.1555, 0.1033, 0.0667, 0.0860, 0.1487, 0.0881, 0.0852, 0.1098,\n",
            "        0.0965, 0.1672, 0.1946, 0.1437, 0.2307, 0.1823, 0.1516, 0.2323, 0.2057,\n",
            "        0.1802, 0.1541, 0.1301, 0.2134, 0.0654, 0.1093, 0.1858, 0.1226, 0.1471,\n",
            "        0.1344, 0.0599, 0.1632, 0.1439, 0.1047, 0.0752, 0.2155, 0.0812, 0.1127,\n",
            "        0.2101, 0.2285, 0.1166, 0.2010, 0.0906, 0.1679, 0.1712, 0.1773, 0.1011,\n",
            "        0.1156, 0.1544, 0.1149, 0.1233, 0.2110, 0.0802, 0.1835, 0.1611, 0.1618,\n",
            "        0.1983, 0.2422, 0.1557, 0.0731, 0.0783, 0.0630, 0.1153, 0.1442, 0.0993,\n",
            "        0.1904, 0.0998, 0.1978, 0.2543, 0.0342, 0.0934, 0.1423, 0.1531, 0.1180,\n",
            "        0.0728, 0.2184, 0.1760, 0.1413, 0.1010, 0.1136, 0.1819, 0.1459, 0.1691,\n",
            "        0.2370, 0.0895, 0.2190, 0.2360, 0.0863, 0.1203, 0.1711, 0.1338, 0.1321,\n",
            "        0.1050, 0.0740, 0.1515, 0.1263, 0.2189, 0.1972, 0.1746, 0.1245, 0.1163,\n",
            "        0.2292, 0.1432, 0.0871, 0.0869, 0.1458, 0.0891, 0.1815, 0.1926, 0.1453,\n",
            "        0.1154, 0.1627, 0.1340, 0.0862, 0.0947, 0.2146, 0.2455, 0.0934, 0.1215,\n",
            "        0.0926, 0.1284, 0.1144, 0.2072, 0.0674, 0.0937, 0.1324, 0.1322, 0.1168,\n",
            "        0.1228, 0.1362, 0.3073, 0.1785, 0.0790, 0.1485, 0.2318, 0.1637, 0.2129,\n",
            "        0.2951, 0.0846, 0.1075, 0.2347, 0.0705, 0.0845, 0.0922, 0.1291, 0.1252,\n",
            "        0.1500, 0.0686, 0.1775, 0.1920, 0.1237, 0.4232, 0.2627, 0.0869, 0.1077,\n",
            "        0.0920, 0.1222, 0.0721, 0.1215, 0.1014, 0.1431, 0.1942, 0.1899, 0.1824,\n",
            "        0.1450, 0.0762, 0.1198, 0.1727, 0.1021, 0.2460, 0.1042, 0.1184, 0.1981,\n",
            "        0.1409, 0.0689, 0.1613, 0.1110, 0.1764, 0.1170, 0.1134, 0.1677, 0.1019,\n",
            "        0.1350, 0.0606, 0.0892, 0.1095, 0.1290, 0.1664, 0.1481, 0.0815, 0.0712,\n",
            "        0.1271, 0.1329, 0.2796, 0.2194, 0.1356, 0.1285, 0.3496, 0.1840, 0.2172,\n",
            "        0.1948, 0.1825, 0.0582, 0.1234, 0.1059, 0.1542, 0.1143, 0.1946, 0.1705,\n",
            "        0.0788, 0.0382, 0.1132, 0.1711, 0.1678, 0.2398, 0.1458, 0.1259, 0.1144,\n",
            "        0.0991, 0.1293, 0.1751, 0.1257, 0.1526, 0.0840, 0.1305, 0.1480, 0.1911,\n",
            "        0.0620, 0.1905, 0.1616, 0.0946, 0.1091, 0.1518, 0.2068, 0.1127, 0.1394,\n",
            "        0.2443, 0.0931, 0.2855, 0.1057, 0.0939, 0.1919, 0.1304, 0.0748, 0.0604,\n",
            "        0.1730, 0.1215, 0.1603, 0.2425, 0.0455, 0.3568, 0.1742, 0.1347, 0.2288,\n",
            "        0.0645, 0.2278, 0.0903, 0.1018, 0.1721, 0.1426, 0.1885, 0.0996, 0.0999,\n",
            "        0.1055, 0.2080, 0.1355, 0.2635, 0.1553, 0.1182, 0.1140, 0.0936, 0.1719,\n",
            "        0.2210, 0.0652, 0.1326, 0.0943, 0.1686, 0.3653, 0.1311, 0.1755, 0.0776,\n",
            "        0.1221, 0.0863, 0.2091, 0.0982, 0.1158, 0.1338, 0.2393, 0.0764, 0.1201,\n",
            "        0.2459, 0.2062, 0.1713, 0.3535, 0.0596, 0.1419, 0.1214, 0.1677, 0.2492,\n",
            "        0.1160, 0.1504, 0.2228, 0.0800, 0.1311, 0.1128, 0.0354, 0.1865, 0.1628,\n",
            "        0.1378, 0.1184, 0.2434, 0.1565, 0.1173, 0.1017, 0.1943, 0.0990, 0.1291,\n",
            "        0.1387, 0.1994, 0.1899, 0.2642, 0.1808, 0.1330, 0.1050, 0.0504, 0.1320,\n",
            "        0.1648, 0.1394, 0.1031, 0.1406, 0.0925, 0.1956, 0.1640, 0.1449, 0.1155,\n",
            "        0.1737, 0.0753, 0.1590, 0.1306, 0.1240, 0.0919, 0.1353, 0.1076, 0.1008,\n",
            "        0.2467, 0.2713, 0.1011, 0.1194, 0.1126, 0.1413, 0.0775, 0.1656, 0.2523,\n",
            "        0.1323, 0.3794, 0.1764, 0.1880, 0.2850, 0.0876, 0.1996, 0.1178, 0.2150,\n",
            "        0.2071, 0.2119, 0.1159, 0.1706, 0.2579, 0.1224, 0.1897, 0.1468, 0.1779,\n",
            "        0.2192, 0.2024, 0.2229, 0.1494, 0.1090, 0.0849, 0.1021, 0.1188, 0.1744,\n",
            "        0.1010, 0.0679, 0.1294, 0.2170, 0.1829, 0.1844, 0.1839, 0.1900, 0.2314,\n",
            "        0.1606, 0.2127, 0.0772, 0.0890, 0.1193, 0.0798, 0.0971, 0.0502, 0.1725,\n",
            "        0.1724, 0.0888, 0.0544, 0.1549, 0.2078, 0.1071, 0.2169, 0.0962, 0.1224,\n",
            "        0.1396, 0.0983, 0.1138, 0.0898, 0.1509, 0.1352, 0.0618, 0.1521, 0.0532,\n",
            "        0.1540, 0.1834, 0.1696, 0.1447, 0.1541, 0.1062, 0.2484, 0.0776, 0.0799,\n",
            "        0.2144, 0.1857, 0.2668, 0.1898, 0.1395, 0.1879, 0.1966, 0.1123, 0.1053,\n",
            "        0.1510, 0.0984, 0.2651, 0.0925, 0.1707, 0.1386, 0.1515, 0.0954, 0.1233,\n",
            "        0.1117, 0.0860, 0.3024, 0.1257, 0.1616, 0.1212, 0.0838, 0.3014, 0.1200,\n",
            "        0.0766, 0.1853, 0.0892, 0.1377, 0.1425, 0.2168, 0.0539, 0.1740, 0.1492,\n",
            "        0.1657, 0.3283, 0.1330, 0.1008, 0.1399, 0.1488, 0.1405, 0.1182, 0.0878,\n",
            "        0.1258, 0.2138, 0.1892, 0.1111, 0.1011, 0.1380, 0.1531, 0.0739, 0.1310,\n",
            "        0.0897, 0.1363, 0.1200, 0.1515, 0.1574, 0.1517, 0.1139, 0.2278],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn1.num_batches_tracked', tensor(99698, device='cuda:0')), ('backbone.layer4.2.conv2.weight', tensor([[[[ 3.9704e-04,  2.8941e-03,  9.6183e-03],\n",
            "          [ 8.2776e-03,  2.7813e-02,  1.1683e-02],\n",
            "          [-5.7245e-04,  8.5748e-03,  2.6366e-03]],\n",
            "\n",
            "         [[ 1.4943e-02,  1.6984e-02,  2.6466e-02],\n",
            "          [ 1.2481e-02,  2.0723e-02,  2.4913e-02],\n",
            "          [ 1.8948e-02,  1.3670e-02,  1.6476e-02]],\n",
            "\n",
            "         [[ 1.6967e-02,  1.7193e-02,  1.3246e-02],\n",
            "          [ 9.8680e-03,  1.5908e-02,  7.0069e-03],\n",
            "          [-8.7529e-04, -4.7545e-03, -1.2462e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9859e-03,  1.1004e-02,  3.7629e-03],\n",
            "          [ 4.7181e-03,  1.8965e-03,  5.8874e-03],\n",
            "          [ 9.3314e-03,  4.4124e-03,  9.2155e-03]],\n",
            "\n",
            "         [[-9.0050e-03, -2.0067e-02, -8.7663e-03],\n",
            "          [ 2.2678e-03,  7.8976e-03, -5.7266e-03],\n",
            "          [-1.7268e-03, -3.9366e-04,  1.9730e-03]],\n",
            "\n",
            "         [[ 3.0004e-02,  3.3156e-02,  2.4555e-02],\n",
            "          [ 3.0706e-02,  3.6794e-02,  1.7408e-02],\n",
            "          [ 1.1767e-02,  1.2892e-02,  7.6207e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.2155e-02, -6.3309e-03, -7.9367e-03],\n",
            "          [-1.4109e-02,  6.9534e-03, -1.4839e-02],\n",
            "          [-1.6227e-03, -1.0202e-02, -1.0212e-02]],\n",
            "\n",
            "         [[-6.3972e-04, -9.0246e-03, -2.2025e-03],\n",
            "          [-3.8804e-04, -3.4710e-02, -1.1715e-03],\n",
            "          [ 5.2873e-03,  8.2195e-03,  1.5156e-02]],\n",
            "\n",
            "         [[ 4.4406e-03,  2.7796e-03,  3.0501e-03],\n",
            "          [ 5.2766e-03,  9.3231e-03,  8.2610e-03],\n",
            "          [-7.1115e-04,  8.5854e-03,  1.4387e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.1197e-03, -3.3662e-03, -1.4810e-02],\n",
            "          [-1.0145e-02, -8.3496e-03,  1.2152e-02],\n",
            "          [-3.8206e-03,  1.5338e-02, -6.9647e-04]],\n",
            "\n",
            "         [[-2.5506e-02, -9.9152e-03, -5.7034e-03],\n",
            "          [-3.7515e-04, -1.4485e-02, -2.4378e-04],\n",
            "          [ 2.6559e-03, -2.0557e-02, -8.7453e-03]],\n",
            "\n",
            "         [[-1.5270e-03,  6.7615e-03, -5.8586e-03],\n",
            "          [ 1.5460e-03, -1.3791e-03,  4.9354e-03],\n",
            "          [-2.6750e-03, -3.1043e-03,  2.1927e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.2548e-04,  2.3513e-03,  1.7533e-02],\n",
            "          [-6.1381e-03, -2.4005e-02,  2.9370e-04],\n",
            "          [ 4.8482e-03, -9.4106e-03, -7.1412e-03]],\n",
            "\n",
            "         [[ 2.8416e-02,  2.2952e-02,  2.2087e-02],\n",
            "          [ 5.1809e-03, -1.8435e-02,  7.0664e-03],\n",
            "          [ 5.5954e-03,  8.5061e-04,  1.6440e-02]],\n",
            "\n",
            "         [[ 3.7593e-03,  5.2693e-03,  9.6525e-03],\n",
            "          [ 5.5836e-03,  6.3798e-03,  6.6646e-03],\n",
            "          [-1.9030e-03, -1.0591e-02, -4.5250e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0602e-04,  2.4490e-03,  1.4744e-03],\n",
            "          [-1.6100e-03, -1.1657e-02, -8.5761e-03],\n",
            "          [-1.6457e-03,  1.0246e-02, -2.5293e-03]],\n",
            "\n",
            "         [[ 1.8162e-03,  5.7937e-03,  8.1354e-03],\n",
            "          [ 1.5498e-02,  8.4048e-03,  8.6628e-03],\n",
            "          [ 3.4892e-02,  1.1560e-02,  1.3631e-02]],\n",
            "\n",
            "         [[-1.7122e-02, -2.2219e-02, -8.5412e-03],\n",
            "          [-6.2168e-03, -1.2108e-02, -1.1400e-02],\n",
            "          [-1.2040e-02, -1.7214e-02, -1.4289e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.5091e-02, -2.9151e-02, -2.4937e-02],\n",
            "          [-2.2417e-02, -2.9277e-02, -3.0389e-02],\n",
            "          [-1.0326e-02, -1.1330e-02, -8.3202e-03]],\n",
            "\n",
            "         [[-1.6909e-03,  4.3715e-03,  3.4124e-03],\n",
            "          [ 1.6816e-02,  5.0210e-03,  7.0388e-03],\n",
            "          [ 1.8391e-02,  1.2741e-02,  6.2119e-03]],\n",
            "\n",
            "         [[ 3.7458e-03,  8.8515e-03,  2.2407e-02],\n",
            "          [-1.0167e-02, -1.1101e-02,  1.8824e-03],\n",
            "          [-2.5891e-02, -3.2403e-02, -2.1687e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3532e-02,  1.9715e-02,  1.9658e-02],\n",
            "          [ 1.4086e-02,  1.4389e-02,  2.0983e-02],\n",
            "          [ 2.2360e-02,  1.5993e-02,  2.2049e-02]],\n",
            "\n",
            "         [[-7.3683e-04,  1.2795e-03,  4.5786e-04],\n",
            "          [-3.7417e-03,  1.3019e-03,  1.1589e-02],\n",
            "          [-8.5171e-03,  6.5659e-03, -5.3941e-03]],\n",
            "\n",
            "         [[ 8.9643e-03,  2.1181e-02,  3.1608e-02],\n",
            "          [-2.7690e-03,  5.6311e-03,  1.8762e-02],\n",
            "          [-1.3559e-02, -1.5843e-02, -8.5806e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.5525e-02, -1.4211e-02, -9.6907e-03],\n",
            "          [ 7.9271e-03,  9.3789e-03,  2.1693e-02],\n",
            "          [-1.1947e-02, -1.1716e-02, -5.7655e-03]],\n",
            "\n",
            "         [[ 1.7688e-02,  8.8556e-03,  9.3008e-03],\n",
            "          [ 1.2196e-02,  1.3612e-02,  9.3753e-03],\n",
            "          [ 1.1421e-02,  6.3137e-03,  3.8485e-03]],\n",
            "\n",
            "         [[ 2.5467e-03,  8.4528e-03,  9.2550e-03],\n",
            "          [ 4.1276e-03,  1.9338e-02,  1.3226e-02],\n",
            "          [-1.1460e-02, -1.6921e-02, -1.3556e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0842e-02,  1.8017e-02,  1.6904e-02],\n",
            "          [ 1.9220e-02,  2.2274e-02,  1.5102e-02],\n",
            "          [ 9.0200e-03,  1.1790e-02,  1.0088e-02]],\n",
            "\n",
            "         [[-5.9808e-04,  1.9133e-03,  2.5567e-03],\n",
            "          [-4.8556e-03,  3.2716e-03, -2.3288e-03],\n",
            "          [-6.4554e-03,  2.3664e-03, -2.2120e-05]],\n",
            "\n",
            "         [[ 1.7281e-02,  2.5107e-02,  1.9385e-02],\n",
            "          [ 1.1216e-02,  2.4363e-02,  2.5663e-02],\n",
            "          [-1.3269e-03, -6.2176e-03,  6.7169e-04]]],\n",
            "\n",
            "\n",
            "        [[[-9.3320e-04, -1.3919e-03, -1.8996e-03],\n",
            "          [-4.1821e-03, -4.4130e-03, -2.4330e-03],\n",
            "          [-3.7591e-03, -3.9801e-03, -3.6155e-03]],\n",
            "\n",
            "         [[ 4.3427e-03,  7.4075e-03,  8.6461e-03],\n",
            "          [ 7.6106e-03,  5.6575e-03,  7.2315e-03],\n",
            "          [ 7.1121e-03,  8.0667e-03,  9.9085e-03]],\n",
            "\n",
            "         [[-4.7291e-03, -8.3015e-03, -6.3358e-03],\n",
            "          [-8.1217e-03, -7.3634e-03, -7.8571e-03],\n",
            "          [-9.5516e-03, -9.0225e-03, -1.1068e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9492e-03,  1.8580e-04,  1.9050e-03],\n",
            "          [-3.7050e-03, -2.7251e-03, -1.5068e-03],\n",
            "          [ 3.9404e-03,  4.0411e-03, -8.1237e-04]],\n",
            "\n",
            "         [[ 7.5398e-04,  4.3734e-04,  1.5541e-03],\n",
            "          [-4.6249e-04,  5.3940e-04,  2.3859e-04],\n",
            "          [-1.5894e-03,  3.2281e-03,  1.0503e-03]],\n",
            "\n",
            "         [[-7.3109e-03, -7.6629e-03, -6.3214e-03],\n",
            "          [-1.2556e-02, -1.3140e-02, -1.1387e-02],\n",
            "          [-1.2889e-02, -1.1335e-02, -1.2671e-02]]]], device='cuda:0')), ('backbone.layer4.2.bn2.weight', tensor([0.0896, 0.1268, 0.1061, 0.1267, 0.1064, 0.1263, 0.1244, 0.1480, 0.1636,\n",
            "        0.1305, 0.1038, 0.1130, 0.1001, 0.1061, 0.0874, 0.1739, 0.1088, 0.1018,\n",
            "        0.0973, 0.1232, 0.0912, 0.1176, 0.1056, 0.1210, 0.1216, 0.1182, 0.1102,\n",
            "        0.1009, 0.1349, 0.1158, 0.1304, 0.1135, 0.1482, 0.1466, 0.1247, 0.1368,\n",
            "        0.1154, 0.0931, 0.1777, 0.0752, 0.0800, 0.0952, 0.1053, 0.1510, 0.1120,\n",
            "        0.1039, 0.0925, 0.1142, 0.1374, 0.1163, 0.1230, 0.1171, 0.1211, 0.1239,\n",
            "        0.1390, 0.1034, 0.1341, 0.1114, 0.1071, 0.1367, 0.1299, 0.1199, 0.0882,\n",
            "        0.1071, 0.1239, 0.0991, 0.1189, 0.1316, 0.1053, 0.1161, 0.1190, 0.0841,\n",
            "        0.1106, 0.1211, 0.1027, 0.1169, 0.2148, 0.1362, 0.1087, 0.1531, 0.0951,\n",
            "        0.0871, 0.1026, 0.1061, 0.1461, 0.0998, 0.1030, 0.0739, 0.1098, 0.0954,\n",
            "        0.1095, 0.0844, 0.1419, 0.1256, 0.1147, 0.1013, 0.1939, 0.1127, 0.1130,\n",
            "        0.1517, 0.1098, 0.1425, 0.1214, 0.1253, 0.1035, 0.1277, 0.1211, 0.1403,\n",
            "        0.1182, 0.1137, 0.1468, 0.0977, 0.1240, 0.0976, 0.1098, 0.1429, 0.1128,\n",
            "        0.1448, 0.1239, 0.1341, 0.0957, 0.1035, 0.1289, 0.0911, 0.1228, 0.1271,\n",
            "        0.1165, 0.0818, 0.1100, 0.1063, 0.0915, 0.1271, 0.1142, 0.1212, 0.0766,\n",
            "        0.1209, 0.1357, 0.1034, 0.1026, 0.1402, 0.0993, 0.1607, 0.1189, 0.0852,\n",
            "        0.1757, 0.1194, 0.1279, 0.0959, 0.1045, 0.1101, 0.1222, 0.1290, 0.1244,\n",
            "        0.1466, 0.1107, 0.1317, 0.0684, 0.1295, 0.1133, 0.1292, 0.1116, 0.1183,\n",
            "        0.1398, 0.1198, 0.1311, 0.1099, 0.1412, 0.1137, 0.1370, 0.1203, 0.1177,\n",
            "        0.1226, 0.1098, 0.1547, 0.1476, 0.1264, 0.1123, 0.1344, 0.1309, 0.1279,\n",
            "        0.1183, 0.0852, 0.1197, 0.1081, 0.1133, 0.1194, 0.1209, 0.1616, 0.1480,\n",
            "        0.1463, 0.1178, 0.1088, 0.1147, 0.1180, 0.0793, 0.1109, 0.1157, 0.1376,\n",
            "        0.0943, 0.1000, 0.1005, 0.1080, 0.1006, 0.1122, 0.0894, 0.0872, 0.1002,\n",
            "        0.1137, 0.0745, 0.1076, 0.1313, 0.1457, 0.0942, 0.1182, 0.1330, 0.1602,\n",
            "        0.1582, 0.1013, 0.1250, 0.0885, 0.1198, 0.1312, 0.1014, 0.0910, 0.1116,\n",
            "        0.1191, 0.1069, 0.1452, 0.1052, 0.1001, 0.1163, 0.1186, 0.1053, 0.0842,\n",
            "        0.1063, 0.1193, 0.1208, 0.1095, 0.1144, 0.1276, 0.1335, 0.1447, 0.1003,\n",
            "        0.1159, 0.1533, 0.1020, 0.0962, 0.1267, 0.1128, 0.1045, 0.1272, 0.1107,\n",
            "        0.0996, 0.1185, 0.1429, 0.1355, 0.1413, 0.1317, 0.1183, 0.1101, 0.0912,\n",
            "        0.1101, 0.1185, 0.1025, 0.1036, 0.1009, 0.0944, 0.1088, 0.0983, 0.1133,\n",
            "        0.1400, 0.1199, 0.1042, 0.1531, 0.0941, 0.1166, 0.1095, 0.1445, 0.0997,\n",
            "        0.1512, 0.1159, 0.1330, 0.1160, 0.1034, 0.0919, 0.1197, 0.1200, 0.1160,\n",
            "        0.1408, 0.1139, 0.0949, 0.0660, 0.1070, 0.1268, 0.1088, 0.0908, 0.1301,\n",
            "        0.1210, 0.1065, 0.1221, 0.1020, 0.1026, 0.1018, 0.1158, 0.1137, 0.1028,\n",
            "        0.0807, 0.0985, 0.0942, 0.1287, 0.1165, 0.1205, 0.1301, 0.1274, 0.1216,\n",
            "        0.1331, 0.1308, 0.0965, 0.0906, 0.1006, 0.1112, 0.1329, 0.1076, 0.0933,\n",
            "        0.1038, 0.1155, 0.1266, 0.1017, 0.1180, 0.1407, 0.1309, 0.1291, 0.1297,\n",
            "        0.1423, 0.1088, 0.1030, 0.1111, 0.1354, 0.1253, 0.1090, 0.1493, 0.1389,\n",
            "        0.0874, 0.1282, 0.0933, 0.1107, 0.1061, 0.1119, 0.0854, 0.1230, 0.1290,\n",
            "        0.1247, 0.1121, 0.1262, 0.1212, 0.1374, 0.0849, 0.1054, 0.0888, 0.1489,\n",
            "        0.0919, 0.1057, 0.0918, 0.1091, 0.1262, 0.0729, 0.1348, 0.1377, 0.1670,\n",
            "        0.1107, 0.1171, 0.1432, 0.1263, 0.1424, 0.1007, 0.1326, 0.0983, 0.1357,\n",
            "        0.1188, 0.1218, 0.1474, 0.1220, 0.1725, 0.1044, 0.1153, 0.1167, 0.1158,\n",
            "        0.0838, 0.1239, 0.0771, 0.0947, 0.1081, 0.1099, 0.1436, 0.1852, 0.1151,\n",
            "        0.0782, 0.0789, 0.1258, 0.1465, 0.1252, 0.0958, 0.1007, 0.0998, 0.0882,\n",
            "        0.0953, 0.1184, 0.1334, 0.0895, 0.1077, 0.1392, 0.1090, 0.0887, 0.1070,\n",
            "        0.1177, 0.0964, 0.1334, 0.1478, 0.0867, 0.1025, 0.0865, 0.1134, 0.0988,\n",
            "        0.0946, 0.1076, 0.1413, 0.1185, 0.1456, 0.1153, 0.1058, 0.1107, 0.1466,\n",
            "        0.1307, 0.0830, 0.1127, 0.1176, 0.0955, 0.1139, 0.1158, 0.1202, 0.0963,\n",
            "        0.1079, 0.1077, 0.1230, 0.0977, 0.0901, 0.1209, 0.1204, 0.1308, 0.0920,\n",
            "        0.1262, 0.1218, 0.1104, 0.1273, 0.1076, 0.1240, 0.1106, 0.1540, 0.1040,\n",
            "        0.1054, 0.1186, 0.0878, 0.1126, 0.1254, 0.1300, 0.1115, 0.1415, 0.1167,\n",
            "        0.0868, 0.1166, 0.1172, 0.1169, 0.1316, 0.1177, 0.1263, 0.1178, 0.0983,\n",
            "        0.0648, 0.1099, 0.1330, 0.1018, 0.1260, 0.1097, 0.0970, 0.1193, 0.1013,\n",
            "        0.1109, 0.1432, 0.1293, 0.1070, 0.1487, 0.1492, 0.1197, 0.0986, 0.1214,\n",
            "        0.1375, 0.1649, 0.1068, 0.1206, 0.0974, 0.1245, 0.1183, 0.0930, 0.1129,\n",
            "        0.1345, 0.1315, 0.1014, 0.1227, 0.1469, 0.1087, 0.0915, 0.1367],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn2.bias', tensor([-0.1001, -0.0255, -0.0384, -0.0593, -0.1136, -0.0806, -0.1029, -0.0836,\n",
            "        -0.1013, -0.0591, -0.0389, -0.0901, -0.0976, -0.0534, -0.0815, -0.1204,\n",
            "        -0.0717, -0.0725, -0.0858, -0.0351, -0.0679, -0.1069, -0.0419, -0.1060,\n",
            "        -0.1100, -0.0734, -0.0422, -0.0102, -0.1003, -0.0927, -0.0532, -0.0683,\n",
            "        -0.1453, -0.1477, -0.1045, -0.0660, -0.0729, -0.0714, -0.1350, -0.0304,\n",
            "        -0.0617, -0.0678, -0.0889, -0.0843, -0.1042, -0.0766, -0.0761, -0.0861,\n",
            "        -0.1036, -0.0826, -0.0774, -0.1113, -0.0854, -0.0828, -0.0298, -0.0612,\n",
            "        -0.0801, -0.0821, -0.0788, -0.0904, -0.1027, -0.0925, -0.0663, -0.1154,\n",
            "        -0.0707, -0.0312, -0.0555,  0.0740, -0.0825, -0.1128, -0.0806, -0.0528,\n",
            "        -0.0879, -0.0895, -0.0782, -0.1046, -0.0999, -0.0668, -0.0432, -0.0926,\n",
            "        -0.0741, -0.0649, -0.0203, -0.0922, -0.0744, -0.0506, -0.0523, -0.0601,\n",
            "        -0.0615, -0.0824, -0.0374, -0.0947, -0.1105, -0.0629, -0.0756, -0.0329,\n",
            "        -0.0726, -0.0884, -0.1040, -0.1211, -0.0640, -0.0720, -0.0999, -0.0770,\n",
            "        -0.0453, -0.0935, -0.0854, -0.0466, -0.1105, -0.0806, -0.0697,  0.0022,\n",
            "        -0.0357, -0.0258, -0.0696, -0.0738, -0.0831, -0.1136,  0.0019, -0.1088,\n",
            "        -0.0680, -0.0439, -0.0627, -0.0055, -0.0773, -0.1363, -0.0967, -0.0516,\n",
            "        -0.1027, -0.0938, -0.0599, -0.0532, -0.0849, -0.0554, -0.0492, -0.0461,\n",
            "        -0.0544, -0.0836, -0.0163, -0.0670, -0.0437, -0.1047, -0.0479, -0.0571,\n",
            "        -0.0877, -0.0921, -0.0750, -0.0655, -0.1026, -0.0813, -0.0907, -0.0877,\n",
            "        -0.0474, -0.0790, -0.0870, -0.0688, -0.0194, -0.0563, -0.0761, -0.1379,\n",
            "        -0.0659, -0.0526, -0.0243, -0.1158, -0.0984, -0.0483, -0.1211, -0.0913,\n",
            "        -0.0435, -0.0675, -0.0929, -0.0844, -0.0876, -0.1351, -0.0793, -0.0595,\n",
            "        -0.0538, -0.0866, -0.0448, -0.1189, -0.0722, -0.0564, -0.0874, -0.0901,\n",
            "        -0.0593, -0.0865, -0.0356, -0.0917, -0.0850, -0.1159, -0.0741, -0.0286,\n",
            "        -0.0571, -0.0549, -0.0540, -0.0759, -0.0704, -0.0491, -0.0484, -0.0707,\n",
            "        -0.0337, -0.0863, -0.0539, -0.0456, -0.0775, -0.0174, -0.0688, -0.0503,\n",
            "        -0.0486, -0.0525, -0.0564, -0.0145, -0.0891, -0.0926, -0.0752, -0.0926,\n",
            "        -0.1147, -0.0599, -0.0944, -0.0793, -0.0211, -0.0714, -0.0672, -0.0782,\n",
            "        -0.0959, -0.0328,  0.0021, -0.0791, -0.1188, -0.0741, -0.1011, -0.0390,\n",
            "        -0.0024, -0.0744, -0.0822, -0.0372, -0.0670, -0.0649, -0.0525, -0.0736,\n",
            "         0.0117, -0.0636, -0.0951, -0.0448, -0.0368, -0.1019, -0.0749, -0.1016,\n",
            "        -0.0532, -0.0686, -0.0823, -0.0882, -0.0789, -0.1033, -0.0661, -0.0521,\n",
            "        -0.1766, -0.0806, -0.1044, -0.0783, -0.0588, -0.0364, -0.0793, -0.1013,\n",
            "        -0.0599, -0.0740, -0.0794, -0.1059, -0.0399, -0.1011, -0.1021, -0.0280,\n",
            "        -0.0402, -0.1012, -0.0734, -0.1091, -0.0482, -0.0563, -0.0570, -0.0804,\n",
            "        -0.1044, -0.1179, -0.0799, -0.0975, -0.0844, -0.0286, -0.0717, -0.0485,\n",
            "        -0.0697, -0.0730, -0.0420,  0.0129, -0.0266, -0.1073, -0.0825, -0.0838,\n",
            "        -0.0630, -0.0860, -0.0571, -0.0573, -0.0276, -0.0706, -0.0603, -0.0705,\n",
            "        -0.0595, -0.0760, -0.0569, -0.1047, -0.0512, -0.0895, -0.0469, -0.0200,\n",
            "        -0.0940, -0.0741, -0.1145, -0.0436, -0.0674, -0.0861, -0.0629, -0.0943,\n",
            "        -0.0948, -0.1186, -0.0474, -0.0732, -0.0875, -0.0609, -0.0945, -0.0847,\n",
            "        -0.1048, -0.0849, -0.0689, -0.0530, -0.0839, -0.1230, -0.0314, -0.0727,\n",
            "        -0.0819, -0.0652, -0.0435, -0.0745, -0.0916, -0.0820, -0.0571, -0.0672,\n",
            "        -0.0914, -0.0544, -0.0623, -0.0724, -0.0879, -0.0490, -0.0863, -0.0549,\n",
            "        -0.0695, -0.1060, -0.0587, -0.0717, -0.0334, -0.0809,  0.0050, -0.1200,\n",
            "        -0.0311, -0.0364, -0.0611, -0.0566, -0.0773, -0.0299, -0.0848, -0.1013,\n",
            "        -0.1173, -0.0273, -0.0748, -0.1053, -0.0517, -0.1029, -0.0389, -0.0455,\n",
            "        -0.0737, -0.0607, -0.0732, -0.0627, -0.1376, -0.1034, -0.1199, -0.0643,\n",
            "        -0.1046, -0.0869, -0.0688, -0.0682, -0.0958, -0.0437, -0.0595, -0.0684,\n",
            "        -0.0692, -0.1153, -0.1251, -0.0417, -0.0916, -0.0196, -0.0754, -0.0606,\n",
            "        -0.1144, -0.0419, -0.0963, -0.0841, -0.0234, -0.0610, -0.0811, -0.1406,\n",
            "        -0.0273, -0.0468, -0.0608, -0.1019, -0.0875, -0.0428, -0.0539, -0.0483,\n",
            "        -0.0584, -0.0657, -0.0603, -0.0535, -0.0586, -0.0699, -0.0504, -0.0220,\n",
            "        -0.0669, -0.0571, -0.1337, -0.1267, -0.0838, -0.0705, -0.0389, -0.1577,\n",
            "        -0.1021, -0.0599, -0.0891, -0.0796, -0.0511, -0.0875, -0.0552, -0.0744,\n",
            "        -0.0729, -0.0976, -0.0755, -0.0392, -0.0641, -0.0538, -0.0872, -0.0928,\n",
            "        -0.0925, -0.0676, -0.0951, -0.0181, -0.0963, -0.0878, -0.1024, -0.0900,\n",
            "        -0.0398, -0.1114, -0.0404, -0.0729, -0.0290, -0.0327, -0.0066, -0.0499,\n",
            "        -0.1249, -0.0419, -0.0731, -0.0851, -0.0253, -0.0882, -0.0876, -0.0686,\n",
            "        -0.0563, -0.1074, -0.1167, -0.0473, -0.0556, -0.0616, -0.0576, -0.0524,\n",
            "        -0.0404, -0.0519, -0.0220, -0.0716, -0.0842, -0.0672, -0.0982, -0.0864,\n",
            "        -0.0575, -0.0978, -0.0775, -0.0912, -0.0343, -0.0625, -0.0802, -0.0591,\n",
            "        -0.1364, -0.1063, -0.0734, -0.0728, -0.0734, -0.0915, -0.0725, -0.0694,\n",
            "        -0.0972, -0.0594, -0.0700, -0.0974, -0.0679, -0.1092, -0.0644, -0.1300],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn2.running_mean', tensor([ 1.8994e-01, -8.3989e-02, -1.8384e-01, -1.7890e-01,  1.1144e-01,\n",
            "         7.2849e-02,  1.1673e-01, -1.1845e-01,  4.3747e-02, -1.6858e-01,\n",
            "        -1.6392e-01,  9.0182e-02,  6.1239e-02, -8.8837e-02,  4.9068e-02,\n",
            "         2.9533e-03,  3.6006e-02,  8.8049e-02,  1.0078e-01, -5.0547e-02,\n",
            "         2.4650e-02,  9.6846e-03, -5.7227e-02,  1.3396e-01,  6.6566e-02,\n",
            "        -1.8136e-02, -1.2284e-01, -1.5751e-01,  8.6838e-02,  1.9635e-03,\n",
            "        -1.6359e-01,  4.2822e-02, -2.4580e-02,  1.6013e-01, -1.0369e-01,\n",
            "        -1.3915e-01, -1.6854e-02,  5.2221e-02, -6.5563e-02, -1.5128e-01,\n",
            "         1.1316e-02,  5.5391e-02,  2.9563e-02, -2.1117e-01,  1.7226e-01,\n",
            "         3.6138e-02,  1.1143e-01, -1.0206e-01,  1.8112e-02, -5.0860e-02,\n",
            "         5.0217e-02,  8.9954e-02, -5.1887e-02, -2.1589e-01, -1.2359e-01,\n",
            "        -1.5505e-01, -4.2414e-02, -1.0733e-01,  4.9779e-02, -6.2102e-02,\n",
            "         6.5290e-02,  9.2149e-02, -6.3598e-02,  1.7025e-01, -2.0736e-01,\n",
            "        -1.3767e-01, -2.0512e-01,  1.1636e-01,  9.5765e-02, -7.7979e-02,\n",
            "         1.1743e-01, -6.6353e-02,  4.1537e-02, -3.4590e-03,  8.4618e-02,\n",
            "         9.7279e-03, -2.3184e-01,  1.9998e-02, -1.5626e-01,  3.1546e-02,\n",
            "         8.2858e-02,  4.3462e-02, -1.0921e-01, -1.6227e-01, -1.7824e-01,\n",
            "        -2.4129e-02,  3.8664e-02, -6.8963e-02,  6.0202e-02,  1.6081e-02,\n",
            "        -1.1420e-01,  4.8097e-02,  4.5805e-02, -2.2192e-01, -4.7982e-02,\n",
            "        -9.3496e-02,  1.3230e-02,  5.2877e-02, -2.0727e-01,  2.5513e-02,\n",
            "        -5.1059e-02, -8.8715e-02,  1.0136e-01,  7.6289e-02, -7.6538e-02,\n",
            "        -2.6263e-02,  9.2272e-02, -9.3748e-02, -1.2724e-01,  6.0104e-02,\n",
            "        -3.6141e-02, -1.2802e-01, -8.3494e-02, -1.3901e-01, -5.6542e-02,\n",
            "         8.1815e-02,  1.1329e-02, -3.8478e-02, -6.3967e-02, -7.8829e-02,\n",
            "        -1.5748e-01, -6.5718e-02, -1.7812e-01, -1.4307e-01, -6.8973e-02,\n",
            "        -9.3349e-02, -1.0337e-01, -6.2515e-02,  7.8033e-02,  7.5868e-02,\n",
            "        -3.1004e-02,  6.1409e-02, -4.9228e-02, -1.5278e-01,  4.6818e-02,\n",
            "        -1.7712e-01, -1.7408e-02,  8.1261e-02, -1.2438e-01, -1.5296e-01,\n",
            "        -3.4832e-03, -2.2774e-01, -1.5455e-01,  7.7658e-02,  7.6313e-02,\n",
            "         8.1699e-02, -1.7723e-01,  5.6116e-02,  1.1224e-02,  9.5543e-02,\n",
            "        -1.0166e-01,  1.0960e-01, -1.2828e-01, -2.6063e-02,  7.7172e-02,\n",
            "         1.3197e-01, -2.3740e-02, -1.1340e-01,  5.2525e-02, -8.0066e-02,\n",
            "         1.3603e-01, -1.7901e-01, -2.0800e-02,  9.7287e-02,  4.9242e-02,\n",
            "        -1.5156e-01,  1.1261e-01,  6.4820e-02, -1.4490e-01,  3.9618e-02,\n",
            "        -8.2675e-02,  3.7432e-02, -1.8887e-02,  1.3877e-02, -4.6973e-02,\n",
            "        -8.1603e-02, -1.6902e-01, -2.8982e-02, -9.5235e-02,  9.0525e-02,\n",
            "         3.5615e-02, -1.4891e-01,  3.6936e-02, -1.3231e-01, -9.2550e-02,\n",
            "         7.5271e-02, -7.8506e-02,  4.6948e-02, -2.3104e-02,  2.5418e-02,\n",
            "        -1.6256e-02, -1.4179e-01, -1.3594e-01, -1.8087e-01, -5.8915e-02,\n",
            "         1.3654e-01, -1.1104e-01, -4.5368e-02, -1.0678e-01,  2.9722e-02,\n",
            "        -1.3987e-01, -5.6374e-02, -2.6195e-02, -6.3364e-02, -1.1288e-01,\n",
            "        -6.4836e-02,  1.0026e-01, -1.3249e-01,  1.5490e-01,  4.0106e-02,\n",
            "        -1.2532e-01, -8.8661e-02,  6.4370e-02,  9.0694e-02,  9.0091e-03,\n",
            "        -2.2326e-01,  5.7072e-02, -4.5145e-02,  1.4521e-01, -1.5273e-01,\n",
            "        -6.9146e-02,  9.5812e-02,  9.8865e-02, -1.0636e-01,  7.8994e-02,\n",
            "        -4.2916e-02, -1.1198e-01,  8.0021e-03,  1.5569e-01, -1.2922e-03,\n",
            "         5.7540e-02, -1.0543e-01, -1.0187e-01, -5.5252e-02, -1.3799e-01,\n",
            "        -1.3549e-01,  6.4987e-02, -5.6329e-02,  3.8417e-02, -4.3024e-02,\n",
            "        -7.2160e-02,  9.7374e-03, -5.8024e-02, -9.1429e-02,  8.3784e-02,\n",
            "        -8.4108e-02,  8.8261e-02,  8.3255e-02, -1.8658e-01,  2.8529e-02,\n",
            "        -8.6676e-02, -7.8932e-02,  2.0440e-02,  8.5595e-02, -1.8005e-01,\n",
            "        -1.2721e-01, -8.9827e-02,  9.0640e-03,  1.6125e-02,  3.5760e-02,\n",
            "         2.2648e-02,  1.7311e-02,  1.1208e-01, -8.9949e-02,  8.0046e-02,\n",
            "         9.3484e-02, -8.7305e-02, -1.8944e-01, -1.8881e-01,  1.0669e-01,\n",
            "         8.2623e-02, -1.1480e-01,  4.5992e-02, -1.2980e-02, -5.6689e-02,\n",
            "         9.4893e-02,  1.7899e-03,  2.0379e-02, -1.2560e-01, -1.7032e-01,\n",
            "         1.0711e-01,  1.3449e-01, -1.5332e-02,  8.0382e-02, -2.2607e-03,\n",
            "        -1.2059e-02, -1.8829e-02, -6.9101e-02, -1.0534e-01,  6.7018e-02,\n",
            "        -2.0271e-01, -8.3891e-02, -8.1373e-02,  1.1702e-01,  1.5801e-01,\n",
            "        -1.7796e-01, -1.5884e-01, -1.4569e-01, -1.9661e-01, -4.2188e-02,\n",
            "        -1.1788e-01,  6.5855e-02,  2.1516e-03, -1.9561e-01, -1.6303e-01,\n",
            "        -1.1914e-01, -1.7476e-01, -1.1872e-01,  2.5025e-03,  7.2325e-02,\n",
            "        -9.9176e-02, -1.2634e-01,  1.2653e-01,  1.6959e-02,  6.0086e-02,\n",
            "        -1.0369e-01, -7.1970e-02,  1.1330e-01, -3.0433e-02,  1.2408e-01,\n",
            "         1.0722e-01,  3.3321e-02, -1.7011e-01, -2.9975e-02,  8.5353e-02,\n",
            "         9.6102e-04,  4.1223e-02, -1.0039e-01, -7.0099e-02, -3.0572e-02,\n",
            "        -2.0992e-01,  6.3302e-02, -1.2856e-01,  6.7077e-02, -2.7855e-02,\n",
            "         4.0362e-02,  1.2765e-01, -3.1827e-02, -1.4512e-01,  8.5535e-02,\n",
            "         8.1099e-02,  9.9991e-02,  1.8595e-04, -8.3665e-02, -1.7263e-02,\n",
            "        -1.6193e-01, -2.2754e-02, -5.2931e-02,  5.6321e-02, -1.5037e-01,\n",
            "         3.7753e-02, -1.3651e-01,  9.5859e-02,  5.1080e-03, -1.5710e-01,\n",
            "        -1.7015e-01, -1.4406e-01,  4.3133e-02, -8.8749e-02,  3.0318e-02,\n",
            "        -1.6722e-01, -1.5063e-01,  1.0480e-01,  9.6376e-02, -8.2703e-02,\n",
            "        -1.1220e-01,  7.4688e-02,  9.9371e-02, -1.1708e-02, -1.3621e-01,\n",
            "         3.5272e-02,  3.7792e-03, -1.3521e-01, -4.8209e-02, -1.8560e-01,\n",
            "        -1.4634e-01,  6.3345e-02, -1.8804e-01,  3.6541e-02, -5.3593e-02,\n",
            "        -5.3391e-02,  1.1970e-02, -1.0715e-01, -1.1095e-01,  3.9742e-02,\n",
            "        -9.9936e-02, -3.9768e-02,  3.4595e-02, -1.1163e-01, -9.4905e-02,\n",
            "        -1.7439e-02, -1.1258e-01, -4.3656e-02, -2.7577e-02,  6.9358e-02,\n",
            "        -1.1657e-01, -1.2119e-01, -8.2972e-02, -2.2459e-01, -6.3501e-02,\n",
            "         8.6983e-02, -7.5334e-02,  7.7090e-02, -3.7798e-02, -5.5410e-02,\n",
            "         5.2727e-02, -8.4692e-02, -9.6191e-02, -8.7968e-02,  1.6485e-02,\n",
            "        -1.1723e-01, -8.6529e-02, -1.0173e-01, -6.1434e-02, -1.8165e-01,\n",
            "         4.2599e-02, -1.2600e-01, -1.5448e-01,  7.3257e-02, -1.3792e-01,\n",
            "        -4.5867e-02,  7.2365e-02,  9.9126e-02, -1.0043e-01, -1.7223e-01,\n",
            "        -9.6714e-02,  7.2782e-02,  8.7910e-02,  8.8322e-02, -6.2794e-02,\n",
            "        -1.1643e-02, -1.4291e-01,  5.9411e-02,  2.8691e-02,  1.4364e-01,\n",
            "         1.0209e-01, -1.2882e-01,  2.7848e-02, -9.1293e-04,  2.0762e-02,\n",
            "        -1.3950e-01,  1.0853e-01, -2.4129e-02, -1.3704e-01, -1.8160e-01,\n",
            "         2.9412e-02, -2.4019e-01,  5.7585e-03, -8.4508e-02,  5.8357e-02,\n",
            "         1.8992e-02, -1.2945e-01,  4.7722e-02,  3.5637e-02,  5.0813e-03,\n",
            "        -1.1395e-01, -1.5915e-01,  8.2435e-02, -1.2147e-01, -8.7055e-02,\n",
            "        -1.3227e-01, -1.5708e-01, -1.1205e-01, -1.2270e-01, -9.6987e-02,\n",
            "        -1.5142e-01, -7.3663e-02, -6.8778e-02, -7.7885e-03, -6.6044e-02,\n",
            "         6.8722e-02, -5.3713e-02, -1.6626e-01, -7.0713e-02, -7.2792e-03,\n",
            "        -1.3299e-01,  1.8894e-02, -1.3992e-01, -1.5645e-01, -9.3605e-02,\n",
            "         9.7660e-03,  1.3724e-02, -6.8574e-02, -4.7008e-02,  6.1689e-02,\n",
            "         6.6533e-02,  5.1738e-02,  6.6517e-02, -1.4335e-01,  2.4949e-02,\n",
            "        -1.4647e-01, -2.1544e-01, -1.1742e-01,  6.8295e-02,  3.7238e-02,\n",
            "        -7.2216e-02, -1.2682e-01,  1.0485e-01,  7.0634e-02, -5.7687e-02,\n",
            "        -1.9816e-01, -9.3652e-02,  1.2519e-01, -1.9565e-02, -2.5266e-02,\n",
            "        -1.3072e-01,  5.9948e-02, -5.8024e-02, -2.3236e-01, -9.9153e-02,\n",
            "         9.4796e-02, -6.9639e-02], device='cuda:0')), ('backbone.layer4.2.bn2.running_var', tensor([0.1977, 0.0178, 0.1901, 0.1018, 0.2177, 0.1556, 0.1851, 0.1687, 0.0678,\n",
            "        0.1099, 0.0921, 0.2018, 0.1065, 0.0437, 0.1209, 0.1192, 0.0752, 0.1625,\n",
            "        0.1688, 0.0390, 0.1706, 0.1005, 0.0416, 0.1436, 0.1401, 0.1281, 0.0469,\n",
            "        0.0693, 0.1618, 0.0477, 0.0665, 0.1370, 0.0844, 0.1883, 0.1579, 0.0552,\n",
            "        0.0958, 0.1525, 0.0326, 0.1279, 0.0578, 0.1018, 0.1154, 0.1346, 0.1631,\n",
            "        0.1459, 0.2166, 0.0622, 0.1208, 0.1440, 0.1481, 0.2000, 0.1360, 0.0886,\n",
            "        0.0328, 0.0567, 0.1173, 0.2311, 0.1717, 0.0508, 0.1025, 0.1903, 0.0547,\n",
            "        0.2181, 0.0967, 0.0606, 0.1305, 0.0307, 0.1797, 0.1311, 0.2362, 0.0457,\n",
            "        0.1374, 0.0585, 0.1083, 0.1058, 0.0666, 0.0853, 0.1051, 0.0606, 0.1517,\n",
            "        0.1240, 0.0270, 0.1169, 0.0739, 0.0601, 0.1741, 0.0900, 0.0668, 0.0940,\n",
            "        0.0231, 0.0709, 0.1289, 0.1068, 0.0365, 0.1056, 0.0761, 0.1166, 0.1564,\n",
            "        0.1242, 0.0973, 0.0439, 0.2229, 0.1414, 0.0732, 0.1048, 0.1983, 0.0452,\n",
            "        0.1122, 0.1538, 0.0368, 0.0284, 0.0308, 0.0426, 0.1401, 0.1023, 0.1381,\n",
            "        0.1205, 0.0268, 0.1090, 0.0917, 0.0707, 0.0837, 0.0327, 0.0658, 0.0631,\n",
            "        0.0503, 0.1726, 0.1523, 0.0692, 0.1441, 0.1065, 0.0377, 0.0547, 0.1508,\n",
            "        0.1015, 0.0872, 0.0802, 0.0656, 0.0605, 0.1395, 0.0951, 0.1337, 0.1550,\n",
            "        0.1620, 0.1528, 0.0687, 0.1122, 0.1077, 0.1522, 0.1467, 0.2083, 0.0866,\n",
            "        0.0946, 0.1999, 0.1627, 0.1088, 0.0370, 0.0451, 0.0654, 0.2092, 0.1007,\n",
            "        0.0224, 0.1389, 0.1322, 0.0892, 0.1461, 0.1567, 0.0858, 0.1920, 0.0336,\n",
            "        0.1594, 0.0138, 0.1296, 0.0324, 0.0556, 0.0813, 0.0938, 0.0560, 0.2179,\n",
            "        0.1357, 0.1332, 0.1464, 0.1017, 0.0628, 0.2393, 0.0441, 0.0814, 0.0796,\n",
            "        0.1301, 0.0575, 0.1033, 0.0503, 0.1180, 0.0950, 0.2517, 0.0726, 0.0980,\n",
            "        0.1304, 0.1750, 0.0562, 0.0273, 0.0945, 0.0668, 0.1197, 0.0769, 0.1494,\n",
            "        0.0757, 0.1274, 0.1252, 0.0514, 0.0236, 0.1711, 0.1177, 0.1664, 0.0376,\n",
            "        0.1691, 0.1374, 0.1744, 0.0720, 0.0154, 0.1284, 0.1872, 0.0875, 0.1086,\n",
            "        0.0255, 0.0326, 0.1010, 0.1788, 0.1223, 0.1457, 0.0668, 0.0430, 0.0330,\n",
            "        0.1010, 0.1012, 0.1418, 0.0837, 0.1301, 0.0593, 0.0275, 0.0761, 0.0422,\n",
            "        0.1070, 0.0678, 0.0446, 0.1792, 0.1914, 0.1278, 0.0919, 0.0259, 0.0493,\n",
            "        0.0847, 0.1651, 0.1254, 0.0613, 0.1631, 0.1326, 0.1081, 0.1346, 0.1663,\n",
            "        0.0732, 0.1879, 0.2059, 0.1538, 0.1247, 0.0573, 0.1528, 0.1585, 0.1789,\n",
            "        0.1970, 0.0676, 0.0759, 0.0823, 0.1677, 0.1199, 0.1163, 0.0902, 0.0582,\n",
            "        0.0827, 0.1941, 0.1709, 0.0923, 0.1423, 0.0918, 0.0681, 0.0828, 0.0521,\n",
            "        0.0389, 0.1526, 0.1632, 0.0333, 0.0266, 0.2425, 0.2257, 0.1356, 0.0672,\n",
            "        0.0400, 0.1315, 0.0707, 0.0978, 0.1841, 0.1248, 0.0750, 0.0421, 0.1590,\n",
            "        0.0795, 0.1350, 0.1367, 0.1451, 0.0885, 0.0437, 0.2314, 0.0784, 0.1359,\n",
            "        0.0644, 0.0425, 0.1879, 0.0811, 0.1432, 0.2077, 0.1110, 0.1085, 0.1226,\n",
            "        0.1621, 0.0490, 0.1535, 0.0538, 0.0607, 0.1019, 0.1043, 0.1295, 0.0530,\n",
            "        0.0780, 0.1017, 0.0475, 0.2196, 0.0414, 0.0658, 0.1959, 0.2467, 0.0630,\n",
            "        0.0544, 0.0723, 0.0801, 0.0960, 0.0204, 0.0485, 0.1320, 0.0768, 0.0903,\n",
            "        0.0634, 0.2253, 0.0912, 0.0948, 0.0366, 0.0906, 0.1776, 0.0422, 0.1495,\n",
            "        0.2045, 0.1343, 0.2262, 0.2473, 0.0331, 0.0563, 0.1740, 0.1954, 0.0820,\n",
            "        0.0737, 0.0917, 0.0330, 0.0697, 0.0220, 0.0429, 0.0838, 0.1895, 0.1489,\n",
            "        0.0495, 0.0286, 0.0477, 0.0325, 0.1153, 0.0573, 0.1401, 0.0598, 0.0219,\n",
            "        0.1431, 0.2376, 0.0397, 0.0833, 0.0247, 0.0291, 0.1013, 0.1505, 0.0683,\n",
            "        0.0898, 0.0595, 0.1151, 0.0223, 0.1112, 0.0415, 0.1845, 0.1254, 0.0496,\n",
            "        0.1562, 0.0303, 0.1662, 0.0409, 0.1845, 0.0486, 0.0427, 0.1552, 0.0316,\n",
            "        0.1132, 0.1588, 0.0423, 0.0909, 0.1767, 0.0653, 0.1284, 0.1931, 0.1404,\n",
            "        0.0762, 0.1133, 0.0410, 0.0983, 0.1625, 0.1146, 0.0243, 0.0505, 0.1012,\n",
            "        0.0638, 0.0907, 0.2269, 0.1602, 0.0689, 0.1294, 0.0788, 0.1494, 0.1209,\n",
            "        0.1429, 0.0392, 0.0441, 0.0844, 0.1538, 0.0645, 0.0335, 0.1732, 0.0593,\n",
            "        0.0801, 0.0382, 0.1042, 0.1219, 0.1053, 0.0730, 0.1288, 0.2267, 0.0796,\n",
            "        0.0746, 0.0258, 0.1139, 0.0324, 0.0759, 0.0510, 0.0246, 0.0704, 0.0567,\n",
            "        0.0634, 0.0584, 0.1877, 0.0299, 0.0771, 0.0309, 0.1127, 0.0567, 0.1538,\n",
            "        0.1632, 0.0593, 0.0443, 0.1428, 0.1401, 0.0851, 0.0717, 0.1319, 0.1578,\n",
            "        0.1526, 0.1005, 0.0571, 0.1334, 0.0769, 0.0811, 0.0281, 0.1893, 0.1005,\n",
            "        0.0504, 0.1032, 0.1797, 0.1854, 0.0675, 0.0947, 0.0566, 0.1528, 0.0635,\n",
            "        0.0538, 0.0401, 0.1362, 0.2251, 0.1700, 0.2144, 0.1550, 0.0342],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn2.num_batches_tracked', tensor(99698, device='cuda:0')), ('backbone.layer4.2.conv3.weight', tensor([[[[-0.0026]],\n",
            "\n",
            "         [[-0.0182]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         [[-0.0100]],\n",
            "\n",
            "         [[ 0.0040]]],\n",
            "\n",
            "\n",
            "        [[[-0.0147]],\n",
            "\n",
            "         [[ 0.0034]],\n",
            "\n",
            "         [[-0.0047]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0020]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         [[-0.0047]]],\n",
            "\n",
            "\n",
            "        [[[-0.0197]],\n",
            "\n",
            "         [[-0.0185]],\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0030]],\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[-0.0055]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0145]],\n",
            "\n",
            "         [[-0.0048]],\n",
            "\n",
            "         [[-0.0123]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0066]],\n",
            "\n",
            "         [[-0.0038]],\n",
            "\n",
            "         [[-0.0051]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[-0.0119]],\n",
            "\n",
            "         [[ 0.0159]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0086]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         [[-0.0098]]],\n",
            "\n",
            "\n",
            "        [[[-0.0154]],\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         [[ 0.0021]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0070]],\n",
            "\n",
            "         [[-0.0055]],\n",
            "\n",
            "         [[-0.0068]]]], device='cuda:0')), ('backbone.layer4.2.bn3.weight', tensor([0.2305, 0.2963, 0.2747,  ..., 0.2020, 0.2811, 0.2050], device='cuda:0')), ('backbone.layer4.2.bn3.bias', tensor([-0.0361, -0.0222, -0.0355,  ..., -0.0157, -0.0191, -0.0200],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn3.running_mean', tensor([-0.0350, -0.0267, -0.0482,  ..., -0.0330, -0.0127, -0.0232],\n",
            "       device='cuda:0')), ('backbone.layer4.2.bn3.running_var', tensor([0.0398, 0.0494, 0.1206,  ..., 0.0456, 0.0101, 0.0560], device='cuda:0')), ('backbone.layer4.2.bn3.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.convs.0.0.weight', tensor([[[[-0.0010]],\n",
            "\n",
            "         [[ 0.0149]],\n",
            "\n",
            "         [[ 0.0050]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0053]],\n",
            "\n",
            "         [[ 0.0124]],\n",
            "\n",
            "         [[-0.0223]]],\n",
            "\n",
            "\n",
            "        [[[-0.0104]],\n",
            "\n",
            "         [[ 0.0058]],\n",
            "\n",
            "         [[-0.0032]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0157]],\n",
            "\n",
            "         [[ 0.0195]],\n",
            "\n",
            "         [[-0.0227]]],\n",
            "\n",
            "\n",
            "        [[[-0.0089]],\n",
            "\n",
            "         [[-0.0080]],\n",
            "\n",
            "         [[ 0.0120]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0230]],\n",
            "\n",
            "         [[ 0.0196]],\n",
            "\n",
            "         [[ 0.0030]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0063]],\n",
            "\n",
            "         [[ 0.0217]],\n",
            "\n",
            "         [[-0.0111]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0045]],\n",
            "\n",
            "         [[-0.0167]],\n",
            "\n",
            "         [[-0.0314]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0074]],\n",
            "\n",
            "         [[-0.0031]],\n",
            "\n",
            "         [[-0.0018]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0238]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0103]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0011]],\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0230]],\n",
            "\n",
            "         [[-0.0001]],\n",
            "\n",
            "         [[-0.0074]]]], device='cuda:0')), ('classifier.0.convs.0.1.weight', tensor([0.4115, 0.4095, 0.4064, 0.4124, 0.3938, 0.4053, 0.4261, 0.4061, 0.4054,\n",
            "        0.4110, 0.4016, 0.4425, 0.4111, 0.4005, 0.3978, 0.4187, 0.4704, 0.3804,\n",
            "        0.4013, 0.4066, 0.4578, 0.4118, 0.5286, 0.4368, 0.4063, 0.4167, 0.4054,\n",
            "        0.3917, 0.4202, 0.4103, 0.3997, 0.4196, 0.3901, 0.4618, 0.4357, 0.4098,\n",
            "        0.4329, 0.4379, 0.4074, 0.4113, 0.4073, 0.4477, 0.4091, 0.4626, 0.4338,\n",
            "        0.4059, 0.4043, 0.4125, 0.4581, 0.4563, 0.4216, 0.4178, 0.4030, 0.4039,\n",
            "        0.3999, 0.4004, 0.4114, 0.4253, 0.4345, 0.4435, 0.3920, 0.4214, 0.4367,\n",
            "        0.4148, 0.4193, 0.3986, 0.4186, 0.3962, 0.3826, 0.4414, 0.4040, 0.4036,\n",
            "        0.4040, 0.3979, 0.5262, 0.4184, 0.3975, 0.4103, 0.4011, 0.4278, 0.4138,\n",
            "        0.4022, 0.4142, 0.4318, 0.3978, 0.4012, 0.4021, 0.4148, 0.3997, 0.4053,\n",
            "        0.4191, 0.4073, 0.4008, 0.4314, 0.4088, 0.3991, 0.4647, 0.4346, 0.4002,\n",
            "        0.3942, 0.4113, 0.4182, 0.4101, 0.4188, 0.4009, 0.4010, 0.3963, 0.4086,\n",
            "        0.4171, 0.4378, 0.4059, 0.4194, 0.3904, 0.4479, 0.4034, 0.4262, 0.4457,\n",
            "        0.4403, 0.4411, 0.4078, 0.3812, 0.3968, 0.4140, 0.3958, 0.4202, 0.4590,\n",
            "        0.4145, 0.4270, 0.3910, 0.3916, 0.3970, 0.4084, 0.3907, 0.4391, 0.3895,\n",
            "        0.4033, 0.3990, 0.4214, 0.3937, 0.4185, 0.3996, 0.4160, 0.4025, 0.4016,\n",
            "        0.3975, 0.4064, 0.4291, 0.3904, 0.4188, 0.4130, 0.4272, 0.4010, 0.4194,\n",
            "        0.4097, 0.3976, 0.4124, 0.4097, 0.4052, 0.4093, 0.4269, 0.4028, 0.4104,\n",
            "        0.4079, 0.4338, 0.4102, 0.4059, 0.4321, 0.4227, 0.4079, 0.4240, 0.3864,\n",
            "        0.3924, 0.4332, 0.4020, 0.4069, 0.4275, 0.4091, 0.4223, 0.4189, 0.4081,\n",
            "        0.4356, 0.4035, 0.3947, 0.4300, 0.3966, 0.4168, 0.4214, 0.3939, 0.3994,\n",
            "        0.3918, 0.4178, 0.4211, 0.4610, 0.4040, 0.4033, 0.3878, 0.4188, 0.4426,\n",
            "        0.4376, 0.4700, 0.4059, 0.4771, 0.3917, 0.4057, 0.4294, 0.4230, 0.4197,\n",
            "        0.3922, 0.4324, 0.4582, 0.3913, 0.4034, 0.4177, 0.3976, 0.4548, 0.4069,\n",
            "        0.4008, 0.4250, 0.4176, 0.4035, 0.4311, 0.3964, 0.4223, 0.4133, 0.4060,\n",
            "        0.4009, 0.4021, 0.3982, 0.4383, 0.3906, 0.4221, 0.4158, 0.4021, 0.4128,\n",
            "        0.3927, 0.4024, 0.4067, 0.4883, 0.3948, 0.4271, 0.4012, 0.4135, 0.4512,\n",
            "        0.4319, 0.4097, 0.4059, 0.3929, 0.4228, 0.4394, 0.3980, 0.4023, 0.4627,\n",
            "        0.4476, 0.4492, 0.4086, 0.4097], device='cuda:0')), ('classifier.0.convs.0.1.bias', tensor([-0.0154, -0.0226, -0.0356, -0.0277,  0.0006, -0.0318,  0.0013, -0.0060,\n",
            "        -0.0138,  0.0036, -0.0378,  0.0143, -0.0065, -0.0047, -0.0163,  0.0075,\n",
            "         0.0021, -0.0356,  0.0044,  0.0064,  0.0117,  0.0123, -0.0075, -0.0114,\n",
            "        -0.0248, -0.0267, -0.0096, -0.0074,  0.0056, -0.0214, -0.0191, -0.0190,\n",
            "        -0.0311, -0.0077, -0.0634,  0.0027, -0.0088, -0.0104,  0.0126, -0.0201,\n",
            "         0.0065,  0.0183, -0.0048, -0.0025, -0.0230, -0.0115, -0.0047, -0.0166,\n",
            "         0.0170, -0.0051,  0.0075,  0.0054, -0.0096, -0.0030, -0.0044, -0.0057,\n",
            "        -0.0391, -0.0210, -0.0021, -0.0257, -0.0177,  0.0100, -0.0065, -0.0333,\n",
            "        -0.0134, -0.0078,  0.0128, -0.0005, -0.0179, -0.0122,  0.0031, -0.0106,\n",
            "        -0.0115, -0.0136, -0.0159, -0.0487, -0.0047, -0.0066, -0.0234,  0.0051,\n",
            "         0.0146,  0.0034, -0.0107, -0.0128, -0.0211, -0.0173, -0.0215,  0.0159,\n",
            "        -0.0304, -0.0177, -0.0192,  0.0054, -0.0064, -0.0271, -0.0041, -0.0154,\n",
            "        -0.0161, -0.0064,  0.0043, -0.0166, -0.0370, -0.0184,  0.0044, -0.0257,\n",
            "        -0.0196,  0.0006, -0.0218, -0.0264, -0.0123, -0.0033,  0.0028, -0.0106,\n",
            "        -0.0165, -0.0144,  0.0025, -0.0148, -0.0185, -0.0070,  0.0016, -0.0314,\n",
            "        -0.0246, -0.0006, -0.0157, -0.0274, -0.0413,  0.0230, -0.0250, -0.0203,\n",
            "        -0.0146, -0.0257, -0.0396, -0.0197, -0.0507, -0.0089, -0.0247,  0.0008,\n",
            "        -0.0111,  0.0136, -0.0241,  0.0069, -0.0510, -0.0099, -0.0005, -0.0166,\n",
            "        -0.0049, -0.0141, -0.0098, -0.0196,  0.0075, -0.0016, -0.0182, -0.0009,\n",
            "        -0.0280, -0.0421, -0.0009,  0.0041, -0.0085, -0.0218, -0.0227, -0.0151,\n",
            "        -0.0252, -0.0012, -0.0536, -0.0132, -0.0465, -0.0175,  0.0078, -0.0087,\n",
            "         0.0078,  0.0087, -0.0224, -0.0108, -0.0190, -0.0102, -0.0191, -0.0155,\n",
            "        -0.0110,  0.0065,  0.0091, -0.0128,  0.0173, -0.0191, -0.0086,  0.0152,\n",
            "        -0.0180, -0.0249, -0.0251, -0.0161, -0.0131, -0.0279,  0.0093,  0.0103,\n",
            "         0.0071, -0.0116, -0.0230, -0.0218,  0.0013, -0.0211,  0.0146,  0.0032,\n",
            "         0.0048, -0.0213, -0.0181, -0.0039, -0.0109, -0.0085,  0.0023, -0.0493,\n",
            "         0.0005, -0.0100, -0.0148, -0.0299, -0.0019, -0.0165, -0.0091, -0.0055,\n",
            "        -0.0358, -0.0149, -0.0065, -0.0156, -0.0133, -0.0206, -0.0352, -0.0149,\n",
            "        -0.0017, -0.0187, -0.0408, -0.0147,  0.0094, -0.0245, -0.0186, -0.0462,\n",
            "         0.0078,  0.0009, -0.0107, -0.0244, -0.0021, -0.0013, -0.0101, -0.0120,\n",
            "        -0.0299, -0.0304,  0.0041,  0.0013,  0.0022, -0.0130, -0.0071,  0.0197,\n",
            "         0.0142, -0.0049, -0.0197,  0.0111,  0.0009,  0.0155, -0.0206, -0.0392],\n",
            "       device='cuda:0')), ('classifier.0.convs.0.1.running_mean', tensor([-0.2730, -0.2976, -0.1329, -0.2057, -0.2579, -0.0145, -0.1083, -0.1141,\n",
            "        -0.5695, -0.1629, -0.1461, -0.1351, -0.1133, -0.2324, -0.0908,  0.2121,\n",
            "         0.1328, -0.4048, -0.0674, -0.1387, -0.0369, -0.1592,  0.0734, -0.1678,\n",
            "        -0.4833,  0.0090, -0.0314, -0.2400,  0.0075, -0.1080, -0.2121, -0.1563,\n",
            "        -0.0872, -0.1220,  0.0250,  0.0361, -0.3246, -0.1346, -0.2688, -0.0753,\n",
            "        -0.2188, -0.0931, -0.5636, -0.1013,  0.0141, -0.7638, -0.2153, -0.1698,\n",
            "         0.0331, -0.2142, -0.1160, -0.0477, -0.0781, -0.4643, -0.3885, -0.1648,\n",
            "        -0.0279, -0.0375, -0.0309, -0.0117, -0.0008, -0.1930, -0.0585, -0.0463,\n",
            "        -0.2692, -0.4099, -0.0558, -0.3246, -0.3868,  0.0706, -0.3164, -0.5252,\n",
            "        -0.2941, -0.3507,  0.1069, -0.0416, -0.2049, -0.0061, -0.1265, -0.0939,\n",
            "         0.0081, -0.2598, -0.2533, -0.1530,  0.2454, -0.3676,  0.1182, -0.0429,\n",
            "        -0.0650,  0.0075, -0.0640, -0.2695, -0.2072, -0.2640, -0.1610, -0.4034,\n",
            "         0.1025, -0.0584, -0.3141, -0.1528, -0.1115,  0.1953, -0.2271, -0.2304,\n",
            "         0.0136, -0.0787, -0.0767, -0.0122, -0.2097, -0.0633, -0.2304, -0.0333,\n",
            "        -0.2725,  0.0179, -0.1676,  0.1247,  0.0508, -0.0241, -0.2003, -0.1016,\n",
            "        -0.5321, -0.3558,  0.0029, -0.0302,  0.0504, -0.1493, -0.1320,  0.0971,\n",
            "        -0.3481, -0.1410, -0.3816, -0.1576, -0.2837,  0.0043, -0.1257, -0.2429,\n",
            "        -0.5234, -0.0408, -0.6467,  0.0104,  0.0865, -0.0715, -0.1256, -0.1641,\n",
            "        -0.3401, -0.1527, -0.0119, -0.3471,  0.0472, -0.0308, -0.0481, -0.2730,\n",
            "        -0.1556, -0.0086, -0.1519, -0.1524, -0.4877,  0.0060, -0.1318, -0.0132,\n",
            "        -0.4838, -0.1302,  0.0600, -0.1171,  0.0426, -0.0739, -0.3715, -0.1590,\n",
            "        -0.1612, -0.2253, -0.1752, -0.3088, -0.1011, -0.3231, -0.0649, -0.0884,\n",
            "        -0.0075, -0.2811, -0.1081, -0.1979, -0.0334,  0.0114, -0.2650,  0.1694,\n",
            "        -0.3297, -0.1307,  0.0498, -0.4786,  0.1116, -0.2896, -0.0638, -0.0221,\n",
            "        -0.0996, -0.2634, -0.5352, -0.2381, -0.1383,  0.0650, -0.0696,  0.0301,\n",
            "        -0.2559,  0.0568, -0.3731, -0.0725, -0.3618,  0.0439, -0.0196, -0.0459,\n",
            "        -0.1806,  0.0501, -0.2809,  0.0697, -0.2567, -0.3429, -0.0043, -0.4035,\n",
            "         0.1041,  0.2410, -0.1438, -0.3274,  0.0458, -0.1844, -0.0888, -0.3739,\n",
            "        -0.2241, -0.3577,  0.0124, -0.3009, -0.1283, -0.4217, -0.1557,  0.0973,\n",
            "        -0.1021, -0.2518, -0.3735, -0.4628, -0.0386, -0.0916, -0.3194, -0.1737,\n",
            "        -0.1377, -0.1970, -0.2579, -0.0264, -0.1647, -0.1885, -0.3576, -0.2521,\n",
            "        -0.0721, -0.2747, -0.2042,  0.0423,  0.1040,  0.0151, -0.3007, -0.1901],\n",
            "       device='cuda:0')), ('classifier.0.convs.0.1.running_var', tensor([0.2673, 0.0786, 0.2029, 0.1696, 0.5299, 0.2357, 0.0801, 0.0484, 0.1298,\n",
            "        0.1553, 0.1023, 0.0888, 0.1354, 0.2574, 0.0590, 0.0810, 0.1375, 0.2657,\n",
            "        0.1886, 0.1326, 0.0781, 0.2936, 0.1319, 0.0995, 0.2865, 0.0468, 0.2077,\n",
            "        0.0993, 0.1142, 0.1838, 0.0828, 0.1702, 0.0912, 0.0950, 0.0964, 0.0883,\n",
            "        0.0686, 0.1913, 0.3548, 0.0976, 0.1679, 0.0429, 0.2775, 0.0494, 0.0987,\n",
            "        0.6128, 0.1603, 0.1024, 0.1029, 0.1145, 0.1465, 0.1474, 0.0997, 0.1070,\n",
            "        0.4349, 0.1473, 0.2035, 0.1460, 0.1486, 0.1163, 0.1543, 0.1301, 0.0473,\n",
            "        0.0689, 0.1275, 0.3844, 0.2323, 0.3875, 0.3087, 0.2372, 0.1944, 0.3232,\n",
            "        0.1499, 0.3839, 0.1247, 0.1355, 0.4383, 0.2162, 0.1018, 0.0832, 0.0728,\n",
            "        0.2288, 0.2794, 0.1781, 0.3986, 0.2128, 0.1294, 0.1499, 0.0708, 0.0789,\n",
            "        0.1394, 0.3333, 0.1580, 0.1415, 0.1141, 0.3132, 0.1040, 0.0462, 0.2783,\n",
            "        0.4286, 0.1041, 0.0823, 0.2722, 0.1970, 0.0769, 0.1146, 0.1528, 0.1345,\n",
            "        0.1126, 0.0776, 0.3252, 0.1150, 0.3010, 0.1314, 0.1399, 0.0542, 0.0351,\n",
            "        0.1629, 0.0722, 0.3500, 0.6151, 0.6351, 0.0462, 0.1301, 0.0942, 0.0969,\n",
            "        0.0795, 0.0475, 0.3788, 0.1134, 0.2570, 0.0768, 0.3877, 0.0754, 0.1251,\n",
            "        0.2719, 0.2002, 0.0705, 0.6500, 0.0874, 0.1565, 0.0952, 0.1261, 0.4838,\n",
            "        0.3805, 0.1078, 0.0314, 0.4803, 0.0957, 0.0928, 0.1967, 0.2329, 0.1727,\n",
            "        0.1112, 0.0690, 0.1727, 0.1657, 0.1468, 0.0687, 0.0530, 0.4428, 0.0877,\n",
            "        0.0814, 0.1246, 0.1507, 0.1469, 0.1179, 0.0789, 0.2360, 0.1872, 0.7293,\n",
            "        0.1802, 0.0756, 0.2768, 0.1386, 0.1656, 0.1538, 0.0802, 0.0826, 0.0838,\n",
            "        0.0786, 0.0953, 0.4055, 0.0843, 0.2529, 0.0849, 0.0845, 0.3292, 0.3772,\n",
            "        0.4102, 0.2208, 0.1430, 0.0457, 0.2154, 0.2819, 0.1864, 0.1409, 0.1435,\n",
            "        0.1047, 0.1060, 0.2359, 0.1451, 0.5353, 0.1283, 0.1600, 0.0609, 0.0684,\n",
            "        0.1109, 0.1244, 0.1159, 0.4887, 0.1715, 0.0735, 0.4459, 0.1298, 0.1147,\n",
            "        0.1833, 0.1783, 0.1582, 0.2017, 0.0438, 0.4518, 0.1971, 0.1603, 0.1294,\n",
            "        0.3167, 0.1349, 0.4945, 0.0982, 0.2984, 0.1120, 0.0528, 0.2928, 0.1001,\n",
            "        0.4699, 0.2840, 0.1118, 0.1112, 0.4393, 0.1437, 0.1189, 0.1120, 0.0944,\n",
            "        0.0988, 0.0936, 0.4622, 0.4895, 0.2280, 0.0986, 0.4254, 0.4643, 0.1084,\n",
            "        0.0758, 0.1136, 0.1431, 0.2074], device='cuda:0')), ('classifier.0.convs.0.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.convs.1.0.weight', tensor([[[[ 3.9353e-03, -1.7337e-02,  5.9470e-03],\n",
            "          [ 9.2262e-03, -2.0200e-04,  6.0062e-03],\n",
            "          [-2.1447e-02, -3.6419e-02, -4.6809e-03]],\n",
            "\n",
            "         [[-1.7290e-02, -1.0659e-02, -1.6905e-02],\n",
            "          [ 7.3385e-03,  2.1454e-02,  1.0253e-03],\n",
            "          [-1.3489e-02, -1.3136e-02, -1.3175e-02]],\n",
            "\n",
            "         [[-8.2113e-03,  5.6677e-03,  1.0763e-03],\n",
            "          [-1.2989e-02, -1.1013e-03,  7.2760e-03],\n",
            "          [-1.8835e-02, -3.0095e-03,  7.4640e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8342e-03,  1.5039e-02, -1.6841e-02],\n",
            "          [-4.7707e-03,  1.5176e-02,  6.1167e-03],\n",
            "          [-1.8114e-03, -1.2070e-02,  2.6174e-03]],\n",
            "\n",
            "         [[-6.1360e-04,  9.4019e-03,  1.5373e-03],\n",
            "          [-5.2172e-03,  5.3431e-03, -1.6803e-02],\n",
            "          [-2.4996e-02, -2.2656e-03, -3.4368e-03]],\n",
            "\n",
            "         [[ 2.0504e-03,  1.0534e-02, -3.8169e-03],\n",
            "          [ 4.8512e-03,  1.8955e-03,  8.7256e-03],\n",
            "          [-1.0443e-02, -8.3786e-03, -1.7229e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0092e-03, -9.6616e-03, -1.3047e-02],\n",
            "          [-5.9808e-03,  1.8117e-04,  3.1779e-04],\n",
            "          [-9.3918e-04,  1.8711e-02, -3.1555e-03]],\n",
            "\n",
            "         [[-2.2473e-03, -5.9412e-03, -7.3760e-03],\n",
            "          [-1.3115e-04,  9.4165e-03,  1.5944e-03],\n",
            "          [ 1.0415e-02,  9.9696e-03,  4.3693e-03]],\n",
            "\n",
            "         [[-1.8379e-02, -1.0108e-02, -1.6235e-02],\n",
            "          [-1.0621e-03, -2.5473e-02,  6.9963e-03],\n",
            "          [ 1.8620e-02, -1.0149e-02,  7.5735e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.2746e-03, -1.2585e-02, -9.8313e-03],\n",
            "          [ 1.0075e-02, -2.7626e-02,  2.3716e-03],\n",
            "          [-1.1477e-02, -1.4824e-02, -1.7379e-02]],\n",
            "\n",
            "         [[-1.1770e-02, -1.2199e-02,  3.6111e-03],\n",
            "          [ 6.7105e-03, -6.1474e-03,  4.4494e-03],\n",
            "          [ 7.0606e-03,  5.7707e-03,  9.4388e-04]],\n",
            "\n",
            "         [[-6.4677e-03, -1.3349e-02, -1.2571e-02],\n",
            "          [ 8.7393e-03, -1.4312e-02, -3.5280e-03],\n",
            "          [ 9.6372e-03,  1.1323e-03,  5.3701e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8107e-03,  3.2547e-02, -4.3144e-03],\n",
            "          [-3.0438e-03,  5.5893e-03, -1.2218e-02],\n",
            "          [ 9.6221e-05, -4.9404e-03,  1.2247e-02]],\n",
            "\n",
            "         [[ 2.2483e-02,  1.4459e-02,  2.4254e-02],\n",
            "          [-1.1712e-02, -1.3788e-02, -1.1490e-02],\n",
            "          [-3.3709e-04,  3.0259e-03,  1.2149e-02]],\n",
            "\n",
            "         [[ 6.4015e-03, -1.8459e-02,  1.9267e-02],\n",
            "          [ 1.5058e-03, -1.9564e-02,  1.2607e-02],\n",
            "          [ 1.0230e-02,  1.5043e-02,  4.3999e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.8261e-04, -1.8619e-02, -3.3239e-04],\n",
            "          [-9.0649e-03,  5.6136e-03, -5.5892e-03],\n",
            "          [ 8.4771e-03,  1.7108e-02,  2.5935e-03]],\n",
            "\n",
            "         [[ 7.2409e-03,  1.1839e-02,  1.2948e-02],\n",
            "          [ 6.6598e-03,  1.7892e-03,  4.4997e-04],\n",
            "          [-1.3333e-02,  5.0809e-03, -9.0091e-04]],\n",
            "\n",
            "         [[-4.6620e-03,  8.8457e-03, -1.2811e-02],\n",
            "          [ 4.1526e-03,  5.4072e-03, -1.3263e-02],\n",
            "          [-5.5109e-04, -8.6126e-03,  8.4076e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.4491e-04, -2.9887e-03,  1.1647e-02],\n",
            "          [ 2.2008e-04, -1.5659e-03,  5.6841e-03],\n",
            "          [ 1.2747e-02, -5.1096e-04, -1.5961e-03]],\n",
            "\n",
            "         [[-1.0580e-02, -1.1676e-02,  2.8791e-03],\n",
            "          [ 6.8733e-03, -7.7934e-04,  7.6164e-03],\n",
            "          [-5.6116e-03,  1.1167e-02, -4.8147e-03]],\n",
            "\n",
            "         [[-1.0507e-02,  3.2716e-03, -5.9228e-04],\n",
            "          [-6.5206e-03, -7.5643e-03,  1.5611e-03],\n",
            "          [ 1.0897e-02,  3.9556e-03, -6.5292e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0776e-04, -2.1285e-03,  1.3058e-02],\n",
            "          [ 3.1323e-03, -2.4643e-02, -1.6923e-02],\n",
            "          [-2.2196e-03, -1.8844e-02, -4.1330e-03]],\n",
            "\n",
            "         [[-1.8944e-02, -1.5259e-02, -1.3692e-02],\n",
            "          [ 6.0238e-03,  1.1468e-02,  8.4057e-03],\n",
            "          [ 1.7401e-02,  1.3263e-02,  2.4195e-03]],\n",
            "\n",
            "         [[-2.0210e-03,  4.1200e-03,  1.2200e-02],\n",
            "          [ 9.9491e-03,  2.5902e-02,  4.9989e-03],\n",
            "          [-5.9395e-03,  4.2437e-03, -1.5875e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4470e-03, -4.5247e-03,  1.2094e-02],\n",
            "          [ 9.0542e-03, -8.9389e-03, -5.6368e-03],\n",
            "          [ 9.2611e-03, -1.6424e-02,  1.3966e-02]],\n",
            "\n",
            "         [[-2.0090e-02, -6.3367e-03, -8.3621e-03],\n",
            "          [ 3.0171e-03,  2.0527e-02,  2.0329e-03],\n",
            "          [-8.7150e-03, -6.3759e-03, -9.0723e-03]],\n",
            "\n",
            "         [[ 1.4531e-03,  2.0546e-02, -5.7179e-03],\n",
            "          [-1.2233e-02, -1.2367e-02,  1.1017e-03],\n",
            "          [-1.5511e-03, -6.3711e-03, -1.9307e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3009e-03,  1.1388e-02, -5.0914e-03],\n",
            "          [ 8.2234e-03,  1.1005e-02, -8.5632e-04],\n",
            "          [ 3.9593e-03, -6.7866e-03,  4.5930e-03]],\n",
            "\n",
            "         [[-1.0942e-02, -1.0274e-02, -3.5540e-03],\n",
            "          [-3.1666e-03,  1.3974e-02, -9.1847e-03],\n",
            "          [ 1.7488e-03, -6.6630e-03, -1.0413e-02]],\n",
            "\n",
            "         [[ 1.2115e-02, -6.3078e-05,  9.0820e-03],\n",
            "          [ 6.8770e-03, -2.5779e-02,  2.6841e-03],\n",
            "          [-3.6398e-03, -1.1781e-02, -1.6052e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.9464e-03, -1.7482e-02,  3.3863e-03],\n",
            "          [ 3.7264e-03,  2.3263e-02, -2.4917e-03],\n",
            "          [-6.4146e-03, -3.9315e-02, -2.7684e-02]],\n",
            "\n",
            "         [[-1.0942e-02, -1.8660e-02, -1.2871e-03],\n",
            "          [ 9.5198e-03,  6.1199e-03, -1.4781e-03],\n",
            "          [-7.3107e-03, -2.5595e-02, -1.9936e-02]],\n",
            "\n",
            "         [[-2.8871e-03,  1.2691e-02, -5.6765e-03],\n",
            "          [ 4.2726e-03,  7.4841e-03,  1.4327e-03],\n",
            "          [-1.8268e-02, -1.2499e-02,  7.4834e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2657e-03, -1.0276e-02, -1.2711e-02],\n",
            "          [-5.7403e-03,  2.6934e-02, -5.5484e-06],\n",
            "          [-3.8840e-03, -1.2555e-03, -5.2952e-03]],\n",
            "\n",
            "         [[-5.5288e-04,  2.5631e-02,  6.0856e-04],\n",
            "          [-8.5402e-03,  1.4660e-03, -1.6786e-02],\n",
            "          [-8.7980e-03,  1.4655e-03, -1.4321e-02]],\n",
            "\n",
            "         [[ 2.1164e-02,  1.9328e-02, -4.9119e-03],\n",
            "          [-1.2642e-02, -1.3803e-03, -1.5854e-03],\n",
            "          [-6.2442e-03, -3.4279e-03, -9.4869e-03]]]], device='cuda:0')), ('classifier.0.convs.1.1.weight', tensor([0.4020, 0.3977, 0.3929, 0.3903, 0.4149, 0.3778, 0.4031, 0.3959, 0.4022,\n",
            "        0.4118, 0.4029, 0.4146, 0.4413, 0.3997, 0.4112, 0.4337, 0.3894, 0.4294,\n",
            "        0.4192, 0.4380, 0.4131, 0.4109, 0.4427, 0.4127, 0.4289, 0.4075, 0.4039,\n",
            "        0.4132, 0.3897, 0.4383, 0.4668, 0.4052, 0.4664, 0.3845, 0.4078, 0.3838,\n",
            "        0.4210, 0.4005, 0.4212, 0.3911, 0.3848, 0.3996, 0.4033, 0.3986, 0.4036,\n",
            "        0.4016, 0.4261, 0.3853, 0.3944, 0.4045, 0.4311, 0.3949, 0.4326, 0.4226,\n",
            "        0.4160, 0.4328, 0.4059, 0.4435, 0.4218, 0.4423, 0.4177, 0.3881, 0.3972,\n",
            "        0.4180, 0.4034, 0.3892, 0.4138, 0.3969, 0.4141, 0.4034, 0.4143, 0.4206,\n",
            "        0.4153, 0.3979, 0.4024, 0.4147, 0.4001, 0.3936, 0.3969, 0.4351, 0.3894,\n",
            "        0.4000, 0.4244, 0.4156, 0.4186, 0.3982, 0.4155, 0.4101, 0.3812, 0.4249,\n",
            "        0.3947, 0.3897, 0.4523, 0.3910, 0.4079, 0.3912, 0.4043, 0.3953, 0.3842,\n",
            "        0.4252, 0.4147, 0.4116, 0.3758, 0.4314, 0.4059, 0.3953, 0.4410, 0.4230,\n",
            "        0.3992, 0.4069, 0.4161, 0.4117, 0.4096, 0.3992, 0.4217, 0.4169, 0.3992,\n",
            "        0.3701, 0.4340, 0.4064, 0.4287, 0.4133, 0.4128, 0.4075, 0.3904, 0.4320,\n",
            "        0.4138, 0.4246, 0.4261, 0.4034, 0.4312, 0.3779, 0.3986, 0.4014, 0.4059,\n",
            "        0.3853, 0.4083, 0.4262, 0.4116, 0.4546, 0.3830, 0.4156, 0.4023, 0.4234,\n",
            "        0.4241, 0.4227, 0.3788, 0.3730, 0.4281, 0.4276, 0.4100, 0.3873, 0.4485,\n",
            "        0.3880, 0.4129, 0.3928, 0.3678, 0.4226, 0.4281, 0.3854, 0.4033, 0.4240,\n",
            "        0.4001, 0.4040, 0.4016, 0.3951, 0.3966, 0.4071, 0.4368, 0.4279, 0.4131,\n",
            "        0.4020, 0.4156, 0.4017, 0.3990, 0.3770, 0.3992, 0.3938, 0.4148, 0.4129,\n",
            "        0.4109, 0.4080, 0.3916, 0.4018, 0.3797, 0.4207, 0.4138, 0.4092, 0.4011,\n",
            "        0.4158, 0.4376, 0.3807, 0.3950, 0.3905, 0.3775, 0.4438, 0.3994, 0.3990,\n",
            "        0.4042, 0.4215, 0.4188, 0.4247, 0.3864, 0.4006, 0.4204, 0.4240, 0.4057,\n",
            "        0.4126, 0.4394, 0.4176, 0.4184, 0.4112, 0.4029, 0.4220, 0.4270, 0.4053,\n",
            "        0.3962, 0.4282, 0.3928, 0.3969, 0.4215, 0.4108, 0.4045, 0.3795, 0.4301,\n",
            "        0.4194, 0.4011, 0.3958, 0.4286, 0.4252, 0.4521, 0.4186, 0.4280, 0.4456,\n",
            "        0.4159, 0.4055, 0.4112, 0.4068, 0.4228, 0.4151, 0.4040, 0.4149, 0.4115,\n",
            "        0.4022, 0.4195, 0.4195, 0.4159, 0.4155, 0.4094, 0.3959, 0.4291, 0.4059,\n",
            "        0.3966, 0.4076, 0.3965, 0.4174], device='cuda:0')), ('classifier.0.convs.1.1.bias', tensor([-0.0284, -0.0331, -0.0338, -0.0344, -0.0337, -0.0573, -0.0236, -0.0199,\n",
            "        -0.0384, -0.0109, -0.0335, -0.0308, -0.0106, -0.0336, -0.0272, -0.0097,\n",
            "        -0.0424, -0.0383, -0.0134, -0.0307, -0.0041, -0.0230, -0.0069, -0.0185,\n",
            "        -0.0145, -0.0307, -0.0166, -0.0108, -0.0447,  0.0029, -0.0489, -0.0320,\n",
            "        -0.0188, -0.0267, -0.0209, -0.0398, -0.0082, -0.0207, -0.0354, -0.0229,\n",
            "        -0.0252, -0.0326, -0.0335, -0.0103, -0.0160, -0.0219, -0.0409, -0.0153,\n",
            "        -0.0389, -0.0226, -0.0009, -0.0200, -0.0256, -0.0090, -0.0183, -0.0474,\n",
            "        -0.0399, -0.0624, -0.0170, -0.0102, -0.0269, -0.0177, -0.0476, -0.0475,\n",
            "        -0.0479, -0.0577, -0.0351, -0.0456, -0.0069, -0.0545, -0.0229, -0.0208,\n",
            "        -0.0286, -0.0450, -0.0110, -0.0105, -0.0268, -0.0292, -0.0332, -0.0328,\n",
            "        -0.0270, -0.0131, -0.0243, -0.0129, -0.0048, -0.0455, -0.0288, -0.0144,\n",
            "        -0.0442, -0.0118, -0.0183, -0.0327,  0.0049, -0.0281, -0.0094, -0.0286,\n",
            "        -0.0184, -0.0437, -0.0426, -0.0231, -0.0410, -0.0135, -0.0297, -0.0184,\n",
            "        -0.0194, -0.0252, -0.0151,  0.0010, -0.0374, -0.0193,  0.0025, -0.0245,\n",
            "        -0.0281, -0.0166, -0.0050, -0.0449, -0.0163, -0.0421, -0.0262, -0.0197,\n",
            "        -0.0332, -0.0278, -0.0180, -0.0162, -0.0276, -0.0227, -0.0340, -0.0042,\n",
            "        -0.0170, -0.0312, -0.0119, -0.0496, -0.0079, -0.0020, -0.0165, -0.0268,\n",
            "        -0.0113, -0.0266, -0.0225, -0.0224, -0.0302, -0.0313, -0.0140, -0.0120,\n",
            "        -0.0317, -0.0182, -0.0321, -0.0301,  0.0005, -0.0550, -0.0344, -0.0216,\n",
            "        -0.0366, -0.0339, -0.0103, -0.0316, -0.0323, -0.0239, -0.0336, -0.0457,\n",
            "        -0.0269, -0.0251, -0.0218, -0.0181, -0.0082, -0.0367, -0.0096, -0.0133,\n",
            "        -0.0200, -0.0258, -0.0409, -0.0371, -0.0394, -0.0336, -0.0279, -0.0494,\n",
            "        -0.0203, -0.0615, -0.0412, -0.0066, -0.0105, -0.0436, -0.0273, -0.0375,\n",
            "        -0.0513, -0.0246, -0.0227, -0.0027, -0.0210, -0.0154, -0.0158, -0.0368,\n",
            "        -0.0215, -0.0304, -0.0260, -0.0260, -0.0386, -0.0310, -0.0397, -0.0054,\n",
            "        -0.0059, -0.0127, -0.0553, -0.0323, -0.0045, -0.0441, -0.0291, -0.0203,\n",
            "        -0.0420, -0.0206, -0.0223, -0.0082, -0.0010, -0.0234, -0.0110, -0.0140,\n",
            "        -0.0253, -0.0154, -0.0467, -0.0018, -0.0291, -0.0607, -0.0340, -0.0381,\n",
            "        -0.0212, -0.0280, -0.0117, -0.0211, -0.0047, -0.0227, -0.0074, -0.0120,\n",
            "         0.0018, -0.0221, -0.0127, -0.0449, -0.0219,  0.0080, -0.0250, -0.0301,\n",
            "        -0.0197, -0.0135, -0.0341, -0.0300, -0.0095, -0.0191, -0.0235, -0.0196,\n",
            "        -0.0315, -0.0261, -0.0107, -0.0247, -0.0097, -0.0399, -0.0126, -0.0442],\n",
            "       device='cuda:0')), ('classifier.0.convs.1.1.running_mean', tensor([-1.6216, -0.3914,  0.3438, -0.3533,  0.1436, -0.1324, -1.8249,  0.9219,\n",
            "        -0.0779, -0.1663, -0.9721, -1.5180,  0.5792, -1.1127, -0.8311, -1.4167,\n",
            "        -0.0809,  1.0976, -1.5216,  1.1194,  0.7875, -0.0750, -2.0996, -0.1469,\n",
            "        -0.1466, -1.3643, -0.7124,  0.1462,  1.1887, -1.1201, -0.0089, -1.4326,\n",
            "         0.6304, -0.5328,  0.4818,  1.2330, -1.0242, -0.3630, -0.4876,  1.7745,\n",
            "         0.1286, -0.3113, -0.2762, -1.4673,  0.6590, -0.0785, -1.7558, -0.1210,\n",
            "         0.9656, -0.3844,  0.3866,  1.7216,  0.3682,  1.9981, -0.0622, -1.7663,\n",
            "        -0.8056, -0.8406, -1.2853, -0.1175, -0.7318,  0.5820, -1.7766, -2.1891,\n",
            "         1.0083,  0.1442,  0.5716, -2.1232,  0.7156, -0.1662, -0.3222,  0.3577,\n",
            "        -0.4848, -0.4687, -1.1459,  0.8641, -0.8386,  0.6056, -0.8002, -1.3298,\n",
            "        -1.2442, -1.8850, -0.2321, -1.3611, -0.9233, -0.3983, -1.4038, -0.2746,\n",
            "        -1.6496, -0.2335,  1.6412,  0.3370,  0.2221, -1.4286, -2.4316, -1.0934,\n",
            "        -1.5266, -2.5676, -0.7051, -0.5098, -0.3513,  0.1063,  1.1919, -1.6377,\n",
            "        -0.4759, -1.9503, -0.8146, -1.0400, -2.0337, -0.7972,  0.9353, -1.4652,\n",
            "        -0.3531, -1.3419, -0.5815, -1.6311, -1.8874,  0.9934,  0.4881, -1.5685,\n",
            "        -0.1626, -0.3018, -0.5094, -0.1124,  1.5075,  1.6240, -1.8509,  0.8298,\n",
            "         1.3705,  0.7778,  0.7550,  1.9502, -0.9552, -1.0982, -1.0836, -1.3398,\n",
            "        -0.3700, -0.1548, -0.5696,  1.8358, -1.1049,  0.5645, -1.2559,  1.0319,\n",
            "        -0.4146, -1.2432, -2.1038,  0.1702, -0.1731, -0.0052, -0.5871, -0.1686,\n",
            "        -0.7733, -2.5567, -1.4771,  1.2100, -0.3532, -0.9997, -0.1507, -0.1756,\n",
            "         1.6956, -2.0177,  0.5205, -1.1724, -1.3979, -0.9679, -0.9515,  0.4949,\n",
            "        -1.0468, -1.3145,  1.7031, -0.5264, -1.3752,  1.4702,  1.6754, -2.7154,\n",
            "        -0.3818, -0.7906,  0.8894, -0.3722,  0.2923, -0.0534, -0.3514, -1.7666,\n",
            "        -0.8074,  0.3886, -0.0158, -0.2580, -1.5155, -0.2213,  0.0470, -1.6924,\n",
            "        -0.0652,  2.5923, -1.3239, -0.3484,  0.1981, -0.9932, -0.4250,  0.7205,\n",
            "         1.4132, -1.6888, -1.2245, -0.1660,  0.9758,  0.8715, -2.1177, -2.0818,\n",
            "         0.9790, -0.4772, -0.4426, -1.3567, -0.8368, -0.3031, -0.7770, -2.5343,\n",
            "        -1.2829,  1.1358, -0.4331, -0.5185,  0.7276, -0.9165,  0.7957, -1.9552,\n",
            "         0.2660, -0.1732,  1.1560, -1.0137, -0.3273, -0.2448,  0.1065, -0.5009,\n",
            "         0.6173,  0.0341, -0.6676,  2.1337,  1.0770,  1.5029, -0.5769, -0.1696,\n",
            "        -0.7012,  0.9324, -0.9975,  0.3514,  0.2623, -0.2460,  2.3155, -1.0138,\n",
            "         0.2269, -0.5877,  0.6711, -0.9169, -0.2531, -0.4463, -0.9566, -2.1702],\n",
            "       device='cuda:0')), ('classifier.0.convs.1.1.running_var', tensor([2.8239, 2.2148, 1.0954, 1.7661, 2.4399, 2.5458, 2.5826, 2.6068, 0.6250,\n",
            "        3.1887, 1.6499, 2.0149, 1.4579, 1.4680, 2.9129, 1.9271, 5.1028, 3.4588,\n",
            "        2.3644, 3.0873, 2.5694, 2.5149, 1.5812, 3.6030, 1.7653, 2.1170, 2.2070,\n",
            "        4.2260, 4.1448, 2.9758, 1.9735, 2.3496, 0.8161, 1.7151, 1.4575, 3.0363,\n",
            "        1.8106, 2.9894, 1.5657, 2.9858, 4.2035, 3.0768, 1.9504, 1.7058, 2.1998,\n",
            "        2.1858, 1.7436, 2.3521, 1.1970, 2.9255, 1.0256, 3.7528, 3.9200, 2.8510,\n",
            "        1.0664, 2.3132, 1.7610, 2.2201, 1.0814, 2.6839, 0.8220, 2.1554, 3.0051,\n",
            "        2.4641, 3.0332, 3.3856, 3.0255, 1.6448, 2.5662, 1.1402, 2.4434, 1.6699,\n",
            "        2.2287, 1.7702, 1.3586, 1.0088, 2.2919, 1.4364, 1.8468, 1.3690, 4.3295,\n",
            "        1.8304, 3.2507, 2.0622, 1.3358, 3.7909, 0.8729, 3.1075, 2.8104, 2.2592,\n",
            "        3.5285, 1.5924, 0.6032, 3.6160, 3.3984, 1.9754, 2.6202, 2.8577, 1.8408,\n",
            "        1.6214, 2.2315, 1.3250, 4.1493, 1.3255, 1.1327, 2.3782, 0.6438, 1.1106,\n",
            "        3.1621, 3.5045, 1.4250, 3.9575, 2.8896, 1.6896, 2.9749, 1.6652, 2.4453,\n",
            "        2.6021, 0.6366, 2.4499, 3.0442, 2.4104, 1.0329, 2.7381, 3.1606, 3.2410,\n",
            "        1.6694, 0.9878, 4.6484, 2.6898, 0.4625, 3.8522, 1.4035, 2.3783, 1.8100,\n",
            "        2.2315, 0.8698, 1.5355, 0.8828, 3.0526, 5.3176, 1.1136, 2.2325, 1.5446,\n",
            "        1.2401, 2.1212, 2.3893, 5.4485, 0.6871, 0.4059, 1.7845, 3.0264, 2.0203,\n",
            "        2.1945, 0.7338, 3.2054, 3.5385, 1.1152, 0.6059, 2.8526, 3.4452, 2.5673,\n",
            "        1.0613, 2.0239, 1.8112, 1.8035, 1.4904, 1.6386, 1.8777, 2.1273, 2.3204,\n",
            "        2.1747, 1.3108, 3.0881, 3.2852, 4.5173, 2.6640, 2.4963, 0.7227, 3.6240,\n",
            "        2.3215, 1.2594, 4.0755, 2.1929, 1.4549, 3.4656, 2.5898, 1.4056, 2.2085,\n",
            "        4.2747, 0.5979, 2.6328, 2.1830, 1.6630, 2.4160, 2.4431, 1.3613, 3.2563,\n",
            "        3.0957, 1.0421, 2.0724, 1.7315, 1.9582, 4.6803, 1.8535, 0.7291, 2.5607,\n",
            "        2.0247, 1.8429, 1.0951, 2.9308, 2.1399, 2.9455, 1.8608, 1.1620, 2.6296,\n",
            "        2.0261, 3.0454, 0.6634, 2.6136, 3.0920, 1.8051, 2.9940, 3.2968, 2.4266,\n",
            "        3.2771, 2.9265, 2.3599, 1.5639, 3.1948, 1.9132, 0.9710, 1.3421, 2.2651,\n",
            "        3.1200, 4.5265, 3.2604, 1.8411, 1.9373, 0.9575, 1.3771, 2.4685, 0.9098,\n",
            "        3.4859, 2.7718, 2.6570, 3.2373, 2.9026, 0.5939, 2.9686, 1.9568, 3.2666,\n",
            "        1.6634, 1.1737, 2.4927, 3.8398], device='cuda:0')), ('classifier.0.convs.1.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.convs.2.0.weight', tensor([[[[-4.7527e-03, -8.2566e-03, -1.4723e-02],\n",
            "          [-7.6748e-03, -1.7045e-03, -4.2229e-03],\n",
            "          [ 7.7206e-03,  1.8765e-02, -5.5082e-03]],\n",
            "\n",
            "         [[-2.2311e-03, -1.3995e-03, -5.9895e-03],\n",
            "          [ 5.1631e-03,  3.3466e-03, -4.8476e-03],\n",
            "          [-2.5713e-03,  1.1513e-02,  4.9359e-03]],\n",
            "\n",
            "         [[-8.1761e-05,  1.0181e-02, -5.6425e-04],\n",
            "          [ 2.3056e-03,  8.0672e-03,  3.1725e-04],\n",
            "          [-4.5809e-03,  1.9635e-03,  1.3213e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2558e-04, -1.5531e-02, -7.7647e-03],\n",
            "          [-1.4302e-02, -2.5947e-02, -1.2630e-02],\n",
            "          [ 5.2169e-03,  8.1638e-03, -7.7162e-03]],\n",
            "\n",
            "         [[-1.0238e-02,  8.6994e-03, -1.6929e-03],\n",
            "          [ 5.8737e-03,  1.7973e-02,  1.5170e-03],\n",
            "          [ 2.1310e-02,  1.2949e-02,  1.7070e-02]],\n",
            "\n",
            "         [[-4.5101e-03, -4.9487e-04, -1.9210e-03],\n",
            "          [-2.1848e-03,  7.1879e-03, -1.6941e-03],\n",
            "          [-3.2409e-03,  8.4692e-03, -1.9709e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4791e-02,  3.0450e-02,  8.2193e-03],\n",
            "          [ 2.5515e-03, -1.6665e-02,  1.0269e-02],\n",
            "          [-1.8216e-02, -1.1444e-02, -8.2125e-03]],\n",
            "\n",
            "         [[ 1.5339e-02, -9.1615e-03,  1.5445e-02],\n",
            "          [ 3.3782e-03,  1.2553e-02, -3.7731e-03],\n",
            "          [-5.1704e-03, -1.7323e-02, -1.5246e-02]],\n",
            "\n",
            "         [[ 1.0671e-02,  8.4138e-03,  3.5128e-03],\n",
            "          [-7.2811e-03,  1.0586e-02,  1.1497e-02],\n",
            "          [-1.1396e-02, -1.5661e-02, -1.0700e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7369e-04, -1.4862e-03,  8.2201e-03],\n",
            "          [-7.9719e-03,  4.4246e-03,  1.7158e-02],\n",
            "          [-1.9434e-02, -1.8444e-02, -1.6845e-02]],\n",
            "\n",
            "         [[ 7.0008e-03,  1.4211e-03, -3.8600e-03],\n",
            "          [-3.8525e-03, -4.0768e-03, -2.9773e-03],\n",
            "          [ 5.0426e-03, -1.9540e-03, -7.9905e-03]],\n",
            "\n",
            "         [[ 1.3388e-02, -4.0870e-03,  3.0924e-03],\n",
            "          [ 1.2969e-02,  3.6433e-03, -4.0576e-03],\n",
            "          [-1.2182e-02, -1.5940e-02, -1.2839e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.4789e-03, -3.6477e-02, -2.4352e-03],\n",
            "          [-3.6960e-03, -8.6878e-04, -2.4923e-03],\n",
            "          [ 5.1044e-03,  2.1197e-03, -4.3837e-03]],\n",
            "\n",
            "         [[-8.4038e-03,  5.9767e-03,  2.6987e-04],\n",
            "          [ 2.4865e-03, -6.8193e-03,  2.0679e-03],\n",
            "          [-3.9528e-03,  1.9514e-02,  2.2522e-03]],\n",
            "\n",
            "         [[ 3.6858e-03,  2.6402e-03,  1.6049e-02],\n",
            "          [ 1.6967e-02, -3.8091e-03,  4.6067e-03],\n",
            "          [-4.5784e-03, -5.0474e-03,  9.8550e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.4062e-05, -3.4459e-02,  1.5548e-03],\n",
            "          [-1.2549e-03, -2.2884e-02, -1.8777e-02],\n",
            "          [ 3.2675e-03,  7.6561e-03,  2.1610e-03]],\n",
            "\n",
            "         [[-2.3078e-03,  5.2461e-03,  3.0220e-03],\n",
            "          [-9.1370e-04, -6.2532e-04,  7.5651e-03],\n",
            "          [ 1.5860e-02,  9.6166e-03,  1.6808e-02]],\n",
            "\n",
            "         [[-9.9611e-03, -1.5566e-03,  9.5898e-04],\n",
            "          [ 2.4419e-03,  1.5567e-02, -2.9818e-03],\n",
            "          [ 3.8041e-03,  5.0592e-03,  2.7976e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.1843e-03,  1.6319e-02,  1.0533e-02],\n",
            "          [-4.2230e-04, -1.2694e-02,  1.3682e-02],\n",
            "          [-1.2545e-02, -3.7559e-03, -1.0288e-02]],\n",
            "\n",
            "         [[ 1.1367e-02, -8.3080e-03,  1.3112e-02],\n",
            "          [-2.8387e-03,  2.5323e-03, -1.8754e-03],\n",
            "          [-8.9361e-03, -8.9989e-03, -1.7310e-02]],\n",
            "\n",
            "         [[ 6.6179e-03,  5.3861e-03,  5.0421e-03],\n",
            "          [-2.1941e-02,  1.4713e-02,  2.4996e-02],\n",
            "          [-1.7786e-02, -1.4228e-02, -1.5302e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3472e-04, -1.3296e-02,  7.9734e-03],\n",
            "          [-3.5298e-03,  6.3709e-03,  1.6620e-02],\n",
            "          [-1.5112e-02, -1.2473e-02, -1.3906e-02]],\n",
            "\n",
            "         [[ 6.2687e-03, -4.8093e-03,  1.4350e-02],\n",
            "          [-6.4238e-03, -5.5771e-03,  2.9030e-03],\n",
            "          [-5.3381e-03, -6.0775e-03, -9.4774e-03]],\n",
            "\n",
            "         [[-5.5291e-03, -6.1489e-04, -3.6119e-03],\n",
            "          [-4.9947e-03,  1.8945e-02,  9.0080e-04],\n",
            "          [-1.1241e-02, -1.3443e-02, -1.5125e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5458e-02, -3.4835e-02, -1.8450e-02],\n",
            "          [-1.1703e-02, -3.1772e-03, -3.6932e-03],\n",
            "          [ 1.2416e-02,  1.1592e-02,  4.0946e-03]],\n",
            "\n",
            "         [[-1.4467e-02, -1.1396e-02, -5.2007e-03],\n",
            "          [ 6.5653e-03, -8.8103e-03, -1.9877e-03],\n",
            "          [-6.4182e-03,  2.3494e-02,  1.2669e-03]],\n",
            "\n",
            "         [[-2.6299e-03, -1.3755e-02, -2.3125e-03],\n",
            "          [ 1.8722e-02,  4.2342e-03,  1.4062e-02],\n",
            "          [-3.7518e-03, -6.6901e-03, -1.1549e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0783e-02, -3.1852e-02, -1.0594e-02],\n",
            "          [-6.6116e-03, -2.2551e-02, -1.9341e-02],\n",
            "          [ 5.6827e-03, -4.1594e-03, -7.7501e-04]],\n",
            "\n",
            "         [[-7.2964e-03, -6.3194e-03, -6.7173e-03],\n",
            "          [-8.6737e-04,  1.4951e-02,  2.3598e-02],\n",
            "          [ 1.6699e-02,  1.7348e-02,  3.1149e-02]],\n",
            "\n",
            "         [[-1.0835e-02, -6.2545e-03, -3.0318e-03],\n",
            "          [-5.8563e-03,  7.0690e-03, -1.9015e-03],\n",
            "          [ 4.2101e-03,  1.2198e-02,  1.1788e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.6094e-03, -6.8904e-03, -7.3499e-03],\n",
            "          [ 8.5960e-04,  2.3634e-03,  4.3791e-03],\n",
            "          [ 1.1606e-02,  1.4359e-03,  7.4359e-03]],\n",
            "\n",
            "         [[-1.0201e-02,  5.9296e-03, -6.2015e-03],\n",
            "          [ 2.4954e-02,  7.4227e-03,  1.5828e-02],\n",
            "          [-5.8361e-03,  1.0726e-02,  9.5063e-03]],\n",
            "\n",
            "         [[ 4.3399e-03, -6.6786e-03,  8.8534e-03],\n",
            "          [ 1.6885e-02, -1.7849e-02,  8.1002e-03],\n",
            "          [-3.0338e-03,  1.1516e-03,  1.6661e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0155e-02, -2.0585e-02, -4.3533e-03],\n",
            "          [ 1.2819e-02, -1.6584e-02,  5.6112e-03],\n",
            "          [ 9.6962e-03, -6.7413e-03,  5.5374e-03]],\n",
            "\n",
            "         [[-1.3178e-02, -7.7168e-03,  3.3639e-03],\n",
            "          [ 1.6458e-03,  5.1854e-03,  1.1397e-02],\n",
            "          [ 1.6078e-02,  1.2170e-02,  3.9435e-02]],\n",
            "\n",
            "         [[-1.3798e-03,  2.4161e-03, -1.8485e-05],\n",
            "          [-7.2078e-03, -3.9636e-03, -2.9853e-03],\n",
            "          [ 8.6166e-03,  2.5713e-02,  1.4363e-02]]]], device='cuda:0')), ('classifier.0.convs.2.1.weight', tensor([0.4048, 0.3997, 0.3831, 0.3777, 0.3749, 0.3958, 0.3971, 0.3956, 0.4067,\n",
            "        0.3964, 0.3844, 0.4077, 0.3896, 0.3853, 0.3942, 0.3666, 0.4045, 0.3712,\n",
            "        0.3867, 0.3970, 0.3707, 0.3717, 0.4011, 0.3942, 0.4042, 0.3889, 0.3834,\n",
            "        0.3792, 0.3907, 0.3952, 0.3818, 0.3968, 0.3998, 0.4023, 0.3746, 0.3914,\n",
            "        0.3955, 0.3854, 0.4063, 0.3983, 0.3646, 0.3947, 0.4187, 0.4050, 0.3529,\n",
            "        0.3672, 0.3760, 0.3848, 0.3816, 0.3699, 0.4035, 0.4079, 0.3848, 0.4117,\n",
            "        0.3868, 0.3892, 0.4103, 0.4022, 0.4196, 0.4024, 0.3901, 0.3689, 0.3710,\n",
            "        0.3807, 0.4073, 0.3796, 0.3682, 0.3751, 0.3875, 0.3721, 0.3919, 0.4105,\n",
            "        0.3894, 0.3587, 0.3807, 0.3820, 0.4156, 0.3957, 0.3879, 0.4157, 0.3371,\n",
            "        0.4005, 0.3918, 0.3972, 0.3842, 0.3919, 0.3944, 0.3862, 0.4064, 0.3940,\n",
            "        0.3927, 0.4164, 0.3761, 0.3858, 0.3993, 0.3978, 0.3772, 0.4040, 0.4055,\n",
            "        0.3809, 0.3851, 0.3888, 0.3819, 0.4104, 0.3818, 0.4165, 0.3995, 0.3997,\n",
            "        0.3926, 0.3755, 0.3970, 0.3703, 0.4000, 0.3922, 0.3866, 0.4014, 0.3981,\n",
            "        0.4108, 0.3926, 0.3797, 0.3889, 0.4014, 0.3578, 0.3782, 0.4063, 0.4052,\n",
            "        0.3763, 0.3868, 0.3651, 0.3796, 0.3829, 0.3997, 0.4484, 0.4059, 0.3994,\n",
            "        0.3922, 0.4010, 0.3824, 0.4023, 0.4214, 0.4090, 0.3881, 0.3954, 0.3778,\n",
            "        0.3832, 0.3757, 0.3851, 0.3606, 0.3989, 0.3887, 0.3828, 0.4013, 0.3643,\n",
            "        0.3897, 0.4027, 0.3652, 0.4062, 0.4015, 0.3784, 0.3832, 0.4137, 0.4245,\n",
            "        0.3773, 0.4071, 0.4179, 0.3860, 0.3978, 0.4260, 0.4000, 0.3765, 0.4113,\n",
            "        0.4026, 0.3946, 0.4040, 0.3853, 0.3899, 0.3765, 0.3937, 0.3835, 0.3798,\n",
            "        0.3832, 0.3835, 0.3970, 0.3834, 0.3891, 0.3624, 0.3856, 0.4006, 0.3868,\n",
            "        0.3610, 0.3646, 0.3656, 0.3907, 0.3928, 0.3908, 0.3696, 0.3924, 0.3971,\n",
            "        0.3677, 0.3725, 0.3644, 0.3720, 0.3847, 0.3875, 0.3867, 0.4111, 0.3964,\n",
            "        0.3878, 0.3928, 0.4001, 0.3788, 0.3875, 0.3695, 0.4076, 0.3900, 0.3855,\n",
            "        0.3802, 0.3920, 0.4125, 0.3692, 0.3854, 0.3780, 0.3787, 0.4132, 0.3894,\n",
            "        0.3955, 0.3812, 0.4128, 0.3906, 0.3888, 0.4009, 0.4031, 0.3949, 0.3889,\n",
            "        0.3821, 0.3922, 0.4080, 0.3711, 0.3719, 0.3988, 0.4324, 0.3905, 0.3969,\n",
            "        0.3885, 0.4012, 0.3807, 0.3843, 0.3962, 0.4098, 0.4134, 0.3962, 0.3851,\n",
            "        0.3871, 0.3979, 0.3848, 0.3936], device='cuda:0')), ('classifier.0.convs.2.1.bias', tensor([-1.3591e-02,  1.6779e-04, -1.7300e-02, -2.0837e-02, -2.1684e-02,\n",
            "        -8.6836e-03, -1.7163e-02, -1.8946e-02, -3.5454e-02, -1.1573e-02,\n",
            "        -4.5710e-02,  5.1338e-03, -2.2823e-02, -1.8478e-02, -1.0060e-02,\n",
            "        -3.6048e-02, -2.0959e-02, -2.4688e-02, -2.5562e-02, -7.2336e-03,\n",
            "        -5.5203e-02, -3.3793e-02, -2.0417e-02, -1.9265e-02, -9.6361e-03,\n",
            "        -2.4389e-02, -2.7572e-02, -1.7381e-02, -2.5513e-02, -2.3233e-02,\n",
            "        -2.6476e-02, -3.1485e-02, -1.6878e-02, -1.4265e-02, -4.0147e-02,\n",
            "        -3.4352e-02, -2.1335e-02, -7.7210e-03, -5.0750e-02, -1.5556e-02,\n",
            "        -4.5163e-02, -1.8538e-02, -7.8350e-03, -2.4699e-02, -4.5814e-02,\n",
            "        -4.0765e-02, -2.0050e-02, -1.5205e-02, -1.7943e-02, -4.4350e-02,\n",
            "        -1.1370e-02, -1.2508e-02, -2.8726e-02, -1.8524e-02, -5.6357e-03,\n",
            "        -1.6699e-02, -1.3510e-02, -6.2506e-03, -1.7660e-02, -4.0736e-02,\n",
            "        -1.7949e-02, -3.8897e-02, -3.4876e-02, -4.1401e-02, -4.8975e-03,\n",
            "        -2.1890e-02, -6.1867e-02, -1.8782e-02, -1.7289e-02, -5.5279e-02,\n",
            "        -5.1311e-02,  1.2151e-02, -3.9691e-02, -5.7412e-02, -1.8914e-02,\n",
            "        -3.5513e-02, -4.7425e-03, -1.3579e-02, -4.4766e-02, -2.2965e-02,\n",
            "        -5.5331e-02, -1.7763e-02, -1.7159e-02, -2.0935e-02, -1.4849e-02,\n",
            "        -5.0985e-02, -4.0274e-02, -5.2117e-02, -8.0930e-03, -3.1599e-02,\n",
            "        -3.7668e-02, -7.7273e-03, -3.6504e-02, -3.2807e-02, -2.3781e-02,\n",
            "        -6.4405e-04, -3.4157e-02, -3.1419e-02, -2.8874e-03, -2.8348e-02,\n",
            "        -1.7093e-02, -3.3576e-02, -2.7751e-02,  7.1217e-04, -3.7850e-02,\n",
            "         3.7087e-03, -2.3390e-02, -3.1118e-03, -8.2243e-03, -2.3149e-02,\n",
            "        -2.5152e-02, -3.8872e-02, -1.0885e-02, -2.1987e-02, -3.1828e-02,\n",
            "        -1.2481e-02, -2.6453e-02, -3.5579e-03, -3.9620e-02, -1.4803e-02,\n",
            "        -2.0686e-02, -4.6452e-02, -3.7920e-02, -2.3677e-02, -4.0488e-02,\n",
            "        -1.5274e-03, -2.8768e-02, -4.4247e-02, -3.2295e-02, -1.6336e-02,\n",
            "        -1.5274e-02, -6.4138e-03, -4.1427e-03, -1.4157e-02, -4.6748e-02,\n",
            "        -1.1732e-02, -2.1309e-02, -3.1544e-02, -7.3367e-03, -6.9638e-03,\n",
            "        -1.8517e-02, -2.1524e-02, -4.7996e-02, -3.0410e-02, -2.4088e-02,\n",
            "        -3.7734e-02, -2.8746e-02, -7.4530e-02, -6.3569e-02, -3.6745e-02,\n",
            "        -2.0028e-02, -3.5572e-02, -3.6486e-02, -2.2744e-02,  3.3618e-03,\n",
            "        -2.4295e-02, -1.6480e-02,  1.2608e-03, -3.6674e-02, -3.3241e-02,\n",
            "        -7.2123e-03,  3.0281e-03, -1.9850e-02, -1.9437e-02, -1.6446e-02,\n",
            "        -2.7091e-02, -1.2835e-02, -1.8816e-02, -9.4318e-03, -1.7507e-02,\n",
            "        -2.2216e-02, -2.3985e-02, -3.1771e-02, -1.9103e-02, -3.1059e-02,\n",
            "        -2.9440e-02, -3.1461e-02, -7.4155e-03, -3.0027e-02, -3.1663e-02,\n",
            "        -2.4965e-02, -2.3347e-02, -7.4430e-03, -1.1333e-02, -1.9628e-02,\n",
            "        -4.4947e-02, -2.1667e-02, -2.4186e-03, -6.1313e-02, -4.8415e-02,\n",
            "        -3.7899e-02, -5.4092e-02, -1.5042e-02, -2.9004e-03, -1.7352e-02,\n",
            "        -2.6489e-02, -7.5437e-03, -3.6538e-02, -3.1288e-02, -2.8740e-02,\n",
            "        -5.3092e-02, -3.6552e-02, -1.2110e-02, -2.0636e-02, -3.1363e-02,\n",
            "        -2.2840e-02, -4.2374e-02, -3.5590e-02, -4.5238e-02,  7.7126e-03,\n",
            "        -3.9953e-02, -3.9526e-02, -3.0946e-02,  4.1929e-03, -1.1248e-02,\n",
            "        -1.7499e-02, -2.3410e-02, -2.3368e-02, -3.3291e-04, -4.5255e-02,\n",
            "        -3.7707e-02, -2.3958e-02, -2.5831e-02, -2.5592e-02, -1.9607e-02,\n",
            "        -1.0032e-02, -3.6462e-02, -2.4751e-02, -1.4940e-02, -3.4437e-02,\n",
            "        -1.9136e-02, -2.4027e-02, -6.4017e-03, -2.0484e-02, -1.9767e-02,\n",
            "        -1.6732e-02, -1.8487e-02, -3.7537e-02, -2.9241e-02, -1.7735e-02,\n",
            "        -3.3520e-03, -2.0143e-02, -1.1977e-02, -2.9115e-02,  5.6522e-03,\n",
            "        -3.3281e-02, -1.4052e-02, -1.0010e-02, -4.0437e-05, -1.3437e-02,\n",
            "        -1.5642e-02, -1.9672e-02, -1.1519e-02, -5.6670e-03, -1.4031e-02,\n",
            "        -1.5298e-02], device='cuda:0')), ('classifier.0.convs.2.1.running_mean', tensor([-1.9020e-01, -6.2977e-01, -2.6778e-02,  1.9720e-01,  7.1733e-01,\n",
            "        -4.6933e-01, -5.7696e-01, -3.2670e-01, -9.6674e-01, -6.3070e-02,\n",
            "         1.7085e+00, -3.2130e-01,  4.5577e-01, -5.1895e-01,  1.7904e-01,\n",
            "        -4.1184e-01, -1.2518e-01, -1.3980e+00,  5.3573e-01, -5.4733e-01,\n",
            "        -4.8990e-01, -1.1094e+00,  1.8993e-02, -5.6830e-01, -4.5390e-01,\n",
            "        -7.4760e-01, -7.0383e-01, -5.7450e-01, -5.1635e-01, -2.5093e-01,\n",
            "        -5.4500e-01, -3.8322e-01, -7.1733e-01, -6.1709e-01, -6.7470e-01,\n",
            "        -7.8257e-01,  3.3073e-01, -6.1566e-01,  1.8500e-01, -5.1471e-01,\n",
            "         1.2717e+00,  6.8267e-01, -5.7510e-01, -2.5580e-01, -7.5448e-01,\n",
            "        -7.9520e-01, -8.8618e-01, -1.7281e-02,  8.2974e-01, -2.6949e-01,\n",
            "        -4.4405e-01, -9.0802e-01, -5.9515e-01, -2.4230e-01, -7.8727e-01,\n",
            "        -8.9578e-01, -4.8214e-01, -8.8882e-01, -4.3747e-01, -7.6830e-01,\n",
            "        -1.4411e-01,  2.5625e-01,  2.2489e-01,  1.9531e-01, -5.2957e-01,\n",
            "        -7.3259e-01,  6.3176e-02, -9.3215e-01, -3.3237e-01,  1.4602e+00,\n",
            "         2.8395e-02, -4.1731e-01, -8.6052e-01, -7.2900e-01, -4.6478e-01,\n",
            "        -9.2471e-01, -6.8237e-01, -4.2020e-01, -5.3405e-01, -2.6935e-01,\n",
            "        -3.0759e-01, -2.5200e-01, -5.9213e-01, -3.5744e-01, -9.1879e-01,\n",
            "        -1.0299e-01, -1.0230e-01, -3.9614e-01, -5.4488e-01,  4.2737e-02,\n",
            "        -3.0716e-01, -4.2476e-01,  1.0723e+00, -7.7710e-01, -5.7106e-01,\n",
            "        -7.3584e-01,  2.2443e-01, -2.1263e-01, -2.1134e-01, -5.2275e-02,\n",
            "        -7.2651e-01, -1.5218e-01, -6.0579e-01,  1.9240e-02, -1.4352e-01,\n",
            "        -2.5104e-01,  5.1980e-01, -9.0417e-01, -3.2216e-01, -2.5394e-01,\n",
            "         1.2075e-01,  5.2145e-04,  1.2893e-01, -2.6379e-01, -1.3894e+00,\n",
            "        -1.0257e+00, -1.1005e+00, -4.6640e-01, -4.4935e-01, -7.8277e-01,\n",
            "        -4.4068e-01, -9.6985e-01, -3.5609e-01, -6.5580e-01,  8.7076e-02,\n",
            "        -6.6475e-01, -6.6185e-01, -1.0707e+00, -5.1203e-01, -1.0341e+00,\n",
            "        -7.3112e-01,  7.6930e-02, -5.8213e-01, -7.2118e-01, -3.5199e-02,\n",
            "        -7.3198e-01, -3.0341e-01,  1.4293e-01, -2.2798e-01, -1.6495e-01,\n",
            "        -9.4087e-01,  6.5312e-01, -2.9686e-01,  8.4070e-01, -7.2394e-01,\n",
            "        -1.2216e+00, -1.5995e-02,  2.1825e+00, -1.5665e-03, -6.4997e-01,\n",
            "         3.5725e-01, -6.0095e-01, -1.9859e+00, -5.8944e-02, -7.4760e-01,\n",
            "        -9.6037e-01, -8.1897e-01, -6.2879e-01,  6.8164e-03, -6.8364e-01,\n",
            "        -6.1817e-01, -5.1717e-01,  2.7765e-01, -5.5779e-01, -2.3540e-02,\n",
            "        -5.5804e-01, -4.1816e-01, -3.4873e-01, -3.9435e-01, -1.1019e+00,\n",
            "        -1.2659e+00, -5.7797e-01,  1.9936e+00, -3.4030e-01, -7.4242e-01,\n",
            "         5.8699e-01, -3.9164e-01, -4.5995e-01, -7.0192e-01,  6.2263e-01,\n",
            "        -2.1328e-01, -8.7380e-01, -7.6765e-01, -1.0504e+00, -8.6436e-02,\n",
            "        -4.6219e-01, -3.1469e-01, -8.6305e-01, -5.6278e-01, -2.1378e-01,\n",
            "        -1.4510e+00,  5.5921e-01, -1.6645e-01,  5.8264e-01, -6.8634e-01,\n",
            "         6.2357e-02, -1.0897e+00, -8.2626e-01,  6.4602e-01, -6.0786e-01,\n",
            "         8.1432e-01, -1.3471e-01, -7.6088e-01, -8.9141e-01, -4.6757e-01,\n",
            "         4.7471e-01, -8.4036e-01,  1.5546e+00,  2.0204e+00, -6.6766e-01,\n",
            "        -9.4774e-01,  1.8171e+00, -1.3187e+00, -6.5221e-01, -2.5817e-01,\n",
            "        -3.1672e-01,  2.8676e-01, -6.9222e-01, -8.0504e-01,  9.6490e-01,\n",
            "        -1.0644e+00, -7.5223e-01, -4.3490e-01, -4.2268e-01, -1.2761e-01,\n",
            "        -4.6254e-01,  4.8920e-01, -8.1736e-01, -8.8671e-01, -8.0496e-01,\n",
            "        -1.1282e-01, -6.5420e-01, -7.3744e-01, -4.6193e-01, -8.3250e-01,\n",
            "         8.1222e-01, -7.1731e-01, -7.0339e-01, -9.5005e-01, -6.3360e-01,\n",
            "        -7.9059e-02, -1.5974e+00, -2.0372e-01, -4.2390e-02, -7.6203e-01,\n",
            "        -7.6820e-01, -5.7109e-01, -9.4165e-01, -6.6084e-01, -1.2288e+00,\n",
            "         6.4244e-02, -4.6208e-01, -5.5167e-01, -7.9214e-01, -1.5173e-01,\n",
            "         9.2905e-01], device='cuda:0')), ('classifier.0.convs.2.1.running_var', tensor([ 1.4104,  2.9895,  1.7197,  4.1669,  2.1954,  0.6195,  1.5084,  0.7321,\n",
            "         1.0280,  1.5931,  2.6419,  2.1320,  1.7714,  2.8409,  1.5325,  1.3688,\n",
            "         0.2658,  3.8561,  1.2336,  0.9694,  1.5816,  5.2701,  0.5477,  4.4501,\n",
            "         1.0082,  1.8661,  1.5296,  3.6941,  1.7897,  2.9309,  1.4033,  4.1354,\n",
            "         1.3297,  0.7508,  1.5707,  1.5267,  1.1241,  2.9861,  0.6272,  1.5384,\n",
            "         2.1308,  1.3444,  0.5035,  0.8107,  6.5455,  5.4223,  5.6434,  2.0243,\n",
            "         1.8056,  1.5004,  1.0675,  1.4226,  3.4241,  1.3134,  1.5179,  1.0442,\n",
            "         2.7233,  1.0362,  1.0731,  1.4282,  2.7556,  4.0938,  2.7733,  0.9785,\n",
            "         1.0906,  1.6952,  6.9893,  3.0270,  3.4781,  5.0732,  0.9006,  2.7541,\n",
            "         2.1576,  6.4309,  3.5307,  3.1118,  1.6018,  5.4011,  1.2779,  0.9478,\n",
            "         2.6358,  2.4743,  1.2223,  0.9195,  2.2780,  0.3550,  0.9289,  1.1805,\n",
            "         2.5009,  0.5886,  0.5630,  0.8822,  2.3551,  0.8150,  1.4804,  1.9319,\n",
            "         1.6397,  0.3952,  0.9166,  1.9955,  1.3928,  0.8073,  2.2575,  1.1514,\n",
            "         1.1239,  1.1522,  1.2526,  2.2450,  1.4861,  5.5850,  0.3536,  3.7546,\n",
            "         0.5773,  1.3361,  4.5517,  1.7783,  1.6908,  0.8459,  1.2000,  1.5756,\n",
            "         1.8540,  1.0822,  3.3544,  2.0081,  0.8812,  3.7285,  2.8233,  0.9355,\n",
            "         4.1005,  6.7215,  3.6147,  0.7886,  0.6155,  2.1302,  0.8455,  0.8455,\n",
            "         0.5453,  0.8646,  0.8497,  0.5561,  4.3295,  2.3573,  1.0586,  7.6303,\n",
            "         1.7295,  3.6911,  1.1377,  4.1547,  1.0924,  0.7183,  1.1714,  0.7787,\n",
            "         5.8992,  1.0997,  2.6236, 10.7035,  1.3478,  1.1288,  1.7582,  1.2923,\n",
            "         0.8261,  0.8775,  2.6023,  0.6250,  1.7661,  2.5817,  0.7789,  0.8145,\n",
            "         1.5588,  6.6419,  0.9564,  1.2241,  2.8638,  1.1056,  1.8298,  1.8794,\n",
            "         0.9599,  3.1681,  1.8463,  1.4297,  3.3295,  2.7305,  2.0358,  3.7728,\n",
            "         1.7998,  3.6071,  1.2337,  2.2156,  1.2372,  4.9494,  3.2563,  3.4733,\n",
            "         3.1521,  2.0775,  1.4612,  1.8817,  1.8154,  0.7860,  1.4023,  3.1309,\n",
            "         2.6543,  2.5197,  2.6825,  2.9096,  1.5844,  0.4031,  3.5474,  2.9985,\n",
            "         3.0458,  2.8452,  1.7732,  1.9799,  4.0292,  1.8829,  4.4210,  1.6847,\n",
            "         2.9394,  1.1028,  1.8227,  1.5222,  1.3608,  1.3803,  3.5781,  1.1046,\n",
            "         0.9872,  2.7157,  2.6926,  0.7556,  3.2273,  1.6242,  1.0684,  0.8039,\n",
            "         2.1649,  2.2357,  2.2340,  2.0528,  3.8817,  2.8149,  8.3250,  1.9795,\n",
            "         0.4878,  4.4909,  2.5547,  2.1218,  2.2531,  2.6785,  2.3980,  2.9237,\n",
            "         0.5841,  1.3784,  0.5277,  1.2331,  2.5430,  3.5215,  3.1634,  1.2631],\n",
            "       device='cuda:0')), ('classifier.0.convs.2.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.convs.3.0.weight', tensor([[[[-2.0607e-04, -1.1789e-02, -9.1035e-03],\n",
            "          [ 1.3777e-02, -1.2187e-02, -4.1440e-03],\n",
            "          [-4.1704e-03,  4.9781e-04, -5.2074e-03]],\n",
            "\n",
            "         [[ 4.5792e-04, -8.3212e-03, -1.0269e-02],\n",
            "          [ 2.8068e-03,  1.3978e-02, -5.4260e-03],\n",
            "          [ 1.3193e-04, -1.4269e-02, -4.7902e-03]],\n",
            "\n",
            "         [[ 5.5432e-03, -1.7266e-02, -5.3558e-03],\n",
            "          [-1.5107e-03,  4.5587e-03, -8.5351e-03],\n",
            "          [ 4.3146e-03,  6.6149e-03,  3.4777e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8181e-03, -1.3821e-02, -7.6698e-03],\n",
            "          [ 1.4143e-02, -5.0257e-03, -1.5818e-03],\n",
            "          [ 3.3928e-03, -1.1363e-02,  3.0010e-03]],\n",
            "\n",
            "         [[ 1.2996e-02, -4.6492e-03, -2.1147e-03],\n",
            "          [ 6.2420e-03,  4.5929e-03, -5.9197e-03],\n",
            "          [-1.0426e-02, -6.3869e-03,  1.7881e-03]],\n",
            "\n",
            "         [[ 4.5163e-04, -1.6654e-02, -7.5593e-03],\n",
            "          [ 2.8518e-02, -9.4510e-03, -1.1281e-02],\n",
            "          [-1.0602e-03, -1.1258e-02,  5.3023e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3509e-03, -4.7560e-03,  2.1638e-03],\n",
            "          [-8.8018e-04,  6.5482e-03, -6.4197e-03],\n",
            "          [ 1.5400e-04,  1.2554e-03, -2.6940e-03]],\n",
            "\n",
            "         [[-1.1416e-03,  1.1622e-03,  8.4808e-03],\n",
            "          [ 6.4237e-03, -6.0485e-04, -8.2098e-03],\n",
            "          [-6.2659e-03,  1.6727e-02,  2.6237e-04]],\n",
            "\n",
            "         [[-8.7216e-03, -1.7726e-02,  1.7463e-03],\n",
            "          [-9.9111e-03,  9.8902e-03, -8.7534e-03],\n",
            "          [-8.5297e-03, -7.1744e-03, -6.2637e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7090e-04, -8.8469e-03,  5.7322e-03],\n",
            "          [-5.2394e-03,  1.4491e-03, -8.9023e-03],\n",
            "          [ 1.0359e-02,  1.4108e-02, -4.7652e-03]],\n",
            "\n",
            "         [[-5.4543e-03, -9.2837e-03, -1.0661e-02],\n",
            "          [-1.7714e-03,  7.8659e-03, -7.7917e-04],\n",
            "          [-3.3986e-03,  4.1963e-03, -6.9819e-03]],\n",
            "\n",
            "         [[-4.2189e-03,  9.3393e-03, -1.5989e-03],\n",
            "          [-6.1530e-03,  1.2595e-02, -1.3860e-02],\n",
            "          [-7.0217e-03, -8.8638e-03, -2.2865e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.5703e-03, -7.2958e-04,  1.9510e-03],\n",
            "          [-2.4068e-03, -1.7252e-02,  8.1546e-04],\n",
            "          [ 1.0872e-02,  3.7307e-03,  9.2984e-03]],\n",
            "\n",
            "         [[-3.6237e-04, -1.0031e-02, -1.3725e-02],\n",
            "          [-8.8352e-03,  4.8775e-03,  1.1619e-02],\n",
            "          [ 7.7129e-03,  4.3514e-03,  3.2980e-04]],\n",
            "\n",
            "         [[-9.1651e-04,  6.1959e-03, -3.9947e-03],\n",
            "          [-4.7025e-03, -1.1972e-02,  6.7938e-03],\n",
            "          [ 1.3411e-02,  2.6188e-02,  1.4651e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.7002e-03,  4.8342e-03, -9.5929e-03],\n",
            "          [ 9.9184e-03,  1.0488e-03,  1.5735e-02],\n",
            "          [ 6.0648e-03,  2.2634e-02,  1.5094e-02]],\n",
            "\n",
            "         [[-4.1444e-03,  1.6719e-02, -1.7475e-03],\n",
            "          [ 2.7196e-03, -1.2203e-03,  1.6846e-03],\n",
            "          [ 1.3716e-03,  1.8706e-03,  1.3984e-02]],\n",
            "\n",
            "         [[-6.9882e-03, -9.2345e-04, -6.2575e-04],\n",
            "          [ 2.3663e-02,  1.1936e-03,  1.3223e-02],\n",
            "          [ 7.8418e-03,  4.4422e-03,  9.1404e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.6637e-03, -2.1430e-02, -2.3609e-03],\n",
            "          [-2.0816e-02, -1.3391e-02, -2.3459e-02],\n",
            "          [ 3.6458e-03, -1.8566e-02, -2.4590e-03]],\n",
            "\n",
            "         [[-1.3428e-03, -9.8564e-03,  1.6527e-03],\n",
            "          [-2.0154e-02,  6.5861e-04, -1.6018e-02],\n",
            "          [-3.2580e-03, -2.5117e-02, -5.9046e-03]],\n",
            "\n",
            "         [[ 4.2982e-03, -8.9596e-03, -3.1378e-03],\n",
            "          [-1.2899e-02, -6.4219e-04, -1.2763e-02],\n",
            "          [ 5.0111e-03, -7.1167e-03, -1.5080e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2845e-03, -1.4687e-02, -5.6771e-03],\n",
            "          [-1.2765e-02, -1.5899e-03, -1.3140e-02],\n",
            "          [ 6.0837e-03, -1.3931e-02,  1.0913e-04]],\n",
            "\n",
            "         [[ 1.0177e-02, -6.6726e-03,  8.9081e-03],\n",
            "          [-1.6667e-02, -5.1099e-03, -8.1469e-03],\n",
            "          [ 6.8097e-05, -1.2461e-02, -7.8700e-03]],\n",
            "\n",
            "         [[ 5.2395e-03, -2.2997e-02, -2.9577e-03],\n",
            "          [-1.1731e-02, -1.2217e-02, -1.8318e-02],\n",
            "          [ 2.1440e-03, -1.2404e-02, -5.2275e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.0736e-04, -9.0787e-03,  8.1488e-04],\n",
            "          [-1.3275e-03,  8.1288e-03,  8.8672e-04],\n",
            "          [ 6.4504e-03,  1.0229e-02,  1.2689e-02]],\n",
            "\n",
            "         [[-5.5810e-03, -3.9525e-03,  1.1583e-03],\n",
            "          [ 2.8535e-04, -5.0028e-03, -4.9758e-03],\n",
            "          [-3.7765e-03,  1.2506e-02,  4.9282e-03]],\n",
            "\n",
            "         [[-3.7998e-03, -1.9115e-02,  3.0553e-04],\n",
            "          [ 3.1200e-03,  6.6645e-03,  4.6003e-03],\n",
            "          [-2.2346e-03, -1.2320e-03,  1.1715e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0774e-03, -4.0429e-03,  8.8655e-03],\n",
            "          [-5.8107e-03,  2.8929e-03, -1.1699e-02],\n",
            "          [ 7.9506e-03,  1.7263e-02,  3.5436e-03]],\n",
            "\n",
            "         [[-6.7749e-03, -1.4286e-02, -1.3541e-05],\n",
            "          [-1.2056e-02,  4.4963e-03, -3.1188e-03],\n",
            "          [-3.3128e-03, -7.5659e-03, -1.4083e-02]],\n",
            "\n",
            "         [[ 3.8833e-03,  1.2064e-05, -8.9273e-04],\n",
            "          [-1.2757e-02, -1.2280e-02, -6.2593e-03],\n",
            "          [-1.5874e-03, -4.3551e-03, -3.5591e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.1347e-04, -4.7417e-03, -1.0226e-02],\n",
            "          [ 1.0537e-02, -9.9567e-03,  1.4146e-03],\n",
            "          [ 7.4847e-03,  1.1350e-02,  7.8197e-03]],\n",
            "\n",
            "         [[ 2.2340e-03, -1.1816e-02, -1.1839e-02],\n",
            "          [-1.3588e-02, -1.4270e-04,  1.1974e-03],\n",
            "          [ 5.7679e-03, -5.0180e-03,  1.5468e-02]],\n",
            "\n",
            "         [[ 3.4069e-04, -1.8214e-02, -7.9217e-03],\n",
            "          [-5.2921e-03, -1.6753e-02,  5.3530e-03],\n",
            "          [ 7.6141e-03,  2.5808e-02,  8.5029e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0219e-02,  1.6678e-03, -5.8090e-03],\n",
            "          [ 2.0208e-02, -9.9129e-03,  1.3149e-02],\n",
            "          [ 1.1208e-02,  1.1968e-02,  1.7446e-02]],\n",
            "\n",
            "         [[ 3.2898e-03, -9.8128e-03, -6.6274e-03],\n",
            "          [-2.1120e-03, -1.3262e-02, -7.3753e-03],\n",
            "          [ 5.6784e-03,  2.7995e-03,  8.5226e-03]],\n",
            "\n",
            "         [[-2.6209e-03, -1.7895e-02, -6.7677e-03],\n",
            "          [ 2.5837e-03, -2.0366e-02,  1.4512e-02],\n",
            "          [ 7.2121e-04,  4.6835e-03,  7.8562e-03]]]], device='cuda:0')), ('classifier.0.convs.3.1.weight', tensor([0.3945, 0.3994, 0.3932, 0.4200, 0.4114, 0.4098, 0.4082, 0.4104, 0.3895,\n",
            "        0.3937, 0.4046, 0.3854, 0.3960, 0.4041, 0.3986, 0.3926, 0.4343, 0.3925,\n",
            "        0.3957, 0.3689, 0.4179, 0.3977, 0.4037, 0.3871, 0.4075, 0.4029, 0.3921,\n",
            "        0.4366, 0.4049, 0.4095, 0.4012, 0.4223, 0.4064, 0.4142, 0.4115, 0.4041,\n",
            "        0.3861, 0.4035, 0.4007, 0.3986, 0.3831, 0.4028, 0.4021, 0.3977, 0.4327,\n",
            "        0.3964, 0.4131, 0.4057, 0.3992, 0.4067, 0.4072, 0.4381, 0.4206, 0.4038,\n",
            "        0.4024, 0.4074, 0.4049, 0.4102, 0.3942, 0.4107, 0.3961, 0.4059, 0.4043,\n",
            "        0.4185, 0.3867, 0.4180, 0.3893, 0.3986, 0.4012, 0.3951, 0.3935, 0.4005,\n",
            "        0.3894, 0.3915, 0.3883, 0.4117, 0.3929, 0.3853, 0.3964, 0.3928, 0.4078,\n",
            "        0.3934, 0.4188, 0.3888, 0.3990, 0.4016, 0.3990, 0.4011, 0.4056, 0.4107,\n",
            "        0.3800, 0.3840, 0.3906, 0.4144, 0.4241, 0.4077, 0.4253, 0.3908, 0.4061,\n",
            "        0.3968, 0.3876, 0.3913, 0.3865, 0.4034, 0.3932, 0.3974, 0.3877, 0.3882,\n",
            "        0.4034, 0.3989, 0.4084, 0.4122, 0.4007, 0.3837, 0.3699, 0.4122, 0.3842,\n",
            "        0.3852, 0.4107, 0.4010, 0.4211, 0.3885, 0.4013, 0.4020, 0.3833, 0.4086,\n",
            "        0.3877, 0.4039, 0.3878, 0.3866, 0.3982, 0.4005, 0.3891, 0.3958, 0.4051,\n",
            "        0.4056, 0.4397, 0.4031, 0.4056, 0.4036, 0.4204, 0.4030, 0.3996, 0.3991,\n",
            "        0.3953, 0.4186, 0.3842, 0.3798, 0.4002, 0.3754, 0.4222, 0.3996, 0.3968,\n",
            "        0.4193, 0.3872, 0.3971, 0.3997, 0.3928, 0.3980, 0.3933, 0.4083, 0.3690,\n",
            "        0.3930, 0.4287, 0.3966, 0.4188, 0.4235, 0.3859, 0.3954, 0.4024, 0.3879,\n",
            "        0.3931, 0.4025, 0.3795, 0.3874, 0.4016, 0.3933, 0.3892, 0.3938, 0.3998,\n",
            "        0.4019, 0.3951, 0.3982, 0.3985, 0.3942, 0.4047, 0.4075, 0.4355, 0.4009,\n",
            "        0.3955, 0.4043, 0.4036, 0.3956, 0.3894, 0.3990, 0.3961, 0.3929, 0.3854,\n",
            "        0.3933, 0.3922, 0.4050, 0.3908, 0.3906, 0.3876, 0.4031, 0.3871, 0.3851,\n",
            "        0.3971, 0.3914, 0.3928, 0.4047, 0.4166, 0.4096, 0.4017, 0.3938, 0.4000,\n",
            "        0.3949, 0.4001, 0.3998, 0.3952, 0.4070, 0.4098, 0.3896, 0.4133, 0.4045,\n",
            "        0.4125, 0.3877, 0.3919, 0.3939, 0.3846, 0.3907, 0.4051, 0.3928, 0.3999,\n",
            "        0.3899, 0.4033, 0.4190, 0.4184, 0.3976, 0.4019, 0.4004, 0.3986, 0.4083,\n",
            "        0.4247, 0.3979, 0.4087, 0.3899, 0.4174, 0.3826, 0.4153, 0.3956, 0.3784,\n",
            "        0.4039, 0.4077, 0.4170, 0.3983], device='cuda:0')), ('classifier.0.convs.3.1.bias', tensor([-0.0108, -0.0315,  0.0007,  0.0204, -0.0221,  0.0102, -0.0118,  0.0090,\n",
            "        -0.0414, -0.0185, -0.0280, -0.0073, -0.0129, -0.0249, -0.0391, -0.0505,\n",
            "        -0.0037, -0.0143, -0.0059, -0.0351, -0.0312, -0.0114,  0.0010, -0.0160,\n",
            "        -0.0129,  0.0010, -0.0156,  0.0179, -0.0366,  0.0018, -0.0366, -0.0005,\n",
            "         0.0089,  0.0136, -0.0017,  0.0033, -0.0202,  0.0069, -0.0042, -0.0372,\n",
            "        -0.0108, -0.0453, -0.0404, -0.0036,  0.0222, -0.0235,  0.0026, -0.0262,\n",
            "        -0.0106, -0.0302, -0.0038, -0.0022, -0.0217, -0.0038, -0.0056,  0.0041,\n",
            "        -0.0385, -0.0134, -0.0129, -0.0087, -0.0162, -0.0006, -0.0018,  0.0080,\n",
            "        -0.0144, -0.0090, -0.0091, -0.0118,  0.0025, -0.0287, -0.0157,  0.0024,\n",
            "        -0.0086, -0.0204, -0.0123,  0.0025, -0.0107, -0.0207, -0.0115, -0.0459,\n",
            "        -0.0372, -0.0541, -0.0251, -0.0143,  0.0057,  0.0040, -0.0029, -0.0077,\n",
            "        -0.0095, -0.0242, -0.0228, -0.0313, -0.0048,  0.0138, -0.0256, -0.0241,\n",
            "         0.0170, -0.0116,  0.0078, -0.0236, -0.0138, -0.0161, -0.0515,  0.0056,\n",
            "        -0.0052, -0.0027, -0.0464, -0.0242, -0.0271, -0.0101, -0.0110,  0.0047,\n",
            "        -0.0098, -0.0206, -0.0179,  0.0028, -0.0075, -0.0051,  0.0120, -0.0224,\n",
            "        -0.0270, -0.0260, -0.0125, -0.0190, -0.0132,  0.0113, -0.0157, -0.0117,\n",
            "        -0.0103, -0.0350, -0.0476, -0.0052, -0.0056, -0.0193,  0.0143,  0.0064,\n",
            "        -0.0112, -0.0119, -0.0159,  0.0016, -0.0122,  0.0044, -0.0122, -0.0291,\n",
            "        -0.0232, -0.0333, -0.0155, -0.0161,  0.0019, -0.0296, -0.0262, -0.0100,\n",
            "        -0.0165, -0.0202, -0.0095, -0.0098, -0.0006, -0.0263, -0.0257, -0.0399,\n",
            "        -0.0227, -0.0256, -0.0135,  0.0020, -0.0012, -0.0105,  0.0138, -0.0216,\n",
            "        -0.0349, -0.0478, -0.0062, -0.0374,  0.0011, -0.0232, -0.0085, -0.0251,\n",
            "        -0.0414, -0.0324, -0.0044, -0.0122,  0.0011, -0.0045, -0.0096, -0.0266,\n",
            "        -0.0042,  0.0017,  0.0092, -0.0154, -0.0032, -0.0087, -0.0306,  0.0018,\n",
            "        -0.0060, -0.0274, -0.0250, -0.0262, -0.0026, -0.0258, -0.0049, -0.0201,\n",
            "         0.0084, -0.0083, -0.0103, -0.0376, -0.0209, -0.0110, -0.0134, -0.0249,\n",
            "        -0.0153, -0.0037, -0.0219,  0.0031,  0.0060, -0.0160, -0.0167,  0.0057,\n",
            "        -0.0033, -0.0081, -0.0250, -0.0476, -0.0058, -0.0308, -0.0107, -0.0178,\n",
            "        -0.0330, -0.0201, -0.0375, -0.0107, -0.0323, -0.0290, -0.0417, -0.0023,\n",
            "        -0.0236,  0.0078, -0.0192,  0.0024, -0.0240,  0.0163, -0.0002, -0.0032,\n",
            "         0.0038, -0.0031, -0.0061,  0.0046, -0.0141, -0.0024,  0.0007, -0.0087,\n",
            "        -0.0089,  0.0174, -0.0107, -0.0179,  0.0093,  0.0077, -0.0432, -0.0068],\n",
            "       device='cuda:0')), ('classifier.0.convs.3.1.running_mean', tensor([-0.1756,  0.0351, -0.1288, -0.2989, -0.3688, -0.4435, -0.0521, -0.2799,\n",
            "        -0.2259,  0.5040, -0.4342, -0.1672, -0.6376, -0.1301, -0.0014,  0.0870,\n",
            "        -0.0811, -0.3511, -0.5159, -0.0145, -0.3485,  0.4228,  0.1303,  0.2755,\n",
            "        -0.6119, -0.3377, -0.2757, -0.0242, -0.2873, -0.0842, -0.0838, -0.2622,\n",
            "        -0.4789, -0.2790, -0.1466, -0.3669, -0.3104, -0.6136, -0.5005,  0.0864,\n",
            "        -0.1852, -0.0833,  0.0245, -0.1515, -0.3397, -0.1821, -0.3485,  0.3140,\n",
            "        -0.4968, -0.3777, -0.1334, -0.1451,  0.1634,  0.0929, -0.6466, -0.4363,\n",
            "         0.1505, -0.2311, -0.7187, -0.6232, -0.6285,  0.0480, -0.0986, -0.2214,\n",
            "        -0.0889,  0.1027, -0.7021,  0.6822, -0.2666, -0.1703,  0.1992, -0.3325,\n",
            "        -0.1261,  0.4794, -0.5619, -0.5127,  0.0398, -0.0248, -0.0191,  0.0953,\n",
            "        -0.2663,  0.1161, -0.1786, -0.4995, -0.5605, -0.3725, -0.2090, -0.0039,\n",
            "         0.1439, -0.5028, -0.3964, -0.3717, -0.4360, -0.2317, -0.3343, -0.3382,\n",
            "        -0.2837, -0.1023, -0.5127, -0.4897, -0.5263, -0.3162,  0.0225, -0.2901,\n",
            "        -0.5020, -0.6767,  0.2759,  0.4677, -0.0875, -0.1669,  0.1526, -0.2874,\n",
            "         0.0101, -0.3874, -0.1996, -0.3150, -0.6350, -0.6388, -0.2129, -0.3894,\n",
            "        -0.3241, -0.5726,  0.0147, -0.4517, -0.2047, -0.3698, -0.3196, -0.6617,\n",
            "         0.3982,  0.2762, -0.2704, -0.0899, -0.5204, -0.7368, -0.4000, -0.4276,\n",
            "        -0.2563, -0.3741, -0.4387, -0.6913,  0.1562, -0.2689, -0.0856, -0.1844,\n",
            "         0.1458, -0.1321,  0.0778, -0.2014, -0.7829, -0.6184, -0.2012, -0.5701,\n",
            "        -0.0684, -0.1571, -0.3889,  0.5336, -0.5047, -0.2890, -0.6966,  0.0431,\n",
            "        -0.3185, -0.2987, -0.1588, -0.3525, -0.3849,  0.2097, -0.4273,  0.6315,\n",
            "         0.1188,  0.0566, -0.3332, -0.1335, -0.4591, -0.2124, -0.2172, -0.0871,\n",
            "         0.7339, -0.0560, -0.6449,  0.1232, -0.1222, -0.1043,  0.2933, -0.0727,\n",
            "        -0.6026, -0.5756, -0.4573, -0.1594, -0.3012, -0.4872, -0.2222, -0.5680,\n",
            "        -0.4307,  0.3039, -0.1479, -0.2519, -0.2728, -0.7121, -0.1098,  0.4529,\n",
            "        -0.3515, -0.2870, -0.1659, -0.0418, -0.5251, -0.2152, -0.1701, -0.1702,\n",
            "         0.4452, -0.0871, -0.2167, -0.2324, -0.5269,  0.0475, -0.3479, -0.3249,\n",
            "        -0.1600, -0.4285, -0.3600,  0.1724, -0.0412, -0.2882, -0.4568, -0.4278,\n",
            "         0.1457, -0.2932,  0.0192, -0.2635,  0.0711, -0.2092,  0.5897, -0.3380,\n",
            "        -0.5533, -0.5104,  0.2170, -0.5714, -0.3604, -0.1470, -0.3156, -0.3569,\n",
            "        -0.5721, -0.2728, -0.1584, -0.1256, -0.3134,  0.0632, -0.5304, -0.4546,\n",
            "        -0.4105, -0.4897, -0.2534,  0.0338, -0.4826, -0.4137, -0.2091, -0.3885],\n",
            "       device='cuda:0')), ('classifier.0.convs.3.1.running_var', tensor([0.9263, 0.8973, 0.7973, 0.6043, 0.6188, 0.7341, 0.3090, 0.8134, 0.7513,\n",
            "        2.3275, 0.5980, 1.5001, 1.6997, 0.2466, 0.4768, 0.6322, 0.1194, 0.4707,\n",
            "        1.0548, 2.5230, 0.5967, 0.7164, 0.6042, 1.0088, 0.3754, 0.7500, 1.2420,\n",
            "        0.3820, 0.5579, 0.3769, 0.5322, 0.2573, 0.9618, 0.6124, 0.1280, 1.4739,\n",
            "        0.8285, 1.1738, 0.3473, 0.2109, 1.1875, 0.4859, 0.4925, 1.0491, 0.6239,\n",
            "        0.5816, 0.8177, 0.2656, 1.5017, 0.5041, 0.3630, 0.3271, 0.1421, 0.5435,\n",
            "        0.7868, 0.7977, 0.3295, 0.3340, 0.9132, 0.7313, 1.0716, 0.4719, 0.2649,\n",
            "        0.4209, 1.3511, 0.3942, 0.9810, 1.4354, 0.6449, 0.5223, 0.2691, 0.2936,\n",
            "        1.3186, 1.1906, 1.8600, 0.4897, 0.4034, 1.0894, 0.3506, 0.5743, 0.7210,\n",
            "        0.4255, 0.6015, 0.7519, 1.8501, 0.8155, 0.8428, 0.3081, 0.2795, 0.2228,\n",
            "        1.1580, 1.9183, 1.5029, 0.4710, 0.5846, 0.4212, 0.6517, 0.6454, 0.7648,\n",
            "        0.6318, 1.3054, 0.8370, 0.5723, 0.3155, 0.9380, 0.8234, 0.5041, 0.7960,\n",
            "        0.8224, 0.4689, 0.2681, 0.2144, 0.3235, 0.6144, 1.8898, 0.8769, 1.0847,\n",
            "        1.3071, 0.8148, 0.4107, 0.5692, 0.8190, 0.3834, 0.5830, 0.9316, 1.2096,\n",
            "        1.6647, 0.8305, 0.7697, 1.8542, 0.6868, 0.4035, 0.9883, 0.8718, 0.7883,\n",
            "        1.2373, 0.6473, 0.7091, 0.5259, 1.5806, 0.2889, 0.4618, 0.2926, 0.8465,\n",
            "        0.2996, 0.8129, 1.3542, 2.4182, 1.7829, 2.2475, 0.6588, 0.6669, 0.3679,\n",
            "        0.3069, 1.1801, 2.3904, 0.7227, 0.3651, 0.8753, 0.6362, 0.6502, 1.4345,\n",
            "        0.4676, 0.2473, 1.3473, 0.2644, 0.1439, 2.2949, 0.4820, 0.4022, 1.7235,\n",
            "        1.1123, 1.1627, 0.8053, 1.0760, 0.6693, 1.4387, 0.7242, 1.2326, 0.2850,\n",
            "        0.3849, 0.4085, 0.7243, 0.3415, 1.7342, 1.1567, 0.4528, 0.0973, 0.3922,\n",
            "        1.0793, 0.2776, 0.6853, 0.5729, 0.5780, 0.1997, 0.3626, 0.7228, 2.3258,\n",
            "        1.0640, 0.9629, 0.8834, 1.5807, 0.8086, 0.7235, 0.6743, 1.1588, 0.6487,\n",
            "        0.6894, 0.9524, 1.3298, 0.3206, 0.4994, 0.9823, 0.1454, 0.6000, 0.8702,\n",
            "        1.1038, 1.4119, 0.5849, 0.2891, 0.3895, 0.6432, 1.3649, 0.6475, 0.1692,\n",
            "        0.5562, 0.4332, 0.8028, 0.3535, 1.1682, 0.9988, 0.8597, 0.9437, 0.5197,\n",
            "        0.3735, 0.3782, 0.5889, 0.3775, 0.6711, 1.2528, 1.2313, 0.9645, 0.4182,\n",
            "        0.3323, 0.8033, 0.4227, 1.0812, 0.6187, 1.5898, 1.0650, 0.6034, 1.4417,\n",
            "        0.9209, 0.8485, 0.6778, 0.9329], device='cuda:0')), ('classifier.0.convs.3.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.convs.4.1.weight', tensor([[[[-0.0022]],\n",
            "\n",
            "         [[ 0.0129]],\n",
            "\n",
            "         [[-0.0152]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0212]],\n",
            "\n",
            "         [[-0.0167]],\n",
            "\n",
            "         [[ 0.0019]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0074]],\n",
            "\n",
            "         [[ 0.0051]],\n",
            "\n",
            "         [[ 0.0084]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0031]],\n",
            "\n",
            "         [[ 0.0045]],\n",
            "\n",
            "         [[-0.0017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0014]],\n",
            "\n",
            "         [[-0.0016]],\n",
            "\n",
            "         [[-0.0198]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0066]],\n",
            "\n",
            "         [[ 0.0048]],\n",
            "\n",
            "         [[ 0.0346]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0136]],\n",
            "\n",
            "         [[-0.0330]],\n",
            "\n",
            "         [[-0.0048]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0064]],\n",
            "\n",
            "         [[-0.0233]],\n",
            "\n",
            "         [[-0.0084]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0073]],\n",
            "\n",
            "         [[ 0.0595]],\n",
            "\n",
            "         [[-0.0173]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0014]],\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         [[-0.0102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0280]],\n",
            "\n",
            "         [[-0.0063]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0131]],\n",
            "\n",
            "         [[ 0.0075]],\n",
            "\n",
            "         [[ 0.0158]]]], device='cuda:0')), ('classifier.0.convs.4.2.weight', tensor([0.3743, 0.3660, 0.3740, 0.4071, 0.3889, 0.3734, 0.3697, 0.3972, 0.3991,\n",
            "        0.3776, 0.3772, 0.3828, 0.3271, 0.4084, 0.3446, 0.3927, 0.3840, 0.3950,\n",
            "        0.3624, 0.3719, 0.4072, 0.3584, 0.3914, 0.3791, 0.3670, 0.4043, 0.3720,\n",
            "        0.3719, 0.3823, 0.4022, 0.3885, 0.3637, 0.3721, 0.3804, 0.3929, 0.4250,\n",
            "        0.4265, 0.3850, 0.4177, 0.3618, 0.3904, 0.3798, 0.4016, 0.3986, 0.3851,\n",
            "        0.3774, 0.3541, 0.3821, 0.3710, 0.3308, 0.3486, 0.4011, 0.3662, 0.3952,\n",
            "        0.3845, 0.3693, 0.3624, 0.3984, 0.3824, 0.3710, 0.3618, 0.3678, 0.3725,\n",
            "        0.3434, 0.3910, 0.4144, 0.3718, 0.3800, 0.3661, 0.3872, 0.3676, 0.3906,\n",
            "        0.3885, 0.3856, 0.3864, 0.3882, 0.3963, 0.3482, 0.4047, 0.3946, 0.3507,\n",
            "        0.3882, 0.3986, 0.3529, 0.4042, 0.3446, 0.3562, 0.3548, 0.3670, 0.3712,\n",
            "        0.3757, 0.3850, 0.3482, 0.3844, 0.3730, 0.3555, 0.3548, 0.3891, 0.3845,\n",
            "        0.3633, 0.3316, 0.3796, 0.3715, 0.3962, 0.3915, 0.3971, 0.3739, 0.4214,\n",
            "        0.3555, 0.3779, 0.3594, 0.3630, 0.3507, 0.3721, 0.3810, 0.3940, 0.3767,\n",
            "        0.3574, 0.3808, 0.3972, 0.3563, 0.4144, 0.3847, 0.3901, 0.3536, 0.3652,\n",
            "        0.3935, 0.4028, 0.4192, 0.4048, 0.3767, 0.3785, 0.4088, 0.4129, 0.4028,\n",
            "        0.3847, 0.3583, 0.3781, 0.3510, 0.3280, 0.3661, 0.3733, 0.3791, 0.3832,\n",
            "        0.3683, 0.3677, 0.3610, 0.3848, 0.3463, 0.3670, 0.3386, 0.3714, 0.3925,\n",
            "        0.3925, 0.3948, 0.3968, 0.4117, 0.3685, 0.4014, 0.3739, 0.4052, 0.3621,\n",
            "        0.3777, 0.3742, 0.3960, 0.3626, 0.4093, 0.3832, 0.3749, 0.3770, 0.3527,\n",
            "        0.3832, 0.3537, 0.3854, 0.3643, 0.3778, 0.3746, 0.4021, 0.3788, 0.3722,\n",
            "        0.3533, 0.3694, 0.3520, 0.3466, 0.3928, 0.3690, 0.3962, 0.3854, 0.3575,\n",
            "        0.3766, 0.3993, 0.4010, 0.3648, 0.3455, 0.3879, 0.3825, 0.4117, 0.3501,\n",
            "        0.3818, 0.3917, 0.4112, 0.3326, 0.3795, 0.3929, 0.3704, 0.3905, 0.3901,\n",
            "        0.3713, 0.3669, 0.3935, 0.3660, 0.3815, 0.3723, 0.3804, 0.3814, 0.3776,\n",
            "        0.3705, 0.4122, 0.3754, 0.3796, 0.3514, 0.3656, 0.3468, 0.3900, 0.3704,\n",
            "        0.3640, 0.3819, 0.3830, 0.3854, 0.3558, 0.3633, 0.4081, 0.3874, 0.3481,\n",
            "        0.4154, 0.3905, 0.3459, 0.3930, 0.3946, 0.3839, 0.3917, 0.3742, 0.3668,\n",
            "        0.3959, 0.3697, 0.4113, 0.3782, 0.4175, 0.3783, 0.3948, 0.3931, 0.4134,\n",
            "        0.3988, 0.3534, 0.3887, 0.3957], device='cuda:0')), ('classifier.0.convs.4.2.bias', tensor([-0.0388, -0.0618, -0.0533, -0.0245, -0.0128, -0.0581, -0.0661, -0.0118,\n",
            "        -0.0117, -0.0327, -0.0494, -0.0160, -0.0760, -0.0366, -0.0389, -0.0301,\n",
            "        -0.0576, -0.0525, -0.0754, -0.0247, -0.0188, -0.0538, -0.0324, -0.0258,\n",
            "        -0.0335, -0.0216, -0.0469, -0.0405, -0.0639, -0.0306, -0.0444, -0.0698,\n",
            "        -0.0551, -0.0134, -0.0199, -0.0149,  0.0364, -0.0331,  0.0074, -0.0448,\n",
            "        -0.0593, -0.0335, -0.0416, -0.0122, -0.0158, -0.0338, -0.0810, -0.0391,\n",
            "        -0.0550, -0.0983, -0.0655, -0.0230, -0.0267, -0.0249, -0.0723, -0.0403,\n",
            "        -0.0335, -0.0204, -0.0674, -0.0579, -0.0705, -0.0377, -0.0688, -0.0707,\n",
            "        -0.0159, -0.0212, -0.0579, -0.0699, -0.1229, -0.0339, -0.0885, -0.0197,\n",
            "        -0.0312, -0.0232, -0.0980, -0.0354, -0.0419, -0.0573, -0.0414, -0.0009,\n",
            "        -0.0822, -0.0338, -0.0153, -0.0567, -0.0256, -0.1280, -0.0402, -0.0810,\n",
            "        -0.0691, -0.0260, -0.0335, -0.0801, -0.0626, -0.0538, -0.0309, -0.0864,\n",
            "        -0.0520, -0.0693, -0.0733, -0.0774, -0.0734, -0.0566, -0.0647, -0.0144,\n",
            "        -0.0083, -0.0410, -0.0577,  0.0175, -0.0870, -0.0128, -0.0641, -0.0938,\n",
            "        -0.0669, -0.0774, -0.0362, -0.0665, -0.0452, -0.0389, -0.0401, -0.0239,\n",
            "        -0.0091, -0.0230, -0.0267, -0.0418, -0.0311, -0.0521, -0.0306, -0.0156,\n",
            "        -0.0413, -0.0122, -0.0316, -0.0712,  0.0175, -0.0195, -0.0358,  0.0053,\n",
            "        -0.0686, -0.0804, -0.0563, -0.0923, -0.0424, -0.0827, -0.0390, -0.0441,\n",
            "        -0.0546, -0.0301, -0.0996, -0.0455, -0.0492, -0.0485, -0.0570, -0.0614,\n",
            "        -0.0134, -0.0287, -0.0131, -0.0473, -0.0332, -0.0678, -0.0139, -0.0812,\n",
            "        -0.0393, -0.0421, -0.0453, -0.0439, -0.0285, -0.0502, -0.0128, -0.0234,\n",
            "        -0.0462, -0.0212, -0.0514, -0.0248, -0.0597, -0.0502, -0.0231, -0.0601,\n",
            "        -0.0037, -0.0809, -0.0698, -0.0221, -0.0701, -0.0421, -0.0815, -0.1014,\n",
            "        -0.0336, -0.0088, -0.0063, -0.0079, -0.0571, -0.0298, -0.0223, -0.0024,\n",
            "        -0.0492, -0.1273, -0.0452, -0.0260, -0.0412, -0.0407, -0.0380, -0.0285,\n",
            "        -0.0149, -0.0935, -0.0716,  0.0030, -0.0227, -0.0298, -0.0209, -0.0176,\n",
            "        -0.0599,  0.0034, -0.1029, -0.0498, -0.0579, -0.0224, -0.0245, -0.0055,\n",
            "        -0.0738, -0.0171, -0.0880, -0.0490, -0.0621, -0.0586, -0.0356, -0.0441,\n",
            "        -0.0193, -0.0042, -0.0104, -0.0347, -0.0334, -0.0401, -0.0320, -0.0188,\n",
            "        -0.0439, -0.0764,  0.0010, -0.0274, -0.0589, -0.0123, -0.0244, -0.0291,\n",
            "        -0.0178, -0.1163, -0.0467, -0.0219, -0.0392, -0.0202, -0.0283, -0.0209,\n",
            "        -0.0297, -0.0480, -0.0274, -0.0640,  0.0036, -0.0350, -0.0149, -0.0613],\n",
            "       device='cuda:0')), ('classifier.0.convs.4.2.running_mean', tensor([ 0.2964, -0.2546,  0.0486,  0.0313, -0.0331,  0.0398, -0.1584,  0.1601,\n",
            "        -0.0553,  0.0201,  0.1728,  0.0491, -0.0006, -0.5346, -0.1326, -0.3352,\n",
            "        -0.2749, -0.0323, -0.0744, -0.1899, -0.4027, -0.2128,  0.1821, -0.0872,\n",
            "        -0.2986, -0.3959, -0.2904,  0.1276,  0.2100,  0.3437, -0.0313, -0.1228,\n",
            "        -0.1746, -0.0255, -0.0717,  0.0314, -0.1440, -0.2290, -0.0922, -0.1723,\n",
            "        -0.2975, -0.0721, -0.1979, -0.0463, -0.1428,  0.0498, -0.1854,  0.1348,\n",
            "         0.1890, -0.0177, -0.2976, -0.1578, -0.0489,  0.0322, -0.1029, -0.3812,\n",
            "        -0.2053, -0.2021,  0.2313, -0.4280, -0.1341,  0.2016, -0.2149, -0.2367,\n",
            "         0.2229, -0.1230, -0.3982,  0.1298,  0.3153,  0.1125,  0.0191, -0.1911,\n",
            "         0.2321, -0.0059, -0.3365, -0.1142, -0.2586, -0.0488, -0.3534, -0.1603,\n",
            "        -0.0859, -0.3050, -0.0799, -0.0654,  0.1066,  0.0074, -0.1370, -0.1884,\n",
            "         0.1381, -0.3995, -0.3106,  0.2164, -0.4267, -0.3050,  0.0466,  0.2764,\n",
            "        -0.2062, -0.0536, -0.1562,  0.0464, -0.0282, -0.2262, -0.4946, -0.2449,\n",
            "         0.2174, -0.0259, -0.3164, -0.0453, -0.1003, -0.1959, -0.1323, -0.0256,\n",
            "         0.2504,  0.2141, -0.4981, -0.1146, -0.5410, -0.2793,  0.2479, -0.2668,\n",
            "        -0.1646, -0.1587,  0.0333,  0.0096,  0.0866,  0.1809,  0.2434,  0.0093,\n",
            "        -0.1893, -0.3318,  0.4281, -0.2943, -0.0305, -0.1183,  0.1690, -0.0881,\n",
            "        -0.3180, -0.0719,  0.0454, -0.3523, -0.2729, -0.1089, -0.2181,  0.1713,\n",
            "        -0.2162, -0.3985, -0.2970, -0.2376, -0.2394, -0.3062, -0.0171, -0.3687,\n",
            "         0.0883, -0.0840, -0.1445, -0.1724, -0.2460, -0.2365, -0.2555, -0.0627,\n",
            "        -0.4464, -0.0571,  0.0792, -0.2992,  0.3314, -0.0801,  0.1665, -0.2924,\n",
            "        -0.3976, -0.2182, -0.4835,  0.1514, -0.0957, -0.3371,  0.0539,  0.1802,\n",
            "        -0.0942, -0.1915, -0.0436, -0.1471,  0.1572, -0.1633,  0.2381, -0.1822,\n",
            "         0.0257,  0.0370,  0.2787, -0.0049,  0.0319, -0.3025, -0.0396,  0.1921,\n",
            "        -0.1688,  0.1308, -0.4768, -0.3434, -0.2192, -0.1964, -0.2918,  0.2077,\n",
            "         0.2951,  0.2628,  0.4182, -0.2173, -0.0821, -0.3907, -0.3342, -0.1211,\n",
            "         0.1846,  0.1315, -0.2582, -0.0891, -0.1807, -0.3356,  0.4132, -0.2163,\n",
            "        -0.3950, -0.4805, -0.0064,  0.0115, -0.2487,  0.1686,  0.1228,  0.0164,\n",
            "         0.0598, -0.4508,  0.1819, -0.1112, -0.1522, -0.4073,  0.0210,  0.0375,\n",
            "        -0.1285, -0.1374, -0.1867, -0.1331,  0.0142,  0.3778, -0.0648, -0.4820,\n",
            "        -0.0055,  0.1128, -0.3520, -0.4853, -0.0885,  0.0616,  0.2262, -0.1843,\n",
            "        -0.0866,  0.2590, -0.1645, -0.2248,  0.0745,  0.2750,  0.0810, -0.3748],\n",
            "       device='cuda:0')), ('classifier.0.convs.4.2.running_var', tensor([0.0018, 0.0083, 0.0040, 0.0047, 0.0071, 0.0036, 0.0083, 0.0030, 0.0017,\n",
            "        0.0050, 0.0030, 0.0040, 0.0039, 0.0038, 0.0044, 0.0043, 0.0048, 0.0028,\n",
            "        0.0057, 0.0056, 0.0044, 0.0047, 0.0053, 0.0032, 0.0058, 0.0096, 0.0038,\n",
            "        0.0059, 0.0042, 0.0032, 0.0080, 0.0056, 0.0020, 0.0035, 0.0054, 0.0040,\n",
            "        0.0072, 0.0049, 0.0063, 0.0029, 0.0035, 0.0034, 0.0041, 0.0036, 0.0020,\n",
            "        0.0070, 0.0066, 0.0053, 0.0028, 0.0023, 0.0018, 0.0048, 0.0020, 0.0037,\n",
            "        0.0023, 0.0034, 0.0056, 0.0045, 0.0065, 0.0023, 0.0054, 0.0060, 0.0043,\n",
            "        0.0037, 0.0023, 0.0120, 0.0055, 0.0056, 0.0032, 0.0036, 0.0032, 0.0042,\n",
            "        0.0031, 0.0040, 0.0053, 0.0035, 0.0019, 0.0036, 0.0052, 0.0021, 0.0022,\n",
            "        0.0079, 0.0035, 0.0029, 0.0041, 0.0041, 0.0057, 0.0072, 0.0039, 0.0034,\n",
            "        0.0036, 0.0021, 0.0063, 0.0039, 0.0034, 0.0039, 0.0024, 0.0034, 0.0063,\n",
            "        0.0051, 0.0038, 0.0037, 0.0048, 0.0050, 0.0056, 0.0043, 0.0053, 0.0038,\n",
            "        0.0029, 0.0047, 0.0022, 0.0035, 0.0035, 0.0067, 0.0042, 0.0051, 0.0025,\n",
            "        0.0041, 0.0028, 0.0044, 0.0031, 0.0037, 0.0029, 0.0031, 0.0030, 0.0096,\n",
            "        0.0039, 0.0052, 0.0070, 0.0040, 0.0030, 0.0073, 0.0046, 0.0042, 0.0044,\n",
            "        0.0024, 0.0049, 0.0077, 0.0027, 0.0039, 0.0033, 0.0040, 0.0052, 0.0034,\n",
            "        0.0041, 0.0090, 0.0070, 0.0053, 0.0031, 0.0010, 0.0042, 0.0049, 0.0038,\n",
            "        0.0059, 0.0042, 0.0027, 0.0035, 0.0054, 0.0078, 0.0075, 0.0050, 0.0035,\n",
            "        0.0026, 0.0043, 0.0052, 0.0036, 0.0043, 0.0048, 0.0062, 0.0041, 0.0033,\n",
            "        0.0051, 0.0033, 0.0036, 0.0029, 0.0043, 0.0045, 0.0048, 0.0052, 0.0045,\n",
            "        0.0049, 0.0025, 0.0049, 0.0016, 0.0056, 0.0065, 0.0061, 0.0056, 0.0108,\n",
            "        0.0061, 0.0076, 0.0046, 0.0027, 0.0049, 0.0046, 0.0048, 0.0048, 0.0023,\n",
            "        0.0066, 0.0066, 0.0073, 0.0036, 0.0088, 0.0062, 0.0039, 0.0039, 0.0058,\n",
            "        0.0040, 0.0029, 0.0022, 0.0081, 0.0030, 0.0059, 0.0047, 0.0051, 0.0023,\n",
            "        0.0060, 0.0078, 0.0044, 0.0039, 0.0036, 0.0044, 0.0024, 0.0078, 0.0026,\n",
            "        0.0040, 0.0022, 0.0045, 0.0018, 0.0055, 0.0057, 0.0028, 0.0079, 0.0037,\n",
            "        0.0055, 0.0057, 0.0032, 0.0067, 0.0027, 0.0091, 0.0035, 0.0073, 0.0055,\n",
            "        0.0063, 0.0056, 0.0073, 0.0057, 0.0034, 0.0026, 0.0044, 0.0100, 0.0035,\n",
            "        0.0034, 0.0054, 0.0047, 0.0070], device='cuda:0')), ('classifier.0.convs.4.2.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.0.project.0.weight', tensor([[[[-0.0204]],\n",
            "\n",
            "         [[-0.0032]],\n",
            "\n",
            "         [[-0.0268]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0005]],\n",
            "\n",
            "         [[ 0.0066]],\n",
            "\n",
            "         [[ 0.0058]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0237]],\n",
            "\n",
            "         [[ 0.0112]],\n",
            "\n",
            "         [[ 0.0158]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0308]],\n",
            "\n",
            "         [[ 0.0027]],\n",
            "\n",
            "         [[-0.0140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050]],\n",
            "\n",
            "         [[ 0.0288]],\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         [[-0.0174]],\n",
            "\n",
            "         [[-0.0208]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0158]],\n",
            "\n",
            "         [[-0.0125]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0034]],\n",
            "\n",
            "         [[-0.0071]],\n",
            "\n",
            "         [[-0.0252]]],\n",
            "\n",
            "\n",
            "        [[[-0.0070]],\n",
            "\n",
            "         [[ 0.0071]],\n",
            "\n",
            "         [[ 0.0015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0099]],\n",
            "\n",
            "         [[ 0.0039]],\n",
            "\n",
            "         [[-0.0017]]],\n",
            "\n",
            "\n",
            "        [[[-0.0287]],\n",
            "\n",
            "         [[ 0.0158]],\n",
            "\n",
            "         [[ 0.0068]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0038]],\n",
            "\n",
            "         [[ 0.0094]],\n",
            "\n",
            "         [[ 0.0159]]]], device='cuda:0')), ('classifier.0.project.1.weight', tensor([0.3829, 0.4081, 0.4214, 0.3931, 0.3957, 0.3487, 0.3845, 0.4203, 0.3889,\n",
            "        0.3605, 0.4124, 0.4350, 0.4110, 0.4365, 0.3968, 0.3970, 0.3933, 0.3874,\n",
            "        0.3977, 0.3925, 0.3931, 0.4077, 0.4126, 0.3970, 0.3788, 0.4071, 0.3552,\n",
            "        0.4035, 0.4213, 0.4002, 0.3538, 0.4475, 0.4098, 0.4074, 0.4479, 0.4214,\n",
            "        0.3651, 0.4177, 0.3822, 0.3758, 0.4308, 0.3501, 0.4116, 0.3883, 0.3776,\n",
            "        0.4373, 0.3935, 0.4183, 0.4187, 0.3556, 0.3859, 0.3663, 0.4191, 0.3335,\n",
            "        0.3710, 0.3914, 0.4099, 0.4093, 0.4017, 0.4100, 0.4070, 0.4067, 0.4096,\n",
            "        0.4271, 0.4226, 0.3481, 0.3965, 0.3966, 0.3858, 0.3820, 0.3987, 0.4114,\n",
            "        0.3873, 0.4064, 0.3846, 0.4100, 0.3877, 0.4304, 0.3867, 0.3978, 0.3841,\n",
            "        0.3867, 0.3655, 0.4026, 0.4394, 0.4302, 0.3932, 0.4065, 0.3665, 0.4112,\n",
            "        0.4219, 0.3622, 0.4153, 0.4072, 0.4063, 0.3944, 0.3924, 0.4534, 0.3960,\n",
            "        0.4151, 0.3973, 0.3636, 0.3974, 0.3780, 0.3905, 0.4589, 0.3936, 0.4020,\n",
            "        0.3936, 0.4022, 0.4348, 0.3913, 0.4065, 0.4141, 0.3823, 0.3757, 0.4020,\n",
            "        0.3771, 0.4007, 0.4143, 0.3955, 0.4442, 0.3607, 0.4058, 0.4071, 0.4132,\n",
            "        0.3780, 0.4027, 0.3987, 0.4144, 0.3906, 0.3971, 0.3813, 0.3936, 0.3947,\n",
            "        0.4056, 0.4110, 0.4068, 0.3767, 0.4297, 0.4045, 0.3993, 0.3606, 0.3553,\n",
            "        0.3830, 0.3731, 0.4090, 0.3864, 0.3784, 0.4094, 0.3614, 0.3709, 0.4000,\n",
            "        0.3521, 0.4037, 0.3916, 0.4223, 0.4198, 0.3971, 0.3762, 0.4039, 0.3941,\n",
            "        0.3792, 0.4200, 0.4001, 0.4266, 0.4025, 0.3605, 0.4019, 0.4020, 0.4498,\n",
            "        0.3916, 0.4237, 0.3977, 0.4085, 0.4128, 0.3743, 0.4131, 0.4025, 0.4072,\n",
            "        0.4087, 0.3945, 0.4046, 0.3997, 0.4109, 0.3889, 0.3872, 0.4396, 0.4041,\n",
            "        0.4006, 0.4388, 0.4128, 0.3673, 0.4138, 0.4211, 0.3776, 0.4136, 0.4138,\n",
            "        0.3902, 0.4289, 0.4198, 0.3786, 0.4157, 0.3939, 0.4089, 0.3746, 0.4042,\n",
            "        0.4186, 0.4028, 0.4014, 0.4359, 0.4048, 0.4274, 0.4063, 0.4163, 0.4036,\n",
            "        0.4018, 0.4304, 0.4103, 0.4156, 0.3933, 0.3954, 0.4054, 0.4055, 0.4147,\n",
            "        0.3862, 0.3873, 0.4039, 0.4220, 0.4162, 0.4139, 0.3694, 0.4707, 0.4050,\n",
            "        0.3992, 0.4119, 0.4088, 0.4119, 0.3955, 0.3927, 0.3935, 0.3946, 0.3868,\n",
            "        0.3938, 0.3891, 0.4062, 0.4084, 0.3920, 0.4133, 0.4250, 0.3814, 0.4421,\n",
            "        0.4214, 0.4064, 0.4169, 0.4044], device='cuda:0')), ('classifier.0.project.1.bias', tensor([-7.2397e-02, -3.7419e-02, -6.8645e-02, -1.8623e-02, -5.1530e-02,\n",
            "        -4.7235e-02,  4.8399e-04, -1.3567e-01, -5.6476e-02, -7.1030e-02,\n",
            "         1.0554e-03, -2.4627e-02, -1.5360e-02,  6.7129e-03, -2.9780e-02,\n",
            "         1.2743e-02, -3.0343e-02, -1.2167e-01, -7.4223e-03, -1.2336e-01,\n",
            "        -5.3446e-02, -8.4628e-03, -1.9474e-03, -1.2658e-02, -5.5186e-03,\n",
            "        -7.0810e-02, -1.6107e-02,  7.8104e-03, -5.4234e-02, -3.7779e-02,\n",
            "        -9.3409e-02, -4.4860e-02,  8.4965e-03, -3.4795e-02, -3.7863e-02,\n",
            "        -5.0809e-02, -8.5689e-02, -2.2709e-02,  1.4750e-02, -4.4211e-02,\n",
            "        -6.0908e-02, -2.8305e-02, -7.4804e-02, -4.2246e-02, -5.8813e-04,\n",
            "        -5.5293e-02, -1.4396e-02, -4.4678e-02, -8.1088e-03, -1.0099e-01,\n",
            "        -1.0014e-02, -1.0991e-01, -1.4049e-02, -4.3486e-02, -4.1453e-02,\n",
            "        -8.6584e-02, -3.5260e-02, -3.8973e-02, -1.2347e-02, -4.4954e-02,\n",
            "        -2.3718e-02, -1.4397e-02,  1.4213e-02, -4.1490e-02, -4.4859e-02,\n",
            "        -5.7993e-02, -4.8249e-02, -5.3864e-02, -9.4099e-03, -7.4649e-02,\n",
            "        -2.9211e-02, -3.3433e-02, -2.4046e-02, -9.0168e-02, -9.1631e-02,\n",
            "        -3.3848e-02, -5.5928e-02, -3.5764e-02,  1.5300e-03, -6.6738e-03,\n",
            "        -1.0281e-02, -6.3909e-05, -1.9070e-02, -3.0470e-02, -4.5459e-03,\n",
            "        -2.5858e-02, -7.3519e-02,  1.0450e-02, -1.3303e-02, -1.0945e-01,\n",
            "        -1.6271e-02,  1.6184e-03, -1.4883e-01, -5.9005e-03, -2.1718e-02,\n",
            "         9.4609e-03, -1.2620e-01, -3.9514e-02, -4.4402e-02, -1.1648e-02,\n",
            "        -2.8901e-02, -5.5240e-02,  8.2924e-03,  1.4198e-03, -4.4374e-02,\n",
            "        -4.3917e-02, -4.0068e-02, -8.4612e-02, -1.3454e-02,  1.4385e-02,\n",
            "        -8.2596e-03,  1.1984e-02, -2.6396e-02, -5.1496e-02, -1.0419e-02,\n",
            "        -6.8513e-03, -2.0923e-02, -1.9992e-02, -5.4113e-02, -5.6305e-02,\n",
            "        -5.2457e-03, -6.0812e-02, -4.0300e-02, -5.5326e-02, -5.4291e-03,\n",
            "         9.3252e-03, -6.5047e-02, -5.7872e-02, -7.7926e-03,  2.6911e-02,\n",
            "        -1.5581e-02, -4.4512e-03, -5.1591e-02, -4.0218e-02,  2.4636e-02,\n",
            "        -1.4165e-02, -7.4185e-03,  2.3436e-03, -1.0412e-01, -3.5296e-02,\n",
            "        -4.2669e-03,  1.1231e-02, -2.9570e-02,  5.0031e-03, -4.0971e-02,\n",
            "        -2.8099e-02, -4.4474e-02, -1.1274e-02, -3.3307e-02, -7.5344e-02,\n",
            "        -5.4672e-02, -1.4670e-02, -6.4856e-02, -5.0564e-02, -3.5974e-02,\n",
            "        -2.0093e-02, -5.5150e-02, -4.1901e-02, -4.2897e-02, -2.8917e-02,\n",
            "        -8.5528e-03, -5.9904e-04, -3.9649e-02, -1.1706e-03,  9.2103e-03,\n",
            "        -7.6798e-03, -3.2757e-02, -8.6354e-02, -7.5729e-02, -9.1997e-03,\n",
            "        -1.1008e-01, -1.2025e-02, -2.0829e-02, -5.6213e-02, -3.4102e-02,\n",
            "        -1.4253e-01, -2.7943e-02, -3.2767e-02, -1.7603e-02, -3.7987e-02,\n",
            "         2.1758e-04, -1.0307e-01, -2.3860e-02, -5.0030e-02, -5.5427e-02,\n",
            "        -3.2196e-02, -4.1488e-02, -1.4329e-02, -5.5390e-02, -4.4177e-02,\n",
            "        -2.5113e-02, -8.5876e-02, -3.6461e-03, -6.3427e-02, -1.7608e-02,\n",
            "        -3.5056e-02, -1.1093e-01, -2.7865e-02, -4.2745e-02,  1.0311e-03,\n",
            "        -4.1554e-02, -4.2268e-02, -1.5006e-02, -4.7252e-02, -2.4732e-02,\n",
            "        -2.9717e-02, -2.1110e-02,  2.2596e-03, -7.0878e-02, -1.6274e-02,\n",
            "        -4.6954e-02, -3.2024e-02, -4.9911e-02,  1.3437e-03, -6.8373e-03,\n",
            "        -5.5487e-02, -3.5224e-02, -8.6539e-02, -6.6707e-02, -5.9349e-03,\n",
            "         1.0242e-02, -2.6479e-02, -7.6299e-03, -3.5145e-04,  5.5706e-03,\n",
            "        -2.7593e-02, -2.7522e-02, -4.1225e-02, -4.4890e-02, -2.6402e-02,\n",
            "        -1.4989e-02, -2.6065e-02, -9.9129e-02, -1.7786e-02, -6.3661e-02,\n",
            "        -7.5996e-02, -4.4738e-02,  6.1585e-03, -4.8699e-03, -2.3614e-02,\n",
            "        -4.4832e-02, -3.1213e-02, -6.3452e-03, -3.5969e-02, -1.6256e-02,\n",
            "        -5.1687e-02,  6.8035e-03, -2.1071e-02, -4.0769e-02, -8.8200e-02,\n",
            "        -8.4211e-03, -2.2825e-02, -3.6520e-02, -8.3595e-03, -5.6471e-02,\n",
            "         5.9225e-04], device='cuda:0')), ('classifier.0.project.1.running_mean', tensor([-6.0707e-01, -9.2437e-02,  1.7121e-01, -4.2346e-01, -6.0784e-02,\n",
            "         4.5934e-01, -9.3673e-01, -1.7699e-01, -1.2894e-01,  3.4006e-01,\n",
            "        -1.3906e+00, -8.2900e-01, -9.5191e-01, -4.5778e-01, -1.3745e+00,\n",
            "        -1.0921e+00, -8.3710e-02,  1.1536e-01, -1.1218e+00, -1.9210e-01,\n",
            "         3.3661e-01, -4.1442e-02, -7.3669e-01, -6.0049e-01,  1.3256e-01,\n",
            "        -2.5869e-01, -1.3692e-01, -3.2853e-01, -2.1600e-01, -9.3409e-01,\n",
            "        -9.7254e-01, -4.9210e-01, -1.3169e+00,  1.3503e-02, -5.8498e-01,\n",
            "         2.7558e-02, -1.2848e-01, -3.1931e-01, -6.1761e-01, -7.8115e-01,\n",
            "        -1.5865e+00, -4.9856e-01, -1.2912e-01, -1.1710e+00, -7.3220e-01,\n",
            "        -1.8649e-01, -7.6480e-01,  7.8162e-02, -1.1860e-01,  4.2042e-01,\n",
            "        -1.8009e-02,  2.9642e-01, -1.2719e+00,  5.4791e-01, -1.2323e-01,\n",
            "         4.3996e-01, -7.0575e-01, -4.0740e-01, -3.7902e-01, -7.5179e-01,\n",
            "        -8.4722e-01, -8.1839e-01, -9.2613e-01, -5.5918e-01, -8.5736e-02,\n",
            "         1.4587e-01, -9.5412e-01,  2.0285e-01, -8.0910e-01, -2.1471e-01,\n",
            "        -7.7416e-01, -5.3423e-03, -3.7450e-01, -5.6048e-02, -5.6340e-01,\n",
            "        -5.9646e-01,  3.7834e-02, -4.4598e-01, -8.9428e-01,  5.9648e-02,\n",
            "        -3.3153e-01, -1.5173e-01, -4.0568e-01,  4.0219e-02, -1.1330e+00,\n",
            "        -3.5276e-01, -4.7736e-02, -8.0848e-01, -1.0876e+00,  3.8652e-01,\n",
            "        -1.0691e+00, -5.4203e-01, -6.7082e-01, -6.5142e-01, -7.6966e-01,\n",
            "        -7.2593e-01,  2.0536e-01, -4.6108e-01, -9.3878e-02, -9.4718e-01,\n",
            "         8.8097e-03, -2.2205e-01, -2.0171e-01, -8.7240e-01, -3.9032e-01,\n",
            "        -2.8817e-01,  2.2689e-01,  3.4790e-01, -9.0979e-01, -1.1734e-01,\n",
            "        -6.9041e-01, -9.1473e-01, -4.9903e-01, -2.3991e-01, -4.2738e-01,\n",
            "         5.6650e-01, -6.3801e-01, -2.1633e-01, -5.2558e-01, -1.1140e+00,\n",
            "        -3.3652e-01, -5.1485e-01, -4.0795e-01, -2.6842e-01, -1.6724e-01,\n",
            "        -4.0631e-01,  2.1244e-01, -7.1711e-01, -3.9298e-01, -5.1280e-01,\n",
            "        -3.8620e-01, -9.7804e-01, -4.4825e-02, -1.8831e+00, -1.6826e-01,\n",
            "        -2.9330e-01, -4.6111e-01, -8.6831e-01,  2.4291e-01, -1.6708e-02,\n",
            "        -2.9474e-01, -8.4768e-01, -1.0610e-02, -3.1693e-01, -5.7415e-01,\n",
            "        -6.7814e-01, -7.1530e-01, -6.4867e-01, -3.3361e-01, -3.4530e-01,\n",
            "         4.0458e-01, -2.5286e-01, -1.0591e-02, -1.2405e+00, -1.5559e+00,\n",
            "        -1.9381e-01, -6.0006e-01,  1.8761e-01, -4.5974e-01,  1.7366e-03,\n",
            "        -4.5164e-01,  4.3982e-01, -1.0064e+00, -4.7231e-01, -1.2477e-01,\n",
            "        -7.7507e-01,  5.2498e-01, -2.0228e-01,  4.7454e-01, -4.8537e-02,\n",
            "         1.8696e-01, -1.0618e+00, -6.9104e-01,  3.2130e-01, -2.2394e-01,\n",
            "        -1.0588e-01,  1.0140e-01, -2.1568e-01, -7.5964e-01, -7.4907e-01,\n",
            "        -7.6290e-01, -1.2414e+00, -1.1403e+00,  6.2235e-01, -7.3220e-01,\n",
            "        -7.3884e-01, -1.3932e+00, -9.0249e-01,  5.1308e-01,  4.3092e-01,\n",
            "        -8.4655e-01, -6.1341e-01, -8.4328e-03, -3.1688e-02, -4.2870e-01,\n",
            "        -1.3479e+00,  2.5846e-01,  5.9681e-02,  4.2206e-01, -1.0367e+00,\n",
            "        -3.7717e-02, -1.3898e+00, -9.7711e-01, -8.7216e-01, -1.3414e+00,\n",
            "        -8.0135e-01, -2.3464e-01, -8.9854e-01,  2.8801e-02, -4.7208e-01,\n",
            "        -1.0130e+00, -5.8733e-01, -2.7412e-01, -1.5223e-01,  2.7237e-02,\n",
            "        -5.0594e-01, -5.9817e-01, -9.7887e-01,  1.4354e-01, -9.3085e-01,\n",
            "        -7.8755e-01, -8.3849e-02, -4.5194e-01, -1.2721e+00, -1.1562e-01,\n",
            "        -7.5181e-02, -8.0705e-01, -3.1133e-01,  1.0540e-01, -5.5315e-01,\n",
            "         5.7459e-02, -3.3808e-01, -4.6647e-01, -9.0075e-01, -7.4661e-01,\n",
            "        -1.3741e-01, -9.8019e-01, -7.3922e-01, -6.3123e-01, -2.7134e-01,\n",
            "        -4.8874e-01, -5.6202e-01, -4.4663e-01,  1.6899e-02, -5.0758e-01,\n",
            "         1.4071e-01, -8.9864e-01,  4.1903e-01, -3.6353e-01,  6.8608e-02,\n",
            "        -1.0764e+00, -5.9916e-01, -9.7338e-02, -6.4713e-01, -4.9758e-01,\n",
            "        -2.2492e-01], device='cuda:0')), ('classifier.0.project.1.running_var', tensor([1.2647, 0.4804, 0.5943, 0.4714, 0.4071, 0.4420, 0.8125, 1.1869, 0.4889,\n",
            "        0.3754, 0.5720, 0.1013, 0.4218, 0.8321, 0.9586, 1.4830, 0.4977, 0.2877,\n",
            "        0.5372, 0.4918, 0.4106, 0.3419, 0.7574, 0.3504, 0.3333, 0.5934, 0.4203,\n",
            "        0.3028, 0.6951, 1.1094, 0.6066, 0.2536, 0.4597, 0.4535, 0.2018, 0.4237,\n",
            "        0.2913, 0.6617, 0.6601, 0.8607, 0.6546, 1.1627, 0.7572, 0.8266, 0.8539,\n",
            "        0.3993, 0.6875, 0.5857, 0.3733, 0.3737, 0.3730, 0.2479, 0.6961, 0.3509,\n",
            "        0.5112, 0.2018, 0.9684, 0.3705, 0.2726, 1.1586, 0.6564, 0.1847, 0.5470,\n",
            "        0.1729, 0.5586, 0.3804, 0.3767, 0.3282, 0.5769, 0.2958, 0.8822, 0.3610,\n",
            "        0.6094, 0.6082, 0.6694, 0.9681, 0.7553, 0.2652, 0.5098, 0.4824, 0.3797,\n",
            "        0.4351, 0.5042, 0.2663, 0.5997, 0.4416, 0.7069, 0.9049, 0.5461, 0.2911,\n",
            "        0.3784, 0.9545, 0.6293, 0.4271, 1.0199, 0.6516, 0.6387, 0.7039, 0.2856,\n",
            "        0.1734, 0.2462, 0.5071, 0.6332, 0.4990, 0.4764, 0.3411, 0.4425, 0.2566,\n",
            "        0.8110, 0.4871, 0.3583, 0.6059, 0.5291, 0.7092, 0.8394, 0.3262, 0.5678,\n",
            "        0.3705, 0.7326, 0.5752, 0.6204, 0.7487, 1.2142, 0.4853, 0.5915, 0.5157,\n",
            "        0.4823, 0.8668, 0.8478, 0.8210, 0.6136, 0.8192, 0.7461, 0.7742, 0.4435,\n",
            "        0.4403, 0.2979, 1.2321, 0.4205, 0.9043, 0.4534, 0.8267, 0.2496, 0.8453,\n",
            "        0.6324, 1.2461, 0.2342, 0.9491, 0.4895, 0.6070, 0.2779, 0.5766, 0.6879,\n",
            "        0.9332, 0.7576, 0.4392, 0.7760, 0.5286, 0.5315, 0.6991, 0.4460, 0.3955,\n",
            "        0.9730, 1.0747, 0.5198, 0.5073, 0.4325, 0.6176, 0.2890, 0.3220, 0.4409,\n",
            "        0.8292, 0.4470, 0.3963, 0.7462, 0.5824, 0.4735, 0.4236, 0.2627, 0.3991,\n",
            "        0.7068, 0.5382, 0.8026, 0.1306, 0.2763, 0.4129, 0.8399, 0.1155, 0.2632,\n",
            "        0.4509, 0.9470, 0.5237, 0.5496, 0.4176, 1.1594, 0.8485, 0.4180, 0.6072,\n",
            "        0.3128, 0.7907, 0.4372, 0.7571, 0.3312, 0.8811, 0.4400, 1.0552, 0.2244,\n",
            "        0.6307, 0.6406, 0.6392, 0.7409, 0.7518, 0.8282, 0.4341, 0.3697, 0.2232,\n",
            "        0.6853, 0.6175, 0.3273, 0.8358, 0.1994, 0.9471, 0.7990, 0.7834, 0.4718,\n",
            "        0.6463, 0.9251, 0.2930, 0.5734, 0.8568, 0.4439, 0.6811, 0.3076, 0.5096,\n",
            "        1.1719, 0.5679, 1.0323, 0.6519, 0.4596, 0.5178, 0.8679, 1.0322, 0.8814,\n",
            "        0.5284, 0.3706, 0.3438, 0.7851, 0.4732, 1.0178, 0.6157, 0.9720, 0.5269,\n",
            "        0.6662, 0.2774, 0.6094, 0.3984], device='cuda:0')), ('classifier.0.project.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.1.weight', tensor([[[[-0.0085,  0.0015, -0.0048],\n",
            "          [-0.0022, -0.0053, -0.0111],\n",
            "          [-0.0009, -0.0064, -0.0067]],\n",
            "\n",
            "         [[-0.0044,  0.0054,  0.0015],\n",
            "          [-0.0010, -0.0075, -0.0150],\n",
            "          [-0.0005, -0.0099,  0.0021]],\n",
            "\n",
            "         [[-0.0182, -0.0077, -0.0121],\n",
            "          [-0.0087, -0.0017, -0.0055],\n",
            "          [ 0.0035, -0.0053, -0.0098]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0014, -0.0065, -0.0101],\n",
            "          [-0.0065,  0.0220, -0.0042],\n",
            "          [-0.0087, -0.0063, -0.0068]],\n",
            "\n",
            "         [[ 0.0018,  0.0019,  0.0055],\n",
            "          [ 0.0063,  0.0263, -0.0060],\n",
            "          [ 0.0152,  0.0161,  0.0183]],\n",
            "\n",
            "         [[-0.0186, -0.0202, -0.0345],\n",
            "          [-0.0123,  0.0073, -0.0137],\n",
            "          [-0.0259, -0.0253, -0.0210]]],\n",
            "\n",
            "\n",
            "        [[[-0.0034, -0.0093, -0.0028],\n",
            "          [-0.0013, -0.0007, -0.0065],\n",
            "          [-0.0015, -0.0090,  0.0055]],\n",
            "\n",
            "         [[ 0.0143, -0.0019,  0.0051],\n",
            "          [ 0.0051,  0.0236,  0.0013],\n",
            "          [ 0.0083,  0.0038,  0.0113]],\n",
            "\n",
            "         [[ 0.0031,  0.0006,  0.0041],\n",
            "          [-0.0046,  0.0376,  0.0062],\n",
            "          [ 0.0097,  0.0068,  0.0144]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0015,  0.0002, -0.0032],\n",
            "          [-0.0025, -0.0244, -0.0013],\n",
            "          [ 0.0019, -0.0013, -0.0006]],\n",
            "\n",
            "         [[ 0.0093,  0.0037,  0.0090],\n",
            "          [-0.0046, -0.0080,  0.0007],\n",
            "          [-0.0096, -0.0122,  0.0066]],\n",
            "\n",
            "         [[ 0.0143,  0.0048,  0.0109],\n",
            "          [ 0.0039, -0.0807,  0.0045],\n",
            "          [ 0.0210,  0.0134,  0.0179]]],\n",
            "\n",
            "\n",
            "        [[[-0.0059,  0.0024, -0.0019],\n",
            "          [-0.0023, -0.0041,  0.0059],\n",
            "          [-0.0014, -0.0145, -0.0115]],\n",
            "\n",
            "         [[ 0.0064,  0.0054, -0.0031],\n",
            "          [-0.0057, -0.0351, -0.0187],\n",
            "          [-0.0033, -0.0173, -0.0138]],\n",
            "\n",
            "         [[ 0.0186,  0.0209,  0.0155],\n",
            "          [ 0.0090, -0.0038, -0.0089],\n",
            "          [ 0.0055, -0.0044,  0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0084, -0.0075, -0.0069],\n",
            "          [-0.0194,  0.0057, -0.0102],\n",
            "          [-0.0025, -0.0114, -0.0133]],\n",
            "\n",
            "         [[ 0.0036,  0.0058,  0.0030],\n",
            "          [ 0.0027,  0.0072, -0.0025],\n",
            "          [ 0.0154,  0.0089,  0.0004]],\n",
            "\n",
            "         [[ 0.0054,  0.0010,  0.0111],\n",
            "          [ 0.0096,  0.0254, -0.0016],\n",
            "          [ 0.0046, -0.0071, -0.0037]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0157,  0.0151,  0.0228],\n",
            "          [ 0.0196,  0.0202,  0.0238],\n",
            "          [ 0.0126,  0.0157,  0.0171]],\n",
            "\n",
            "         [[-0.0071,  0.0016, -0.0029],\n",
            "          [ 0.0006, -0.0058,  0.0093],\n",
            "          [ 0.0113,  0.0183,  0.0151]],\n",
            "\n",
            "         [[ 0.0015, -0.0205,  0.0029],\n",
            "          [-0.0047, -0.0052, -0.0047],\n",
            "          [ 0.0081,  0.0065,  0.0082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0099, -0.0001,  0.0053],\n",
            "          [-0.0016,  0.0251, -0.0020],\n",
            "          [-0.0046, -0.0066,  0.0055]],\n",
            "\n",
            "         [[-0.0063, -0.0007, -0.0096],\n",
            "          [ 0.0213,  0.0240, -0.0014],\n",
            "          [ 0.0135,  0.0186,  0.0004]],\n",
            "\n",
            "         [[-0.0278, -0.0403, -0.0353],\n",
            "          [-0.0089, -0.0022, -0.0061],\n",
            "          [-0.0201, -0.0137, -0.0148]]],\n",
            "\n",
            "\n",
            "        [[[-0.0033, -0.0107, -0.0116],\n",
            "          [-0.0095,  0.0010, -0.0109],\n",
            "          [-0.0077, -0.0067, -0.0037]],\n",
            "\n",
            "         [[-0.0064, -0.0053, -0.0155],\n",
            "          [-0.0006,  0.0078, -0.0041],\n",
            "          [-0.0108, -0.0169, -0.0098]],\n",
            "\n",
            "         [[ 0.0116,  0.0064,  0.0028],\n",
            "          [ 0.0055,  0.0577,  0.0121],\n",
            "          [ 0.0146,  0.0143,  0.0072]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0034, -0.0005, -0.0057],\n",
            "          [ 0.0081,  0.0241,  0.0041],\n",
            "          [ 0.0080,  0.0046,  0.0013]],\n",
            "\n",
            "         [[ 0.0249,  0.0081,  0.0091],\n",
            "          [ 0.0025,  0.0094, -0.0021],\n",
            "          [-0.0006, -0.0026,  0.0067]],\n",
            "\n",
            "         [[ 0.0016, -0.0058, -0.0009],\n",
            "          [-0.0092, -0.0414,  0.0055],\n",
            "          [ 0.0096, -0.0022, -0.0037]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0139,  0.0118,  0.0126],\n",
            "          [ 0.0108,  0.0168,  0.0168],\n",
            "          [ 0.0047,  0.0036, -0.0016]],\n",
            "\n",
            "         [[-0.0064,  0.0029, -0.0136],\n",
            "          [-0.0041, -0.0745, -0.0120],\n",
            "          [-0.0164,  0.0010, -0.0172]],\n",
            "\n",
            "         [[ 0.0131,  0.0145,  0.0090],\n",
            "          [-0.0003, -0.0107,  0.0039],\n",
            "          [ 0.0061,  0.0198,  0.0055]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0071,  0.0098, -0.0079],\n",
            "          [ 0.0067,  0.0582, -0.0045],\n",
            "          [ 0.0186, -0.0088,  0.0119]],\n",
            "\n",
            "         [[-0.0215, -0.0162, -0.0255],\n",
            "          [-0.0180, -0.0038, -0.0082],\n",
            "          [-0.0077,  0.0002, -0.0114]],\n",
            "\n",
            "         [[ 0.0060,  0.0098,  0.0027],\n",
            "          [ 0.0060,  0.0362,  0.0031],\n",
            "          [ 0.0146, -0.0022, -0.0007]]]], device='cuda:0')), ('classifier.2.weight', tensor([0.7145, 0.5250, 0.6694, 0.5836, 0.5818, 0.6083, 0.5813, 0.6361, 0.5961,\n",
            "        0.5960, 0.6884, 0.7151, 0.5717, 0.5472, 0.5340, 0.6161, 0.6680, 0.6205,\n",
            "        0.6249, 0.5665, 0.6037, 0.5805, 0.5098, 0.6889, 0.7092, 0.5804, 0.8542,\n",
            "        0.5807, 0.4974, 0.5484, 0.8767, 0.6034, 0.7487, 0.6108, 0.6553, 0.6040,\n",
            "        0.5750, 0.5911, 0.5872, 0.6843, 0.5077, 0.6055, 0.7673, 0.6861, 0.6881,\n",
            "        0.5810, 0.6287, 0.5318, 0.6717, 0.4738, 0.6652, 0.5517, 0.5952, 0.4938,\n",
            "        0.5317, 0.5361, 0.6796, 0.6625, 0.6538, 0.5454, 0.5619, 0.5977, 0.8257,\n",
            "        0.6020, 0.7596, 0.5718, 0.6769, 0.6608, 0.6955, 0.5541, 0.6129, 0.7517,\n",
            "        0.6084, 0.6558, 0.6033, 0.8139, 0.7749, 0.4820, 0.6774, 0.7325, 0.4793,\n",
            "        0.5782, 0.7712, 0.5948, 0.5740, 0.5660, 0.7416, 0.6487, 0.6489, 0.6886,\n",
            "        0.5488, 0.6215, 0.5835, 0.5130, 0.5489, 0.5198, 0.7938, 0.5899, 0.6465,\n",
            "        0.7424, 0.6530, 0.5091, 0.6706, 0.6026, 0.5984, 0.5415, 0.6821, 0.6519,\n",
            "        0.6179, 0.7275, 0.6568, 0.6066, 0.5461, 0.7019, 0.5355, 0.7628, 0.8306,\n",
            "        0.5408, 0.8319, 0.6392, 0.6449, 0.7249, 0.5682, 0.6137, 0.6444, 0.6293,\n",
            "        0.7860, 0.5035, 0.6394, 0.5937, 0.5376, 0.5963, 0.6469, 0.6218, 0.7652,\n",
            "        0.5996, 0.6173, 0.5965, 0.4761, 0.7443, 0.6428, 0.6400, 0.6028, 0.6028,\n",
            "        0.6823, 0.6487, 0.5683, 0.6363, 0.5892, 0.5213, 0.7344, 0.5025, 0.6739,\n",
            "        0.8711, 0.4821, 0.5992, 0.5613, 0.6071, 0.5466, 0.7029, 0.5722, 0.5692,\n",
            "        0.5838, 0.7123, 0.5966, 0.7556, 0.6605, 0.5962, 0.4932, 0.4809, 0.7579,\n",
            "        0.6982, 0.5298, 0.7835, 0.5884, 0.7146, 0.4973, 0.5909, 0.7496, 0.7168,\n",
            "        0.7232, 0.8166, 0.7181, 0.6330, 0.6469, 0.7517, 0.6141, 0.6564, 0.5513,\n",
            "        0.6515, 0.8066, 0.5346, 0.5819, 0.7372, 0.5849, 0.5793, 0.6037, 0.5990,\n",
            "        0.7496, 0.5717, 0.5758, 0.5322, 0.4858, 0.5315, 0.6944, 0.8157, 0.7801,\n",
            "        0.6837, 0.6757, 0.6729, 0.6074, 0.5298, 0.5921, 0.6654, 0.7827, 0.5943,\n",
            "        0.5955, 0.6521, 0.6959, 0.6745, 0.5950, 0.7364, 0.6982, 0.6222, 0.6813,\n",
            "        0.7080, 0.6470, 0.5739, 0.6222, 0.5459, 0.7332, 0.6695, 0.6238, 0.6810,\n",
            "        0.5453, 0.6250, 0.7516, 0.7281, 0.6951, 0.5710, 0.7698, 0.8129, 0.5576,\n",
            "        0.5473, 0.5658, 0.7339, 0.5385, 0.6165, 0.5856, 0.7641, 0.5390, 0.5727,\n",
            "        0.5893, 0.6854, 0.5885, 0.5793], device='cuda:0')), ('classifier.2.bias', tensor([ 0.1617,  0.1499,  0.2240,  0.1328,  0.1885,  0.1878,  0.2413,  0.1700,\n",
            "         0.2105,  0.1075,  0.1629,  0.2441,  0.1653,  0.1195,  0.1746,  0.1538,\n",
            "         0.1395,  0.1723,  0.1737,  0.0906,  0.1561,  0.0990,  0.1467,  0.1979,\n",
            "         0.1111,  0.1982,  0.1913,  0.1918,  0.1193,  0.2288,  0.1809,  0.1884,\n",
            "         0.1698,  0.2071,  0.2334,  0.2548,  0.2243,  0.2219,  0.1600,  0.2085,\n",
            "         0.1551,  0.2692,  0.2100,  0.2273,  0.1559,  0.2779,  0.1889,  0.1298,\n",
            "         0.1309,  0.1017,  0.1629,  0.2328,  0.1449,  0.1600,  0.1319,  0.1109,\n",
            "         0.2276,  0.2177,  0.1483,  0.0949,  0.0964,  0.0705,  0.2258,  0.1468,\n",
            "         0.1706,  0.1546,  0.1234,  0.2614,  0.1792,  0.1673,  0.0867,  0.1928,\n",
            "         0.1566, -0.0038,  0.1760,  0.2108,  0.1304,  0.1314,  0.0656,  0.1196,\n",
            "         0.0840,  0.1671,  0.1962,  0.1273,  0.1578,  0.1366,  0.1767,  0.2108,\n",
            "         0.1784,  0.1854,  0.1536,  0.2266,  0.1440,  0.1175,  0.1840,  0.2528,\n",
            "         0.1682,  0.2123,  0.1694,  0.1868,  0.2136,  0.1699,  0.1831,  0.2526,\n",
            "         0.1904,  0.1655,  0.2213,  0.1518,  0.1256,  0.1537,  0.1850,  0.1214,\n",
            "         0.0884,  0.1662,  0.1576,  0.2085,  0.1364,  0.1008,  0.1830,  0.1861,\n",
            "         0.1712,  0.2474,  0.1146,  0.1296,  0.1506,  0.2308,  0.2409,  0.1235,\n",
            "         0.1326,  0.2634,  0.1205,  0.1708,  0.1535,  0.2021,  0.2186,  0.1212,\n",
            "         0.1636,  0.1234,  0.0915,  0.1644,  0.1587,  0.1395,  0.1132,  0.2126,\n",
            "         0.1960,  0.2085,  0.1338,  0.2116,  0.1427,  0.1077,  0.1901,  0.0812,\n",
            "         0.2528,  0.1808,  0.0360,  0.1382,  0.1659,  0.2519,  0.1495,  0.2185,\n",
            "         0.2101,  0.2093,  0.2442,  0.1482,  0.0671,  0.2061,  0.1770,  0.1719,\n",
            "         0.0812,  0.1146,  0.2031,  0.2048,  0.1571,  0.1539,  0.1305,  0.1938,\n",
            "         0.0938,  0.2791,  0.1853,  0.1567,  0.1836,  0.2047,  0.1576,  0.1489,\n",
            "         0.2002,  0.2294,  0.1735,  0.1577,  0.1175,  0.1323,  0.1771,  0.1282,\n",
            "         0.1984,  0.1845,  0.1217,  0.0970,  0.2131,  0.1978,  0.2158,  0.2101,\n",
            "         0.1497,  0.1875,  0.1919,  0.1147,  0.1887,  0.1711,  0.2232,  0.1691,\n",
            "         0.2030,  0.1703,  0.1867,  0.1380,  0.1248,  0.1709,  0.1830,  0.2227,\n",
            "         0.2743,  0.1955,  0.2006,  0.0993,  0.1151,  0.2677,  0.2041,  0.0869,\n",
            "         0.1319,  0.1969,  0.1912,  0.1282,  0.1412,  0.2002,  0.1354,  0.1915,\n",
            "         0.1434,  0.1830,  0.1107,  0.1632,  0.1942,  0.1985,  0.1213,  0.1583,\n",
            "         0.1940,  0.2497,  0.2094,  0.2557,  0.1994,  0.2080,  0.1130,  0.1523,\n",
            "         0.1509,  0.1877,  0.1437,  0.1731,  0.1704,  0.1648,  0.0328,  0.1999],\n",
            "       device='cuda:0')), ('classifier.2.running_mean', tensor([-7.4513e-01, -1.9290e-01, -2.4330e-01, -4.4170e-01, -2.6994e-01,\n",
            "        -3.0169e-01,  3.1736e-01, -2.1913e+00, -1.0786e-01, -1.1089e-01,\n",
            "        -2.6172e-01, -6.4973e-02,  1.0222e-01, -8.9301e-02,  2.8290e-02,\n",
            "        -1.9980e-01, -3.9312e-01, -7.4526e-01, -3.2438e-01, -2.1820e-01,\n",
            "        -7.3991e-01, -2.2579e-01,  2.2982e-02,  5.5040e-02,  2.8952e-01,\n",
            "        -8.3903e-02, -5.7298e-01,  3.4261e-02, -2.5823e-01, -9.3821e-03,\n",
            "        -2.2594e-01, -4.8594e-01, -9.8580e-01, -6.4248e-01, -6.3471e-01,\n",
            "         5.3180e-01,  1.1925e-01, -1.7226e-01, -4.1365e-01, -2.4039e-01,\n",
            "        -8.1804e-02, -2.0978e-01, -3.2987e-01, -4.7076e-01,  2.6819e-01,\n",
            "         3.7431e-01,  9.1494e-01, -2.0369e-01,  4.0411e-01, -7.1350e-01,\n",
            "         5.9591e-01,  1.6651e-01, -5.7387e-01, -4.6602e-01,  3.1316e-01,\n",
            "        -3.4124e-01, -5.7651e-01, -5.2579e-01,  1.8850e-01, -5.1273e-01,\n",
            "        -1.5556e-01, -4.0040e-01,  3.7965e-01, -1.7762e-01, -2.0231e-01,\n",
            "        -9.7396e-02,  8.3312e-01, -2.0570e-01, -2.6078e-01,  3.6902e-02,\n",
            "        -1.7271e-01, -6.6873e-02, -3.1681e-01, -7.7045e-01,  4.9864e-01,\n",
            "        -6.5146e-01, -7.2658e-01, -7.5139e-01, -3.4211e-01, -3.6039e-01,\n",
            "         2.7843e-01,  1.3078e-01, -3.6270e-01,  6.3585e-01, -4.8408e-01,\n",
            "         7.7210e-01, -3.3527e-01, -4.1743e-01,  4.0794e-01,  4.1338e-01,\n",
            "         1.6314e-01,  4.8348e-01, -1.2883e+00, -1.2295e-01,  5.1793e-01,\n",
            "         1.7596e-01, -8.7191e-01, -6.5184e-02, -7.8831e-01, -3.9023e-01,\n",
            "         2.4513e-01,  1.3039e-02, -6.2261e-01, -1.9639e-01,  1.7387e-01,\n",
            "        -1.3226e-01,  2.3201e-01, -2.2881e-01, -2.2092e-01,  3.9482e-01,\n",
            "         5.2362e-01,  3.7446e-01,  2.6005e-02, -4.0064e-01, -3.2829e-01,\n",
            "        -3.2447e-01, -7.9758e-01, -3.3954e-01, -3.3360e-01,  1.8804e-01,\n",
            "         9.5318e-01, -4.4670e-02, -1.2399e-01,  5.5746e-01, -1.8646e-01,\n",
            "        -2.5406e-01,  9.1169e-02, -2.1048e-01, -9.2305e-01,  5.2706e-02,\n",
            "        -3.0761e-01, -7.1861e-01, -9.0661e-02,  1.7229e-01, -6.1399e-01,\n",
            "         3.7266e-01,  1.9956e-01, -5.6863e-01, -1.8145e-01, -6.6500e-02,\n",
            "        -5.5234e-01, -6.3562e-01, -4.8945e-01, -3.8192e-01, -5.5272e-01,\n",
            "         2.5734e-01, -1.0282e-01, -3.6970e-01,  7.4657e-02, -3.8428e-01,\n",
            "        -2.5026e-01,  3.5688e-02, -6.0227e-01, -4.3853e-01, -2.9747e-01,\n",
            "        -1.0329e-01, -1.6420e-01,  4.9835e-02, -7.1044e-01, -5.6883e-01,\n",
            "         7.7874e-02, -1.4696e-01,  6.5979e-01,  1.3478e-01,  7.5789e-01,\n",
            "        -1.0375e-02, -6.8445e-01,  6.6315e-01, -3.1650e-01, -1.4436e-01,\n",
            "        -7.4558e-01, -4.5302e-01, -4.0832e-01,  2.1575e-01, -4.3424e-01,\n",
            "         1.2552e-01, -6.2824e-01, -2.6482e-03,  2.0818e-01, -7.4145e-01,\n",
            "        -8.2257e-01, -4.4623e-01, -7.8474e-01, -8.8849e-01,  1.7660e-01,\n",
            "        -2.7624e-01, -3.4671e-01, -7.7311e-02, -2.1164e-01,  7.0539e-01,\n",
            "        -1.5656e-01,  3.4187e-02,  9.7807e-02, -9.2212e-01, -1.8509e-01,\n",
            "        -2.7500e-01,  1.6266e-01, -1.6157e-01, -3.0364e-01, -3.7212e-01,\n",
            "        -3.1563e-01,  2.8612e-01,  1.0041e-03, -8.8106e-02, -5.4687e-01,\n",
            "        -5.7041e-01,  1.5746e-01, -6.7975e-01, -5.9517e-01, -9.9496e-01,\n",
            "        -4.0165e-01, -4.1065e-02, -2.6793e-01, -2.3097e-01, -6.7044e-01,\n",
            "        -3.6129e-02,  5.0050e-01, -4.1626e-02, -2.0924e-01, -1.1272e-01,\n",
            "        -5.2691e-01, -8.5064e-02, -5.4370e-01, -5.1293e-01, -2.1005e-01,\n",
            "        -4.6161e-01,  1.7825e-02, -3.3428e-01, -1.8311e-01,  4.1570e-01,\n",
            "        -2.4838e-01,  1.0631e-01,  7.1985e-02,  2.0056e-01, -2.6954e-01,\n",
            "        -1.1772e+00,  2.3842e-01, -3.2214e-01, -1.5089e-02, -2.6986e-01,\n",
            "        -1.4740e-01, -2.2783e-01,  2.9220e-01, -4.3386e-02,  2.0386e-01,\n",
            "        -2.1985e-01, -8.1532e-02,  2.6506e-01, -1.1619e-01, -5.8480e-01,\n",
            "        -4.8604e-01,  1.2358e+00,  3.6562e-01, -5.7262e-02, -4.7982e-01,\n",
            "         1.0109e-02], device='cuda:0')), ('classifier.2.running_var', tensor([2.4620, 1.8665, 2.5229, 2.1456, 2.6459, 2.4389, 2.4579, 2.9138, 0.5277,\n",
            "        2.4602, 1.5217, 1.6284, 1.8782, 1.9811, 1.3745, 2.4359, 2.1347, 2.1271,\n",
            "        2.4301, 1.3598, 1.2467, 1.6898, 1.2822, 1.6101, 2.0156, 2.3334, 3.6074,\n",
            "        1.6148, 0.6676, 1.9262, 2.2920, 2.5386, 2.6331, 2.5887, 2.1904, 1.1752,\n",
            "        1.7374, 0.9907, 2.2812, 0.9485, 2.1446, 1.9940, 2.9642, 2.1212, 1.2870,\n",
            "        0.6299, 2.3453, 1.5999, 0.6022, 1.5295, 1.2983, 1.6729, 2.5680, 0.8066,\n",
            "        0.9768, 1.4691, 2.2545, 2.3847, 1.7175, 0.6901, 1.6595, 1.0323, 1.4147,\n",
            "        1.4762, 3.0099, 1.9016, 1.2856, 2.2547, 3.7865, 2.1474, 1.6124, 2.1558,\n",
            "        1.3666, 1.8714, 1.7328, 3.2021, 1.8775, 1.0021, 2.6917, 2.7770, 0.5200,\n",
            "        1.3622, 2.0504, 0.9456, 1.6252, 1.8556, 1.3490, 1.8811, 2.5779, 1.6469,\n",
            "        1.2348, 1.7098, 1.6591, 1.8574, 2.2280, 1.6551, 2.1802, 1.7441, 1.8042,\n",
            "        3.2318, 1.9233, 0.8530, 2.9665, 1.9874, 1.8436, 1.6136, 1.8255, 1.7352,\n",
            "        1.4309, 1.9301, 0.8672, 0.7242, 1.9638, 1.9371, 1.2872, 2.1964, 2.2286,\n",
            "        2.1167, 2.8288, 2.2611, 0.7176, 1.1447, 1.9611, 0.5453, 1.6044, 2.8403,\n",
            "        1.4254, 1.9093, 2.6561, 1.9623, 1.9207, 1.8965, 1.3687, 2.0597, 3.3768,\n",
            "        0.9620, 1.5488, 1.9591, 1.4295, 1.7611, 2.2755, 2.7854, 2.1044, 2.1564,\n",
            "        2.6840, 2.8807, 2.1536, 1.1696, 1.4256, 1.5262, 2.3440, 1.5932, 1.9081,\n",
            "        2.8132, 1.2516, 1.8279, 2.9096, 2.2139, 1.3849, 3.2740, 2.4288, 2.1732,\n",
            "        1.1639, 2.4495, 0.5998, 1.3240, 1.4027, 1.2685, 1.5941, 1.9431, 2.7850,\n",
            "        2.9903, 1.5472, 2.1185, 0.8912, 1.3822, 1.2599, 2.1605, 0.9547, 1.7919,\n",
            "        2.3591, 3.0421, 3.2689, 2.5362, 1.3233, 1.2453, 2.2085, 2.2652, 1.6529,\n",
            "        1.3856, 1.6772, 2.0429, 2.7204, 2.1818, 1.5492, 1.4502, 3.5159, 2.3116,\n",
            "        2.9681, 2.0296, 1.5317, 2.3990, 1.6621, 1.7473, 2.4900, 1.9268, 1.5167,\n",
            "        2.5891, 2.5150, 3.0616, 2.6673, 1.4208, 1.4842, 1.8744, 3.4455, 2.5356,\n",
            "        1.6702, 1.8741, 1.9127, 3.8267, 1.5881, 1.1868, 0.7426, 2.3940, 1.4854,\n",
            "        2.3173, 1.9023, 1.9209, 1.3542, 1.3877, 1.4716, 1.4465, 1.4237, 1.7493,\n",
            "        1.3554, 1.5428, 1.3195, 1.7407, 2.4626, 1.7925, 1.6976, 1.1025, 2.0308,\n",
            "        2.0827, 2.0115, 1.9457, 1.4590, 1.9781, 1.0404, 1.7945, 2.0026, 0.8709,\n",
            "        1.6726, 1.3426, 1.3833, 2.0485], device='cuda:0')), ('classifier.2.num_batches_tracked', tensor(99698, device='cuda:0')), ('classifier.4.weight', tensor([[[[ 0.1213]],\n",
            "\n",
            "         [[-0.0683]],\n",
            "\n",
            "         [[ 0.0891]],\n",
            "\n",
            "         [[-0.0378]],\n",
            "\n",
            "         [[ 0.1186]],\n",
            "\n",
            "         [[ 0.0379]],\n",
            "\n",
            "         [[ 0.0587]],\n",
            "\n",
            "         [[ 0.0608]],\n",
            "\n",
            "         [[ 0.0816]],\n",
            "\n",
            "         [[ 0.0361]],\n",
            "\n",
            "         [[ 0.1489]],\n",
            "\n",
            "         [[ 0.1669]],\n",
            "\n",
            "         [[ 0.1071]],\n",
            "\n",
            "         [[-0.0531]],\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[ 0.0463]],\n",
            "\n",
            "         [[ 0.0855]],\n",
            "\n",
            "         [[ 0.1377]],\n",
            "\n",
            "         [[-0.0535]],\n",
            "\n",
            "         [[ 0.1241]],\n",
            "\n",
            "         [[-0.0861]],\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         [[ 0.1063]],\n",
            "\n",
            "         [[ 0.1241]],\n",
            "\n",
            "         [[ 0.1095]],\n",
            "\n",
            "         [[ 0.1361]],\n",
            "\n",
            "         [[ 0.0232]],\n",
            "\n",
            "         [[-0.0694]],\n",
            "\n",
            "         [[ 0.0717]],\n",
            "\n",
            "         [[ 0.1485]],\n",
            "\n",
            "         [[ 0.1098]],\n",
            "\n",
            "         [[ 0.0322]],\n",
            "\n",
            "         [[ 0.0923]],\n",
            "\n",
            "         [[ 0.1243]],\n",
            "\n",
            "         [[ 0.0308]],\n",
            "\n",
            "         [[ 0.0380]],\n",
            "\n",
            "         [[ 0.1262]],\n",
            "\n",
            "         [[ 0.0495]],\n",
            "\n",
            "         [[ 0.1045]],\n",
            "\n",
            "         [[-0.0280]],\n",
            "\n",
            "         [[ 0.0659]],\n",
            "\n",
            "         [[ 0.1836]],\n",
            "\n",
            "         [[ 0.1224]],\n",
            "\n",
            "         [[ 0.0686]],\n",
            "\n",
            "         [[ 0.1079]],\n",
            "\n",
            "         [[ 0.0776]],\n",
            "\n",
            "         [[-0.0321]],\n",
            "\n",
            "         [[ 0.1049]],\n",
            "\n",
            "         [[-0.0103]],\n",
            "\n",
            "         [[ 0.1570]],\n",
            "\n",
            "         [[ 0.0699]],\n",
            "\n",
            "         [[ 0.1149]],\n",
            "\n",
            "         [[-0.0746]],\n",
            "\n",
            "         [[ 0.1114]],\n",
            "\n",
            "         [[-0.0586]],\n",
            "\n",
            "         [[ 0.0893]],\n",
            "\n",
            "         [[ 0.1121]],\n",
            "\n",
            "         [[ 0.1696]],\n",
            "\n",
            "         [[-0.0546]],\n",
            "\n",
            "         [[-0.0307]],\n",
            "\n",
            "         [[-0.0777]],\n",
            "\n",
            "         [[ 0.2252]],\n",
            "\n",
            "         [[ 0.1130]],\n",
            "\n",
            "         [[ 0.0791]],\n",
            "\n",
            "         [[ 0.0510]],\n",
            "\n",
            "         [[ 0.1147]],\n",
            "\n",
            "         [[ 0.0888]],\n",
            "\n",
            "         [[ 0.1471]],\n",
            "\n",
            "         [[ 0.0400]],\n",
            "\n",
            "         [[-0.0613]],\n",
            "\n",
            "         [[ 0.0867]],\n",
            "\n",
            "         [[ 0.0554]],\n",
            "\n",
            "         [[-0.0780]],\n",
            "\n",
            "         [[ 0.0777]],\n",
            "\n",
            "         [[ 0.0968]],\n",
            "\n",
            "         [[ 0.2174]],\n",
            "\n",
            "         [[-0.0339]],\n",
            "\n",
            "         [[-0.0742]],\n",
            "\n",
            "         [[ 0.0964]],\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[ 0.0808]],\n",
            "\n",
            "         [[ 0.1405]],\n",
            "\n",
            "         [[ 0.0527]],\n",
            "\n",
            "         [[ 0.0896]],\n",
            "\n",
            "         [[ 0.0941]],\n",
            "\n",
            "         [[ 0.1580]],\n",
            "\n",
            "         [[ 0.0561]],\n",
            "\n",
            "         [[ 0.0667]],\n",
            "\n",
            "         [[ 0.0621]],\n",
            "\n",
            "         [[ 0.0526]],\n",
            "\n",
            "         [[ 0.1014]],\n",
            "\n",
            "         [[ 0.0187]],\n",
            "\n",
            "         [[-0.0695]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         [[ 0.0847]],\n",
            "\n",
            "         [[ 0.1376]],\n",
            "\n",
            "         [[ 0.0721]],\n",
            "\n",
            "         [[ 0.1068]],\n",
            "\n",
            "         [[ 0.1376]],\n",
            "\n",
            "         [[ 0.0791]],\n",
            "\n",
            "         [[-0.0450]],\n",
            "\n",
            "         [[ 0.0371]],\n",
            "\n",
            "         [[ 0.1358]],\n",
            "\n",
            "         [[ 0.0941]],\n",
            "\n",
            "         [[-0.0664]],\n",
            "\n",
            "         [[ 0.0315]],\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         [[ 0.0353]],\n",
            "\n",
            "         [[ 0.1549]],\n",
            "\n",
            "         [[ 0.0489]],\n",
            "\n",
            "         [[ 0.0262]],\n",
            "\n",
            "         [[-0.0562]],\n",
            "\n",
            "         [[ 0.1817]],\n",
            "\n",
            "         [[-0.0666]],\n",
            "\n",
            "         [[ 0.2068]],\n",
            "\n",
            "         [[ 0.1800]],\n",
            "\n",
            "         [[-0.0011]],\n",
            "\n",
            "         [[ 0.1968]],\n",
            "\n",
            "         [[ 0.1307]],\n",
            "\n",
            "         [[ 0.0820]],\n",
            "\n",
            "         [[ 0.2092]],\n",
            "\n",
            "         [[-0.0701]],\n",
            "\n",
            "         [[ 0.0845]],\n",
            "\n",
            "         [[ 0.1500]],\n",
            "\n",
            "         [[ 0.0367]],\n",
            "\n",
            "         [[ 0.1610]],\n",
            "\n",
            "         [[-0.0346]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         [[ 0.0658]],\n",
            "\n",
            "         [[-0.0432]],\n",
            "\n",
            "         [[-0.0577]],\n",
            "\n",
            "         [[ 0.0505]],\n",
            "\n",
            "         [[ 0.0330]],\n",
            "\n",
            "         [[ 0.1524]],\n",
            "\n",
            "         [[ 0.1140]],\n",
            "\n",
            "         [[ 0.1031]],\n",
            "\n",
            "         [[ 0.1179]],\n",
            "\n",
            "         [[-0.0832]],\n",
            "\n",
            "         [[ 0.1425]],\n",
            "\n",
            "         [[ 0.1404]],\n",
            "\n",
            "         [[ 0.0408]],\n",
            "\n",
            "         [[-0.0069]],\n",
            "\n",
            "         [[ 0.1362]],\n",
            "\n",
            "         [[ 0.0719]],\n",
            "\n",
            "         [[ 0.1033]],\n",
            "\n",
            "         [[ 0.0918]],\n",
            "\n",
            "         [[ 0.0553]],\n",
            "\n",
            "         [[ 0.1138]],\n",
            "\n",
            "         [[-0.0662]],\n",
            "\n",
            "         [[ 0.0899]],\n",
            "\n",
            "         [[-0.0724]],\n",
            "\n",
            "         [[ 0.0890]],\n",
            "\n",
            "         [[ 0.1857]],\n",
            "\n",
            "         [[-0.0859]],\n",
            "\n",
            "         [[-0.0471]],\n",
            "\n",
            "         [[ 0.1129]],\n",
            "\n",
            "         [[ 0.1109]],\n",
            "\n",
            "         [[-0.0253]],\n",
            "\n",
            "         [[ 0.0557]],\n",
            "\n",
            "         [[ 0.0057]],\n",
            "\n",
            "         [[ 0.0763]],\n",
            "\n",
            "         [[ 0.0419]],\n",
            "\n",
            "         [[ 0.1410]],\n",
            "\n",
            "         [[ 0.0630]],\n",
            "\n",
            "         [[ 0.1209]],\n",
            "\n",
            "         [[ 0.1469]],\n",
            "\n",
            "         [[ 0.0504]],\n",
            "\n",
            "         [[-0.0441]],\n",
            "\n",
            "         [[-0.0323]],\n",
            "\n",
            "         [[ 0.0953]],\n",
            "\n",
            "         [[ 0.1342]],\n",
            "\n",
            "         [[-0.0735]],\n",
            "\n",
            "         [[ 0.0919]],\n",
            "\n",
            "         [[-0.0049]],\n",
            "\n",
            "         [[ 0.1212]],\n",
            "\n",
            "         [[-0.0671]],\n",
            "\n",
            "         [[ 0.0827]],\n",
            "\n",
            "         [[ 0.1013]],\n",
            "\n",
            "         [[ 0.1682]],\n",
            "\n",
            "         [[ 0.0903]],\n",
            "\n",
            "         [[ 0.1087]],\n",
            "\n",
            "         [[ 0.1266]],\n",
            "\n",
            "         [[ 0.0832]],\n",
            "\n",
            "         [[ 0.0989]],\n",
            "\n",
            "         [[ 0.1497]],\n",
            "\n",
            "         [[ 0.1148]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         [[-0.0764]],\n",
            "\n",
            "         [[ 0.0867]],\n",
            "\n",
            "         [[ 0.1563]],\n",
            "\n",
            "         [[-0.0257]],\n",
            "\n",
            "         [[ 0.0938]],\n",
            "\n",
            "         [[ 0.1153]],\n",
            "\n",
            "         [[-0.0605]],\n",
            "\n",
            "         [[-0.0155]],\n",
            "\n",
            "         [[ 0.0930]],\n",
            "\n",
            "         [[ 0.0702]],\n",
            "\n",
            "         [[ 0.1822]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         [[ 0.1008]],\n",
            "\n",
            "         [[-0.0508]],\n",
            "\n",
            "         [[-0.0388]],\n",
            "\n",
            "         [[-0.0406]],\n",
            "\n",
            "         [[ 0.1452]],\n",
            "\n",
            "         [[ 0.1935]],\n",
            "\n",
            "         [[ 0.1344]],\n",
            "\n",
            "         [[ 0.1301]],\n",
            "\n",
            "         [[ 0.0627]],\n",
            "\n",
            "         [[ 0.0771]],\n",
            "\n",
            "         [[ 0.0970]],\n",
            "\n",
            "         [[-0.0703]],\n",
            "\n",
            "         [[-0.0610]],\n",
            "\n",
            "         [[ 0.1362]],\n",
            "\n",
            "         [[ 0.1751]],\n",
            "\n",
            "         [[ 0.0263]],\n",
            "\n",
            "         [[ 0.0200]],\n",
            "\n",
            "         [[ 0.1443]],\n",
            "\n",
            "         [[ 0.1174]],\n",
            "\n",
            "         [[ 0.0372]],\n",
            "\n",
            "         [[-0.0432]],\n",
            "\n",
            "         [[ 0.2006]],\n",
            "\n",
            "         [[ 0.1351]],\n",
            "\n",
            "         [[-0.0636]],\n",
            "\n",
            "         [[ 0.1037]],\n",
            "\n",
            "         [[ 0.1072]],\n",
            "\n",
            "         [[ 0.1127]],\n",
            "\n",
            "         [[-0.0788]],\n",
            "\n",
            "         [[-0.0694]],\n",
            "\n",
            "         [[ 0.0948]],\n",
            "\n",
            "         [[ 0.1513]],\n",
            "\n",
            "         [[ 0.1238]],\n",
            "\n",
            "         [[ 0.1294]],\n",
            "\n",
            "         [[ 0.0518]],\n",
            "\n",
            "         [[-0.0596]],\n",
            "\n",
            "         [[ 0.0697]],\n",
            "\n",
            "         [[ 0.1701]],\n",
            "\n",
            "         [[ 0.1263]],\n",
            "\n",
            "         [[ 0.1330]],\n",
            "\n",
            "         [[ 0.1218]],\n",
            "\n",
            "         [[ 0.1947]],\n",
            "\n",
            "         [[ 0.1890]],\n",
            "\n",
            "         [[ 0.0830]],\n",
            "\n",
            "         [[ 0.0773]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         [[ 0.0758]],\n",
            "\n",
            "         [[-0.0752]],\n",
            "\n",
            "         [[ 0.0638]],\n",
            "\n",
            "         [[ 0.0809]],\n",
            "\n",
            "         [[ 0.1790]],\n",
            "\n",
            "         [[-0.0737]],\n",
            "\n",
            "         [[ 0.0349]],\n",
            "\n",
            "         [[ 0.1166]],\n",
            "\n",
            "         [[ 0.1072]],\n",
            "\n",
            "         [[-0.0858]],\n",
            "\n",
            "         [[ 0.1047]]],\n",
            "\n",
            "\n",
            "        [[[-0.0908]],\n",
            "\n",
            "         [[-0.0145]],\n",
            "\n",
            "         [[-0.0286]],\n",
            "\n",
            "         [[ 0.0738]],\n",
            "\n",
            "         [[-0.0754]],\n",
            "\n",
            "         [[-0.0805]],\n",
            "\n",
            "         [[-0.1050]],\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         [[-0.0961]],\n",
            "\n",
            "         [[-0.0752]],\n",
            "\n",
            "         [[-0.0590]],\n",
            "\n",
            "         [[-0.1470]],\n",
            "\n",
            "         [[-0.1121]],\n",
            "\n",
            "         [[ 0.0349]],\n",
            "\n",
            "         [[ 0.0521]],\n",
            "\n",
            "         [[-0.0687]],\n",
            "\n",
            "         [[-0.0689]],\n",
            "\n",
            "         [[-0.0234]],\n",
            "\n",
            "         [[-0.0530]],\n",
            "\n",
            "         [[ 0.0273]],\n",
            "\n",
            "         [[-0.0704]],\n",
            "\n",
            "         [[ 0.0786]],\n",
            "\n",
            "         [[ 0.0194]],\n",
            "\n",
            "         [[-0.0608]],\n",
            "\n",
            "         [[-0.0678]],\n",
            "\n",
            "         [[-0.0832]],\n",
            "\n",
            "         [[-0.2020]],\n",
            "\n",
            "         [[-0.1082]],\n",
            "\n",
            "         [[ 0.0003]],\n",
            "\n",
            "         [[-0.0970]],\n",
            "\n",
            "         [[-0.1352]],\n",
            "\n",
            "         [[-0.0977]],\n",
            "\n",
            "         [[-0.1418]],\n",
            "\n",
            "         [[-0.1425]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[-0.0917]],\n",
            "\n",
            "         [[-0.0927]],\n",
            "\n",
            "         [[-0.0628]],\n",
            "\n",
            "         [[-0.0935]],\n",
            "\n",
            "         [[-0.1610]],\n",
            "\n",
            "         [[ 0.0531]],\n",
            "\n",
            "         [[-0.0930]],\n",
            "\n",
            "         [[-0.1628]],\n",
            "\n",
            "         [[-0.1012]],\n",
            "\n",
            "         [[-0.0441]],\n",
            "\n",
            "         [[-0.0789]],\n",
            "\n",
            "         [[-0.0067]],\n",
            "\n",
            "         [[ 0.0689]],\n",
            "\n",
            "         [[-0.0061]],\n",
            "\n",
            "         [[ 0.0422]],\n",
            "\n",
            "         [[-0.1668]],\n",
            "\n",
            "         [[-0.0646]],\n",
            "\n",
            "         [[-0.0814]],\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         [[-0.0939]],\n",
            "\n",
            "         [[ 0.0339]],\n",
            "\n",
            "         [[-0.0748]],\n",
            "\n",
            "         [[-0.0794]],\n",
            "\n",
            "         [[-0.1555]],\n",
            "\n",
            "         [[ 0.0621]],\n",
            "\n",
            "         [[ 0.0561]],\n",
            "\n",
            "         [[ 0.0261]],\n",
            "\n",
            "         [[-0.2033]],\n",
            "\n",
            "         [[-0.0163]],\n",
            "\n",
            "         [[-0.0975]],\n",
            "\n",
            "         [[-0.1256]],\n",
            "\n",
            "         [[-0.0567]],\n",
            "\n",
            "         [[-0.0674]],\n",
            "\n",
            "         [[-0.0636]],\n",
            "\n",
            "         [[-0.0964]],\n",
            "\n",
            "         [[ 0.0310]],\n",
            "\n",
            "         [[-0.1801]],\n",
            "\n",
            "         [[-0.1143]],\n",
            "\n",
            "         [[ 0.0531]],\n",
            "\n",
            "         [[-0.0627]],\n",
            "\n",
            "         [[-0.1823]],\n",
            "\n",
            "         [[-0.1776]],\n",
            "\n",
            "         [[ 0.0173]],\n",
            "\n",
            "         [[ 0.0707]],\n",
            "\n",
            "         [[-0.1103]],\n",
            "\n",
            "         [[ 0.0158]],\n",
            "\n",
            "         [[-0.0553]],\n",
            "\n",
            "         [[-0.1232]],\n",
            "\n",
            "         [[-0.0162]],\n",
            "\n",
            "         [[-0.0537]],\n",
            "\n",
            "         [[-0.0438]],\n",
            "\n",
            "         [[-0.1962]],\n",
            "\n",
            "         [[-0.1245]],\n",
            "\n",
            "         [[-0.0623]],\n",
            "\n",
            "         [[-0.1024]],\n",
            "\n",
            "         [[-0.0674]],\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         [[-0.0788]],\n",
            "\n",
            "         [[-0.0037]],\n",
            "\n",
            "         [[-0.0667]],\n",
            "\n",
            "         [[-0.0496]],\n",
            "\n",
            "         [[-0.1104]],\n",
            "\n",
            "         [[-0.0486]],\n",
            "\n",
            "         [[-0.0694]],\n",
            "\n",
            "         [[-0.1426]],\n",
            "\n",
            "         [[-0.0068]],\n",
            "\n",
            "         [[ 0.0402]],\n",
            "\n",
            "         [[-0.0840]],\n",
            "\n",
            "         [[-0.0941]],\n",
            "\n",
            "         [[-0.0597]],\n",
            "\n",
            "         [[ 0.0205]],\n",
            "\n",
            "         [[-0.0667]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-0.1248]],\n",
            "\n",
            "         [[-0.1900]],\n",
            "\n",
            "         [[-0.0894]],\n",
            "\n",
            "         [[-0.0441]],\n",
            "\n",
            "         [[ 0.0314]],\n",
            "\n",
            "         [[-0.0845]],\n",
            "\n",
            "         [[-0.0124]],\n",
            "\n",
            "         [[-0.1700]],\n",
            "\n",
            "         [[-0.1679]],\n",
            "\n",
            "         [[ 0.0622]],\n",
            "\n",
            "         [[-0.1472]],\n",
            "\n",
            "         [[-0.0904]],\n",
            "\n",
            "         [[-0.0275]],\n",
            "\n",
            "         [[-0.0968]],\n",
            "\n",
            "         [[ 0.0027]],\n",
            "\n",
            "         [[-0.0530]],\n",
            "\n",
            "         [[-0.1309]],\n",
            "\n",
            "         [[-0.1215]],\n",
            "\n",
            "         [[-0.1779]],\n",
            "\n",
            "         [[ 0.0449]],\n",
            "\n",
            "         [[ 0.0711]],\n",
            "\n",
            "         [[-0.0629]],\n",
            "\n",
            "         [[ 0.0168]],\n",
            "\n",
            "         [[ 0.0284]],\n",
            "\n",
            "         [[-0.0885]],\n",
            "\n",
            "         [[-0.0752]],\n",
            "\n",
            "         [[-0.1540]],\n",
            "\n",
            "         [[-0.1368]],\n",
            "\n",
            "         [[-0.0232]],\n",
            "\n",
            "         [[-0.0821]],\n",
            "\n",
            "         [[ 0.0458]],\n",
            "\n",
            "         [[-0.1097]],\n",
            "\n",
            "         [[-0.1206]],\n",
            "\n",
            "         [[-0.1254]],\n",
            "\n",
            "         [[ 0.0724]],\n",
            "\n",
            "         [[-0.0827]],\n",
            "\n",
            "         [[-0.1274]],\n",
            "\n",
            "         [[-0.0364]],\n",
            "\n",
            "         [[-0.0879]],\n",
            "\n",
            "         [[-0.1457]],\n",
            "\n",
            "         [[-0.0555]],\n",
            "\n",
            "         [[ 0.0279]],\n",
            "\n",
            "         [[-0.0867]],\n",
            "\n",
            "         [[ 0.0372]],\n",
            "\n",
            "         [[-0.0639]],\n",
            "\n",
            "         [[-0.2023]],\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.1126]],\n",
            "\n",
            "         [[-0.0042]],\n",
            "\n",
            "         [[ 0.0610]],\n",
            "\n",
            "         [[-0.1230]],\n",
            "\n",
            "         [[-0.1131]],\n",
            "\n",
            "         [[-0.0105]],\n",
            "\n",
            "         [[-0.0535]],\n",
            "\n",
            "         [[-0.0884]],\n",
            "\n",
            "         [[-0.0453]],\n",
            "\n",
            "         [[-0.1909]],\n",
            "\n",
            "         [[-0.1068]],\n",
            "\n",
            "         [[-0.1289]],\n",
            "\n",
            "         [[ 0.0373]],\n",
            "\n",
            "         [[ 0.0239]],\n",
            "\n",
            "         [[-0.1222]],\n",
            "\n",
            "         [[-0.1308]],\n",
            "\n",
            "         [[ 0.0605]],\n",
            "\n",
            "         [[-0.1588]],\n",
            "\n",
            "         [[ 0.0636]],\n",
            "\n",
            "         [[-0.1508]],\n",
            "\n",
            "         [[ 0.0779]],\n",
            "\n",
            "         [[-0.0335]],\n",
            "\n",
            "         [[-0.0216]],\n",
            "\n",
            "         [[-0.0844]],\n",
            "\n",
            "         [[-0.1280]],\n",
            "\n",
            "         [[-0.1721]],\n",
            "\n",
            "         [[-0.1597]],\n",
            "\n",
            "         [[-0.0876]],\n",
            "\n",
            "         [[-0.0570]],\n",
            "\n",
            "         [[-0.0622]],\n",
            "\n",
            "         [[-0.0511]],\n",
            "\n",
            "         [[-0.0980]],\n",
            "\n",
            "         [[ 0.0605]],\n",
            "\n",
            "         [[-0.0800]],\n",
            "\n",
            "         [[-0.0813]],\n",
            "\n",
            "         [[ 0.0731]],\n",
            "\n",
            "         [[-0.0555]],\n",
            "\n",
            "         [[-0.0584]],\n",
            "\n",
            "         [[ 0.0746]],\n",
            "\n",
            "         [[ 0.0760]],\n",
            "\n",
            "         [[-0.0321]],\n",
            "\n",
            "         [[-0.0987]],\n",
            "\n",
            "         [[-0.0717]],\n",
            "\n",
            "         [[-0.1055]],\n",
            "\n",
            "         [[-0.0982]],\n",
            "\n",
            "         [[ 0.0416]],\n",
            "\n",
            "         [[ 0.0752]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         [[-0.0844]],\n",
            "\n",
            "         [[-0.1885]],\n",
            "\n",
            "         [[-0.1015]],\n",
            "\n",
            "         [[-0.1021]],\n",
            "\n",
            "         [[-0.0654]],\n",
            "\n",
            "         [[-0.0503]],\n",
            "\n",
            "         [[-0.0514]],\n",
            "\n",
            "         [[ 0.0729]],\n",
            "\n",
            "         [[ 0.0701]],\n",
            "\n",
            "         [[-0.0298]],\n",
            "\n",
            "         [[-0.1219]],\n",
            "\n",
            "         [[-0.0922]],\n",
            "\n",
            "         [[-0.0780]],\n",
            "\n",
            "         [[-0.0973]],\n",
            "\n",
            "         [[-0.0666]],\n",
            "\n",
            "         [[-0.1003]],\n",
            "\n",
            "         [[ 0.0732]],\n",
            "\n",
            "         [[-0.1291]],\n",
            "\n",
            "         [[-0.0792]],\n",
            "\n",
            "         [[ 0.0526]],\n",
            "\n",
            "         [[-0.1423]],\n",
            "\n",
            "         [[-0.1190]],\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[ 0.0082]],\n",
            "\n",
            "         [[ 0.0360]],\n",
            "\n",
            "         [[-0.0422]],\n",
            "\n",
            "         [[-0.0655]],\n",
            "\n",
            "         [[-0.0813]],\n",
            "\n",
            "         [[-0.1694]],\n",
            "\n",
            "         [[-0.0496]],\n",
            "\n",
            "         [[ 0.0406]],\n",
            "\n",
            "         [[ 0.0097]],\n",
            "\n",
            "         [[-0.0951]],\n",
            "\n",
            "         [[-0.1717]],\n",
            "\n",
            "         [[-0.1128]],\n",
            "\n",
            "         [[-0.0193]],\n",
            "\n",
            "         [[-0.1888]],\n",
            "\n",
            "         [[-0.1877]],\n",
            "\n",
            "         [[-0.0683]],\n",
            "\n",
            "         [[-0.1053]],\n",
            "\n",
            "         [[-0.0489]],\n",
            "\n",
            "         [[-0.1519]],\n",
            "\n",
            "         [[ 0.0637]],\n",
            "\n",
            "         [[-0.0827]],\n",
            "\n",
            "         [[-0.0785]],\n",
            "\n",
            "         [[-0.1975]],\n",
            "\n",
            "         [[ 0.0662]],\n",
            "\n",
            "         [[-0.0069]],\n",
            "\n",
            "         [[-0.1193]],\n",
            "\n",
            "         [[-0.1211]],\n",
            "\n",
            "         [[ 0.0039]],\n",
            "\n",
            "         [[-0.1246]]]], device='cuda:0')), ('classifier.4.bias', tensor([-0.0068,  0.0114], device='cuda:0')), ('aux_classifier.0.weight', tensor([[[[-8.4776e-04, -1.9110e-03, -1.4882e-03],\n",
            "          [-6.9765e-04, -1.4595e-03, -1.5718e-03],\n",
            "          [-1.1785e-03, -1.1119e-03, -2.0589e-03]],\n",
            "\n",
            "         [[ 5.0155e-04,  1.3001e-03,  1.3215e-03],\n",
            "          [ 7.7052e-04,  1.8713e-03,  1.3745e-03],\n",
            "          [-1.2296e-03,  2.7902e-05, -9.1070e-04]],\n",
            "\n",
            "         [[-7.1898e-03, -3.7166e-03, -4.9611e-03],\n",
            "          [ 1.0656e-03,  2.4118e-03,  3.1431e-03],\n",
            "          [-7.7793e-04,  1.8108e-03,  9.4492e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.3530e-04, -3.6230e-04, -5.5800e-05],\n",
            "          [ 4.7797e-04, -3.5864e-04, -5.5750e-05],\n",
            "          [ 5.4731e-05, -5.4561e-04, -2.1408e-04]],\n",
            "\n",
            "         [[ 2.3862e-05,  1.2850e-03,  5.6620e-04],\n",
            "          [ 1.5976e-03,  2.3572e-03,  1.9084e-03],\n",
            "          [ 1.1288e-03,  2.1967e-03,  1.6731e-03]],\n",
            "\n",
            "         [[ 3.2430e-04, -3.8102e-04, -1.5519e-04],\n",
            "          [-6.0373e-04, -1.0756e-03, -9.8072e-04],\n",
            "          [-2.3616e-04, -1.3899e-03, -7.0197e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6494e-05, -7.0069e-04, -2.0747e-03],\n",
            "          [-1.2220e-04, -9.3988e-04, -2.0411e-03],\n",
            "          [ 4.9010e-04, -1.1179e-03, -2.2562e-03]],\n",
            "\n",
            "         [[ 1.7952e-03, -2.6257e-04,  2.1608e-03],\n",
            "          [ 3.1402e-03,  5.9222e-04,  3.6237e-03],\n",
            "          [ 9.0164e-03,  6.6282e-03,  1.0648e-02]],\n",
            "\n",
            "         [[-1.2410e-02, -7.0737e-03, -1.1525e-02],\n",
            "          [-9.6376e-03, -4.6871e-03, -9.3880e-03],\n",
            "          [-1.8444e-02, -1.3857e-02, -1.7647e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.6726e-03, -3.6002e-03, -4.7355e-03],\n",
            "          [-3.5708e-03, -2.7662e-03, -3.8878e-03],\n",
            "          [-3.7983e-03, -3.1903e-03, -3.7428e-03]],\n",
            "\n",
            "         [[-6.2454e-03, -4.5716e-03, -6.6433e-03],\n",
            "          [-4.9715e-03, -3.5342e-03, -6.1855e-03],\n",
            "          [-5.9330e-03, -4.8231e-03, -7.4629e-03]],\n",
            "\n",
            "         [[ 3.7602e-03,  1.3164e-03,  2.1360e-03],\n",
            "          [ 2.3376e-03,  1.3484e-03,  2.5566e-03],\n",
            "          [ 3.1909e-03,  2.2792e-03,  3.4212e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1431e-03,  1.2893e-03,  6.1321e-04],\n",
            "          [ 3.6156e-03,  1.1910e-03,  1.9063e-04],\n",
            "          [ 4.6932e-03,  2.9864e-03, -1.9087e-03]],\n",
            "\n",
            "         [[ 1.1409e-03, -2.3823e-04,  2.4681e-03],\n",
            "          [-1.1242e-03, -6.1590e-04,  1.7460e-03],\n",
            "          [-2.6716e-04, -5.6713e-04,  2.7201e-03]],\n",
            "\n",
            "         [[-7.9935e-04, -1.2945e-03, -1.5829e-03],\n",
            "          [ 1.5825e-03,  8.8278e-05, -3.0850e-04],\n",
            "          [ 1.1353e-03,  3.6096e-04,  4.3641e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.0110e-04,  1.5090e-03,  1.1086e-03],\n",
            "          [-5.0351e-04,  1.7398e-03,  1.2960e-03],\n",
            "          [-5.2556e-04,  1.4618e-03,  1.6820e-03]],\n",
            "\n",
            "         [[ 2.9778e-04,  1.3553e-03,  4.4040e-04],\n",
            "          [ 2.6572e-04,  1.4215e-03,  8.8957e-04],\n",
            "          [ 2.4009e-04,  1.3651e-03,  1.2087e-03]],\n",
            "\n",
            "         [[ 4.5688e-03,  2.6691e-03,  4.8468e-03],\n",
            "          [ 2.5669e-03,  3.3536e-03,  5.4940e-03],\n",
            "          [ 5.3903e-03,  3.9115e-03,  6.2308e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.4133e-04, -2.9542e-03, -1.5080e-03],\n",
            "          [-1.1336e-03, -2.7438e-03, -1.3180e-03],\n",
            "          [-6.7434e-04, -3.1970e-03, -9.3702e-04]],\n",
            "\n",
            "         [[-8.8304e-03, -5.8071e-03, -9.5625e-03],\n",
            "          [-7.5296e-03, -4.7520e-03, -7.5889e-03],\n",
            "          [-9.0352e-03, -5.9626e-03, -9.2736e-03]],\n",
            "\n",
            "         [[ 2.1843e-02,  1.6814e-02,  2.4457e-02],\n",
            "          [ 7.1330e-03,  4.6224e-03,  1.0996e-02],\n",
            "          [ 1.6484e-02,  1.2644e-02,  1.8890e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6132e-03,  2.3343e-03,  3.0378e-03],\n",
            "          [ 3.3065e-03,  2.2565e-03,  3.4336e-03],\n",
            "          [ 4.8380e-03,  3.7371e-03,  4.1102e-03]],\n",
            "\n",
            "         [[-2.0936e-03, -1.1974e-03, -3.7616e-04],\n",
            "          [-4.2967e-04,  7.8459e-04,  1.5004e-03],\n",
            "          [ 7.6321e-04,  1.4781e-03,  2.9134e-03]],\n",
            "\n",
            "         [[-4.2060e-03, -1.8657e-03, -3.0701e-03],\n",
            "          [-3.5693e-03, -1.0647e-03, -3.9468e-03],\n",
            "          [-3.5949e-03, -2.5119e-03, -4.7137e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.9451e-04,  1.4324e-03,  6.4369e-04],\n",
            "          [ 9.0728e-04,  1.6323e-03,  9.5387e-04],\n",
            "          [ 3.6949e-04,  1.2910e-03,  1.0749e-04]],\n",
            "\n",
            "         [[ 6.4657e-04,  1.8140e-03,  4.2050e-04],\n",
            "          [ 4.2399e-04,  1.6875e-03,  3.3897e-04],\n",
            "          [-1.8897e-03, -1.3822e-04, -1.6049e-03]],\n",
            "\n",
            "         [[ 3.3707e-03,  1.1892e-03,  2.5908e-03],\n",
            "          [-2.3977e-03, -3.9085e-03, -3.3077e-03],\n",
            "          [ 6.6217e-05, -2.7130e-03, -1.9644e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.5755e-04,  8.5299e-04,  1.0658e-03],\n",
            "          [-6.8995e-04, -5.5820e-04, -7.3320e-04],\n",
            "          [-1.7533e-03, -2.1568e-03, -2.1518e-03]],\n",
            "\n",
            "         [[-4.3669e-03, -2.8473e-03, -4.7293e-03],\n",
            "          [-2.4778e-03, -8.0278e-04, -2.7110e-03],\n",
            "          [-3.3328e-03, -1.7962e-03, -3.5990e-03]],\n",
            "\n",
            "         [[-1.0205e-03, -9.1679e-04, -1.0761e-03],\n",
            "          [-1.2828e-03, -1.2496e-03, -1.0715e-03],\n",
            "          [-2.0161e-03, -1.7835e-03, -1.5697e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5726e-03,  2.4251e-03,  3.3192e-03],\n",
            "          [ 1.5255e-03,  1.7979e-03,  2.2056e-03],\n",
            "          [ 1.7012e-03,  1.7513e-03,  2.1325e-03]],\n",
            "\n",
            "         [[ 4.4999e-04,  1.6722e-03,  5.5768e-04],\n",
            "          [-1.3582e-03, -2.6530e-04, -1.2382e-03],\n",
            "          [-1.3813e-03, -2.8873e-04, -1.8364e-03]],\n",
            "\n",
            "         [[-5.3085e-03, -4.5491e-03, -4.0206e-03],\n",
            "          [-1.2540e-03, -3.9437e-04, -1.0232e-04],\n",
            "          [-4.5091e-04,  6.7656e-04,  3.5208e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7728e-03,  1.3554e-03,  2.0109e-03],\n",
            "          [ 2.2351e-03,  5.5187e-04,  1.1009e-03],\n",
            "          [ 2.0548e-03,  8.4820e-04,  1.0974e-03]],\n",
            "\n",
            "         [[ 2.9925e-04, -6.3034e-05,  5.6105e-04],\n",
            "          [ 1.2895e-04, -4.6804e-04,  3.7786e-04],\n",
            "          [-3.6287e-04, -8.3998e-04,  3.1660e-04]],\n",
            "\n",
            "         [[-4.6208e-04, -5.2602e-04, -1.4326e-03],\n",
            "          [-2.5894e-04, -1.7253e-04, -9.8773e-04],\n",
            "          [ 6.8933e-04, -2.1837e-05, -1.9231e-04]]]], device='cuda:0')), ('aux_classifier.1.weight', tensor([0.4109, 0.4866, 0.3133, 0.5057, 0.5694, 0.2776, 0.3778, 0.2648, 0.4249,\n",
            "        0.1892, 0.5165, 0.4324, 0.4442, 0.3449, 0.3220, 0.3357, 0.2296, 0.3765,\n",
            "        0.4474, 0.3133, 0.3273, 0.3004, 0.2416, 0.5426, 0.5054, 0.3838, 0.2015,\n",
            "        0.3394, 0.2320, 0.4046, 0.2450, 0.4503, 0.3039, 0.4189, 0.4746, 0.5230,\n",
            "        0.5017, 0.3489, 0.3439, 0.4354, 0.3705, 0.4196, 0.3522, 0.3510, 0.4254,\n",
            "        0.2809, 0.3200, 0.4553, 0.3709, 0.4907, 0.5368, 0.4312, 0.4528, 0.4631,\n",
            "        0.2569, 0.2578, 0.3920, 0.4152, 0.3323, 0.4927, 0.4072, 0.4166, 0.4824,\n",
            "        0.5845, 0.4108, 0.4425, 0.4183, 0.3565, 0.3909, 0.4210, 0.3692, 0.5037,\n",
            "        0.3302, 0.2685, 0.4091, 0.2742, 0.4257, 0.3788, 0.4641, 0.1973, 0.4301,\n",
            "        0.6172, 0.4624, 0.4278, 0.2792, 0.2638, 0.4282, 0.2369, 0.3358, 0.3008,\n",
            "        0.3191, 0.3028, 0.3724, 0.3876, 0.2555, 0.4322, 0.3419, 0.3365, 0.4405,\n",
            "        0.5029, 0.2905, 0.5813, 0.3479, 0.3231, 0.4915, 0.5966, 0.2884, 0.5026,\n",
            "        0.3864, 0.1820, 0.2608, 0.2854, 0.3495, 0.4602, 0.4382, 0.4852, 0.2975,\n",
            "        0.3692, 0.1692, 0.3975, 0.3598, 0.3591, 0.4102, 0.3577, 0.2827, 0.4566,\n",
            "        0.2937, 0.3863, 0.5228, 0.3398, 0.4029, 0.4132, 0.2621, 0.3504, 0.4849,\n",
            "        0.5136, 0.4912, 0.3693, 0.4746, 0.3067, 0.5200, 0.2513, 0.2744, 0.4990,\n",
            "        0.4561, 0.4320, 0.3445, 0.4386, 0.3602, 0.2659, 0.4568, 0.4629, 0.3292,\n",
            "        0.3368, 0.2285, 0.5152, 0.2721, 0.3436, 0.5074, 0.3254, 0.2995, 0.2924,\n",
            "        0.3680, 0.3534, 0.4635, 0.2720, 0.4080, 0.2917, 0.3225, 0.3029, 0.4411,\n",
            "        0.3673, 0.3292, 0.4218, 0.2760, 0.3079, 0.3166, 0.3596, 0.3553, 0.5075,\n",
            "        0.3392, 0.2879, 0.4128, 0.3695, 0.2497, 0.2908, 0.2619, 0.4662, 0.5054,\n",
            "        0.4310, 0.5454, 0.2863, 0.4671, 0.4750, 0.5113, 0.3742, 0.3083, 0.3586,\n",
            "        0.3858, 0.4923, 0.3985, 0.4069, 0.3554, 0.3503, 0.5442, 0.4518, 0.4200,\n",
            "        0.3126, 0.3225, 0.5050, 0.2487, 0.4752, 0.2762, 0.5003, 0.1964, 0.2985,\n",
            "        0.4840, 0.2871, 0.3544, 0.3219, 0.3137, 0.2108, 0.4590, 0.2206, 0.5302,\n",
            "        0.3475, 0.2443, 0.3323, 0.3111, 0.3550, 0.2849, 0.2452, 0.2944, 0.4956,\n",
            "        0.3646, 0.2434, 0.4453, 0.3928, 0.2787, 0.3651, 0.4644, 0.4466, 0.2744,\n",
            "        0.4197, 0.4868, 0.4306, 0.4053, 0.4517, 0.4545, 0.4539, 0.3434, 0.4951,\n",
            "        0.3497, 0.4668, 0.4048, 0.2473], device='cuda:0')), ('aux_classifier.1.bias', tensor([ 2.3955e-01,  1.2899e-01, -1.2040e-02,  2.1276e-01,  1.6780e-01,\n",
            "         2.1309e-01,  1.2469e-01,  2.1462e-01,  1.9580e-01,  7.9942e-02,\n",
            "         1.6521e-01,  2.1646e-01,  1.1933e-01,  2.0277e-02,  9.6482e-02,\n",
            "         1.7268e-01,  5.5460e-02,  1.6947e-01,  1.1853e-01,  6.5705e-02,\n",
            "         4.2382e-03,  3.7724e-02, -6.9240e-02,  1.5681e-01,  1.4907e-01,\n",
            "        -1.3087e-03,  5.6100e-02,  3.6664e-02,  7.9298e-02,  2.2790e-01,\n",
            "         1.2658e-01,  1.4982e-01,  1.6257e-01,  1.4708e-02,  1.7025e-01,\n",
            "         1.1365e-01,  2.6247e-01,  9.5431e-02,  2.3666e-02,  1.4755e-01,\n",
            "         1.5375e-01,  1.9537e-01,  1.6393e-01,  9.5169e-02,  1.3152e-01,\n",
            "         3.8366e-02, -7.3312e-02,  1.4471e-01,  1.8823e-01,  2.1000e-01,\n",
            "         1.9119e-01,  1.3462e-01,  1.3206e-01,  1.7185e-01,  1.8939e-01,\n",
            "         1.8441e-01,  4.0062e-02,  1.8777e-01,  1.9627e-01,  1.9564e-01,\n",
            "         1.6134e-01,  1.6826e-01,  2.3988e-01,  1.8694e-01,  2.0114e-01,\n",
            "         1.4826e-01,  1.3455e-01,  1.9688e-01,  8.5495e-02,  1.4254e-01,\n",
            "         1.5028e-01,  2.2007e-01,  1.4341e-01,  1.7497e-01,  1.9054e-01,\n",
            "         1.2925e-01, -4.2210e-02,  1.4178e-01,  1.1373e-01,  5.6263e-02,\n",
            "         1.6382e-01,  1.7819e-01, -1.0355e-02,  1.8095e-01,  1.3800e-01,\n",
            "         1.0493e-01,  1.3116e-01,  6.1264e-02,  1.5335e-01,  1.6560e-01,\n",
            "         5.0190e-02,  8.1498e-02,  1.4363e-01,  1.5577e-01,  8.3457e-02,\n",
            "         1.4513e-01,  9.7901e-02,  1.4732e-01,  1.9202e-01,  1.9667e-01,\n",
            "         4.9535e-02,  2.6748e-01,  9.2332e-02,  1.2684e-02,  1.5183e-01,\n",
            "         1.9792e-01,  4.1985e-02,  2.0941e-01,  9.1456e-02,  5.2877e-02,\n",
            "         9.8386e-02,  1.6125e-04,  1.7381e-01,  1.8993e-01,  2.0064e-01,\n",
            "         1.6003e-01,  6.9362e-02,  9.4585e-02,  4.2842e-02,  1.2120e-01,\n",
            "         2.2476e-01,  8.8577e-02,  1.7655e-01,  5.6854e-02,  9.8518e-02,\n",
            "         1.3948e-01,  2.0367e-01,  1.4183e-01,  2.0398e-01,  5.0986e-02,\n",
            "         9.6820e-02,  2.2993e-01,  1.1096e-01,  1.3026e-01,  1.5759e-01,\n",
            "         1.6657e-01,  7.5848e-02, -1.9310e-02,  1.9734e-01,  1.3834e-02,\n",
            "         1.7383e-01,  1.3164e-01,  3.7200e-02,  1.7930e-01,  1.4170e-01,\n",
            "         1.0236e-01,  1.1417e-01,  1.6925e-01,  1.3019e-01,  7.5233e-02,\n",
            "         1.3214e-01,  1.8466e-01,  1.7342e-01,  1.3686e-01,  6.3547e-02,\n",
            "         1.4518e-01,  5.6646e-02,  1.8236e-01,  1.9047e-01,  1.2581e-01,\n",
            "         1.1893e-01,  1.3410e-01,  1.2861e-01,  1.0887e-01, -3.0100e-02,\n",
            "         8.9258e-02,  1.4883e-01,  8.8080e-02, -8.1134e-02,  1.6845e-01,\n",
            "         8.1433e-02,  2.8736e-02,  1.5212e-01,  1.9235e-02,  5.0331e-02,\n",
            "         1.3108e-01,  3.8324e-02,  2.8926e-02,  1.8558e-01,  1.3940e-01,\n",
            "         1.4523e-01,  9.9433e-02,  1.7537e-01,  1.4859e-01,  1.6399e-01,\n",
            "         8.4641e-02,  1.4208e-01,  1.3169e-01,  1.7405e-01,  1.4662e-01,\n",
            "         1.6093e-01,  9.8396e-02,  1.7714e-01,  1.7813e-01,  1.6606e-01,\n",
            "         9.6409e-02,  2.1723e-01,  1.1121e-01,  1.0961e-01,  1.6551e-01,\n",
            "         7.2646e-02, -2.5587e-02,  1.3798e-01,  1.5558e-01,  1.9369e-01,\n",
            "         1.8112e-01,  1.7698e-01,  1.8000e-01,  2.3076e-02,  1.9861e-01,\n",
            "         9.4274e-02,  1.6368e-01,  4.0121e-02,  1.6738e-01,  4.9747e-02,\n",
            "         1.7056e-02,  1.6766e-01,  1.6113e-01,  1.4904e-02,  1.1899e-01,\n",
            "         5.1841e-02,  1.3931e-01,  2.3362e-01,  6.9925e-02,  1.0946e-01,\n",
            "         1.6890e-01,  1.8720e-02,  1.2941e-01,  1.5277e-01,  1.8609e-01,\n",
            "        -5.8018e-02,  8.2923e-02,  1.4705e-01,  1.9864e-01,  1.1147e-01,\n",
            "         1.0491e-01,  2.1787e-01,  1.9659e-01,  7.7449e-02,  1.3032e-01,\n",
            "         2.5585e-01,  6.9820e-02,  3.3461e-02,  1.0185e-01,  1.5240e-01,\n",
            "         1.3124e-01,  1.1238e-01,  1.6992e-01,  2.0305e-01,  1.0953e-01,\n",
            "         1.1351e-01,  1.1012e-01,  1.4169e-01,  1.5403e-01,  1.8329e-01,\n",
            "         1.5958e-01], device='cuda:0')), ('aux_classifier.1.running_mean', tensor([-0.0044, -0.0700, -0.0221, -0.0490, -0.0132,  0.0306,  0.0088,  0.0204,\n",
            "        -0.0160, -0.0098, -0.0373, -0.0449,  0.0030, -0.0198, -0.0215,  0.0191,\n",
            "        -0.0377, -0.0063, -0.0308, -0.0522, -0.0217, -0.0245, -0.0304, -0.0390,\n",
            "        -0.0124, -0.0392, -0.0710, -0.0494, -0.0581, -0.0002, -0.0131, -0.0411,\n",
            "        -0.0091, -0.0568, -0.0272, -0.0379, -0.0154,  0.0045, -0.0744,  0.0433,\n",
            "        -0.0169, -0.0330,  0.0170, -0.0529,  0.0202, -0.0190, -0.0715, -0.0364,\n",
            "        -0.0147, -0.0285, -0.0420, -0.0315, -0.0453, -0.0040, -0.0131,  0.0432,\n",
            "        -0.0345,  0.0103,  0.0484,  0.0073, -0.0131, -0.0391,  0.0230, -0.0191,\n",
            "        -0.0203, -0.0467, -0.0292, -0.0287, -0.0221, -0.0237, -0.0271, -0.0405,\n",
            "        -0.0060,  0.0154,  0.0057, -0.0219, -0.0710, -0.0035, -0.0303, -0.0289,\n",
            "        -0.0109, -0.0910, -0.0464, -0.0159,  0.0098,  0.0256,  0.0194, -0.0359,\n",
            "         0.0098,  0.0105, -0.0184,  0.0382, -0.0023, -0.0463, -0.0411, -0.0454,\n",
            "         0.0366, -0.0295,  0.0016, -0.0482,  0.0122, -0.0095, -0.0242, -0.0463,\n",
            "        -0.0305, -0.0189, -0.0059, -0.0317,  0.0232, -0.0631, -0.0128, -0.0271,\n",
            "        -0.0191, -0.0283, -0.0079, -0.0383, -0.0465, -0.0509, -0.0356,  0.0127,\n",
            "        -0.0258, -0.0366, -0.0121, -0.0588, -0.0434, -0.0152,  0.0396, -0.0200,\n",
            "        -0.0124, -0.0178, -0.0531, -0.0117, -0.0336, -0.0138, -0.0694, -0.0342,\n",
            "        -0.0139, -0.0361, -0.0215,  0.0001, -0.0549, -0.0327, -0.0458, -0.0100,\n",
            "        -0.0774, -0.0714, -0.0143, -0.0271, -0.0387, -0.0391, -0.0518, -0.0242,\n",
            "        -0.0380, -0.0201, -0.0105, -0.0047, -0.0584, -0.0028, -0.0290, -0.0280,\n",
            "        -0.0248,  0.0006, -0.0489, -0.0310, -0.0731,  0.0147,  0.0021, -0.0625,\n",
            "        -0.0089, -0.0095, -0.0301, -0.0422, -0.0198, -0.0281, -0.0304, -0.0343,\n",
            "        -0.0529, -0.0463,  0.0036, -0.0663, -0.0021, -0.0033,  0.0103, -0.0205,\n",
            "        -0.0226, -0.0573, -0.0302,  0.0239, -0.0465, -0.0620, -0.0362, -0.0312,\n",
            "         0.0027, -0.0478, -0.0270, -0.0548, -0.0183, -0.0039, -0.0159, -0.0160,\n",
            "        -0.0243, -0.0760, -0.0263,  0.0311, -0.0384, -0.0093, -0.0299, -0.0233,\n",
            "        -0.0178, -0.0203, -0.0541, -0.0552, -0.0343, -0.0459, -0.0222, -0.0170,\n",
            "        -0.0301,  0.0341, -0.0451, -0.0203, -0.0233,  0.0104, -0.0162,  0.0099,\n",
            "        -0.0195, -0.0227, -0.0297,  0.0013, -0.0164, -0.0007, -0.0035, -0.0521,\n",
            "         0.0036,  0.0048,  0.0211, -0.0437, -0.0224, -0.0304, -0.0239,  0.0304,\n",
            "        -0.0166, -0.0267, -0.0322, -0.0092, -0.0476,  0.0070, -0.0101, -0.0153,\n",
            "        -0.0067, -0.0144, -0.0236, -0.0168,  0.0005, -0.0515, -0.0108, -0.0204],\n",
            "       device='cuda:0')), ('aux_classifier.1.running_var', tensor([0.0031, 0.0028, 0.0011, 0.0027, 0.0018, 0.0031, 0.0015, 0.0021, 0.0020,\n",
            "        0.0004, 0.0036, 0.0022, 0.0024, 0.0022, 0.0018, 0.0018, 0.0012, 0.0016,\n",
            "        0.0013, 0.0020, 0.0017, 0.0015, 0.0006, 0.0021, 0.0028, 0.0019, 0.0022,\n",
            "        0.0017, 0.0027, 0.0017, 0.0013, 0.0023, 0.0009, 0.0026, 0.0017, 0.0019,\n",
            "        0.0029, 0.0031, 0.0020, 0.0027, 0.0015, 0.0024, 0.0017, 0.0025, 0.0033,\n",
            "        0.0013, 0.0020, 0.0036, 0.0021, 0.0026, 0.0020, 0.0019, 0.0022, 0.0014,\n",
            "        0.0015, 0.0025, 0.0024, 0.0025, 0.0021, 0.0021, 0.0016, 0.0020, 0.0027,\n",
            "        0.0021, 0.0019, 0.0015, 0.0022, 0.0022, 0.0016, 0.0027, 0.0015, 0.0024,\n",
            "        0.0012, 0.0016, 0.0017, 0.0026, 0.0024, 0.0012, 0.0020, 0.0006, 0.0028,\n",
            "        0.0030, 0.0029, 0.0046, 0.0015, 0.0009, 0.0037, 0.0015, 0.0026, 0.0013,\n",
            "        0.0025, 0.0021, 0.0013, 0.0023, 0.0014, 0.0026, 0.0020, 0.0017, 0.0017,\n",
            "        0.0023, 0.0020, 0.0026, 0.0011, 0.0012, 0.0019, 0.0035, 0.0017, 0.0028,\n",
            "        0.0031, 0.0014, 0.0016, 0.0015, 0.0013, 0.0028, 0.0017, 0.0024, 0.0022,\n",
            "        0.0029, 0.0009, 0.0016, 0.0022, 0.0012, 0.0013, 0.0031, 0.0017, 0.0026,\n",
            "        0.0027, 0.0016, 0.0029, 0.0019, 0.0016, 0.0031, 0.0024, 0.0028, 0.0017,\n",
            "        0.0018, 0.0025, 0.0021, 0.0019, 0.0009, 0.0021, 0.0030, 0.0013, 0.0024,\n",
            "        0.0020, 0.0023, 0.0013, 0.0025, 0.0013, 0.0019, 0.0021, 0.0019, 0.0016,\n",
            "        0.0015, 0.0013, 0.0040, 0.0018, 0.0025, 0.0026, 0.0018, 0.0032, 0.0018,\n",
            "        0.0019, 0.0020, 0.0031, 0.0035, 0.0014, 0.0015, 0.0011, 0.0012, 0.0022,\n",
            "        0.0021, 0.0012, 0.0024, 0.0010, 0.0025, 0.0018, 0.0019, 0.0018, 0.0027,\n",
            "        0.0016, 0.0017, 0.0018, 0.0016, 0.0025, 0.0017, 0.0013, 0.0031, 0.0032,\n",
            "        0.0030, 0.0020, 0.0020, 0.0014, 0.0022, 0.0024, 0.0018, 0.0022, 0.0014,\n",
            "        0.0026, 0.0028, 0.0013, 0.0022, 0.0015, 0.0027, 0.0028, 0.0028, 0.0028,\n",
            "        0.0022, 0.0016, 0.0023, 0.0020, 0.0014, 0.0010, 0.0022, 0.0007, 0.0016,\n",
            "        0.0017, 0.0026, 0.0020, 0.0021, 0.0016, 0.0016, 0.0029, 0.0007, 0.0026,\n",
            "        0.0014, 0.0008, 0.0019, 0.0013, 0.0017, 0.0009, 0.0026, 0.0017, 0.0035,\n",
            "        0.0015, 0.0020, 0.0017, 0.0024, 0.0015, 0.0028, 0.0024, 0.0018, 0.0017,\n",
            "        0.0023, 0.0022, 0.0025, 0.0048, 0.0020, 0.0021, 0.0025, 0.0022, 0.0016,\n",
            "        0.0010, 0.0018, 0.0016, 0.0024], device='cuda:0')), ('aux_classifier.1.num_batches_tracked', tensor(99698, device='cuda:0')), ('aux_classifier.4.weight', tensor([[[[ 0.1393]],\n",
            "\n",
            "         [[ 0.0192]],\n",
            "\n",
            "         [[-0.2024]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0957]],\n",
            "\n",
            "         [[ 0.1031]],\n",
            "\n",
            "         [[ 0.1969]]],\n",
            "\n",
            "\n",
            "        [[[-0.1030]],\n",
            "\n",
            "         [[-0.0716]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0458]],\n",
            "\n",
            "         [[-0.1292]],\n",
            "\n",
            "         [[-0.0203]]],\n",
            "\n",
            "\n",
            "        [[[-0.0885]],\n",
            "\n",
            "         [[-0.0294]],\n",
            "\n",
            "         [[-0.0144]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0766]],\n",
            "\n",
            "         [[ 0.0593]],\n",
            "\n",
            "         [[-0.0180]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2164]],\n",
            "\n",
            "         [[-0.0895]],\n",
            "\n",
            "         [[-0.0197]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1905]],\n",
            "\n",
            "         [[ 0.1309]],\n",
            "\n",
            "         [[-0.0425]]],\n",
            "\n",
            "\n",
            "        [[[-0.0502]],\n",
            "\n",
            "         [[ 0.1271]],\n",
            "\n",
            "         [[ 0.0427]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1256]],\n",
            "\n",
            "         [[ 0.2076]],\n",
            "\n",
            "         [[ 0.0132]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2056]],\n",
            "\n",
            "         [[-0.0335]],\n",
            "\n",
            "         [[-0.0340]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1688]],\n",
            "\n",
            "         [[-0.0357]],\n",
            "\n",
            "         [[ 0.1954]]]], device='cuda:0')), ('aux_classifier.4.bias', tensor([ 0.8720, -0.1463, -0.1448, -0.0780, -0.1318, -0.1184, -0.1139,  0.0500,\n",
            "        -0.0599, -0.0853, -0.0777,  0.2649,  0.0165, -0.0843, -0.0376,  0.3010,\n",
            "        -0.0715, -0.1799, -0.0596, -0.0140, -0.1012], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test/images/20190526_9560_23986636_fedb1aa67ec7c51df42d63c0b59590fa.jpg'))\n",
        "mask = Image.open(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test/masks/20190526_9560_23986636_fedb1aa67ec7c51df42d63c0b59590fa.jpg'))\n",
        "\n",
        "\n",
        "infer_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "input_image = infer_transform(image).to(device)\n",
        "\n",
        "output = seg_model(input_image.unsqueeze(dim=0))\n",
        "output['out'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpjB180hC0aE",
        "outputId": "a7caabff-4cbb-49d8-8f65-f0927fd1308c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 800, 600])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = Image.open(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test/images/20190526_9560_23986636_fedb1aa67ec7c51df42d63c0b59590fa.jpg'))\n",
        "image2 = Image.open(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test/masks/20190526_9560_23986636_fedb1aa67ec7c51df42d63c0b59590fa.jpg'))\n",
        "cls = torch.argmax(output['out'][0].to(\"cpu\"), dim=0).numpy()\n",
        "out = np.zeros_like(cls)\n",
        "out[cls==1] = 1\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(image1)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(image2)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "wyn3GE79C2qk",
        "outputId": "ffeb8825-01ca-4710-ce0e-ea595d3daf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdf3027b890>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vudrqDwSOZo7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}